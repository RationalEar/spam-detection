{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b0cc346f79f899a",
      "metadata": {
        "id": "3b0cc346f79f899a"
      },
      "source": [
        "#### Explainability of BERT using LayerIntegratedGradients"
      ]
    },
    {
      "cell_type": "code",
      "id": "79867e4373874d69",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:29.253356Z",
          "start_time": "2025-08-16T12:00:29.238972Z"
        },
        "id": "79867e4373874d69",
        "outputId": "092dcdef-4a4d-472a-bf87-45332e750ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    workspace_dir = '/content/spam-detection'\n",
        "    branch = 'feature/extended-explainability'\n",
        "    current_dir = os.getcwd()\n",
        "    if not os.path.exists(workspace_dir) and current_dir != workspace_dir:\n",
        "        !git clone https://github.com/RationalEar/spam-detection.git\n",
        "        os.chdir(workspace_dir)\n",
        "        !git checkout $branch\n",
        "        !ls -al\n",
        "        !pip install -q transformers==4.48.0 scikit-learn pandas numpy\n",
        "        !pip install -q torch --index-url https://download.pytorch.org/whl/cu126\n",
        "        !pip install captum --no-deps --ignore-installed\n",
        "    else:\n",
        "        os.chdir(workspace_dir)\n",
        "        !git pull origin $branch\n",
        "\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 1.26 KiB | 645.00 KiB/s, done.\n",
            "From https://github.com/RationalEar/spam-detection\n",
            " * branch            feature/extended-explainability -> FETCH_HEAD\n",
            "   338ef0c..5d7141a  feature/extended-explainability -> origin/feature/extended-explainability\n",
            "Updating 338ef0c..5d7141a\n",
            "Fast-forward\n",
            " explainability/BERT_Explain_2.ipynb      | 200 \u001b[32m++++\u001b[m\u001b[31m---------------------------\u001b[m\n",
            " explainability/BertExplanationMetrics.py |  11 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 32 insertions(+), 179 deletions(-)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:31.542706Z",
          "start_time": "2025-08-16T12:00:29.268287Z"
        },
        "id": "2ef380a1afc6497a",
        "outputId": "64291e0e-28b2-4a79-bcef-eb5c3d8c834f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "from utils.constants import DATA_PATH, MODEL_SAVE_PATH\n",
        "\n",
        "DATA_PATH"
      ],
      "id": "2ef380a1afc6497a",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Projects/spam-detection-data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "id": "982dab78441b50c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:32.564795Z",
          "start_time": "2025-08-16T12:00:31.568009Z"
        },
        "id": "982dab78441b50c6",
        "outputId": "8b67678c-c99e-4b62-c3d5-d68103596040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "train_df = pd.read_pickle(DATA_PATH + '/data/processed/train.pkl')\n",
        "test_df = pd.read_pickle(DATA_PATH + '/data/processed/test.pkl')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "id": "641a94a36b7ff2e3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:32.808607Z",
          "start_time": "2025-08-16T12:00:32.590110Z"
        },
        "id": "641a94a36b7ff2e3"
      },
      "source": [
        "from utils.functions import set_seed, build_vocab\n",
        "\n",
        "# Build vocabulary and load embeddings\n",
        "set_seed(42)\n",
        "word2idx, idx2word = build_vocab(train_df['text'])\n",
        "embedding_dim = 300\n",
        "max_len = 200\n",
        "pretrained_embeddings = None"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "id": "3c6c6db7f9188f8b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:41.222964Z",
          "start_time": "2025-08-16T12:00:32.826937Z"
        },
        "id": "3c6c6db7f9188f8b",
        "outputId": "a30142b4-0bc0-4475-eb93-8bd44bf6fc56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from models.bert import SpamBERT\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = SpamBERT(dropout=0.2)\n",
        "\n",
        "# Load the trained model weights\n",
        "model_path = os.path.join(MODEL_SAVE_PATH, 'spam_bert_final.pt')\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpamBERT(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "id": "4092325026fdc633",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:46.061025Z",
          "start_time": "2025-08-16T12:00:41.290458Z"
        },
        "id": "4092325026fdc633",
        "outputId": "15aa6b8e-715d-4d16-ae8c-8f15f3822340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from models.bert import tokenize_texts\n",
        "\n",
        "# Tokenize test data\n",
        "X_test_input_ids, X_test_attention_mask = tokenize_texts(test_df['text'].tolist(), tokenizer)\n",
        "y_test_tensor = torch.tensor(test_df['label'].values, dtype=torch.float32)\n",
        "\n",
        "# Move data to device\n",
        "X_test_input_ids = X_test_input_ids.to(device)\n",
        "X_test_attention_mask = X_test_attention_mask.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "print(f\"Test data prepared: {X_test_input_ids.shape[0]} samples\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data prepared: 606 samples\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "id": "8634e358623832cc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-16T12:00:47.003768Z",
          "start_time": "2025-08-16T12:00:46.209998Z"
        },
        "id": "8634e358623832cc",
        "outputId": "ae8d3feb-dd97-4426-b7c8-20a7fa989a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get model predictions using BERT tokenized inputs\n",
        "with torch.no_grad():\n",
        "    model_output = model(\n",
        "        input_ids=X_test_input_ids,\n",
        "        attention_mask=X_test_attention_mask\n",
        "    )\n",
        "    # If model returns a tuple, use the first element (typically the predictions)\n",
        "    if isinstance(model_output, tuple):\n",
        "        y_pred_probs = model_output[0]\n",
        "    else:\n",
        "        y_pred_probs = model_output\n",
        "\n",
        "    y_pred = (y_pred_probs > 0.5).float()\n",
        "\n",
        "print(f\"Model predictions computed for {len(y_pred)} samples\")\n",
        "print(f\"Predicted spam samples: {(y_pred == 1).sum().item()}\")\n",
        "print(f\"Predicted ham samples: {(y_pred == 0).sum().item()}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predictions computed for 606 samples\n",
            "Predicted spam samples: 194\n",
            "Predicted ham samples: 412\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "id": "400eb8fd7172eaa8",
      "metadata": {
        "id": "400eb8fd7172eaa8"
      },
      "source": [
        "#### LayerIntegratedGradients for BERT"
      ]
    },
    {
      "cell_type": "code",
      "id": "e402bab1",
      "metadata": {
        "id": "e402bab1",
        "outputId": "4eda36f4-6b24-4c08-b064-46299e33e3b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from explainability.BertExplanationMetrics import BertExplanationMetrics\n",
        "\n",
        "# Initialize the BERT explanation quality metrics calculator\n",
        "quality_evaluator = BertExplanationMetrics(model, tokenizer, device)\n",
        "\n",
        "print(\"BERT Explanation Quality Metrics Calculator initialized successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Explanation Quality Metrics Calculator initialized successfully!\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "id": "1b1f8032",
      "metadata": {
        "id": "1b1f8032",
        "outputId": "d0eb272e-a3aa-4169-ea00-5f90fd26933b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute explanation quality metrics using Integrated Gradients\n",
        "print(\"Computing explanation quality metrics using LayerIntegratedGradients...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "ig_results = []\n",
        "\n",
        "for (i, row) in test_df.iterrows():\n",
        "    text = row['text']\n",
        "    subject = row['subject']\n",
        "    try:\n",
        "        # Compute metrics using Integrated Gradients\n",
        "        metrics = quality_evaluator.evaluate_explanation_quality(\n",
        "            text,\n",
        "            subject=subject,\n",
        "            method='integrated_gradients',\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        metrics['sample_id'] = i + 1\n",
        "        metrics['text'] = subject\n",
        "        metrics['label'] = 'Spam' if row['label'] == 1 else 'Ham'\n",
        "\n",
        "        ig_results.append(metrics)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sample {i+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\nCompleted processing {len(ig_results)} samples with Integrated Gradients.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing explanation quality metrics using LayerIntegratedGradients...\n",
            "============================================================\n",
            "\n",
            "Completed processing 606 samples with Integrated Gradients.\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "metadata": {
        "id": "57da59032b26258e",
        "outputId": "34388e08-4c50-4cdd-ac69-7232502b0ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "cell_type": "code",
      "source": [
        "metrics_df = pd.DataFrame(ig_results)\n",
        "metrics_df"
      ],
      "id": "57da59032b26258e",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     auc_deletion  auc_insertion  comprehensiveness  jaccard_stability  \\\n",
              "0        0.451565       0.107920           0.005028           0.334127   \n",
              "1        0.615704       0.149823           0.500781           0.210714   \n",
              "2        0.429045       0.112967           0.004510           0.535714   \n",
              "3        0.183767       0.067226           0.005919           0.346825   \n",
              "4        0.218783       0.104998           0.005007           0.966667   \n",
              "..            ...            ...                ...                ...   \n",
              "601      0.594187       0.444710           0.564256           0.371825   \n",
              "602      0.846331       0.767668           0.049100           0.229762   \n",
              "603      0.755331       0.826747           0.008041           0.316270   \n",
              "604      0.787173       0.894576           0.001132           0.264683   \n",
              "605      0.857049       0.864517           0.066490           0.242460   \n",
              "\n",
              "          computation_time  sample_id  \\\n",
              "0   0 days 00:00:12.116649          1   \n",
              "1   0 days 00:00:12.005684          2   \n",
              "2   0 days 00:00:11.815992          3   \n",
              "3   0 days 00:00:11.916729          4   \n",
              "4   0 days 00:00:11.820961          5   \n",
              "..                     ...        ...   \n",
              "601 0 days 00:00:11.835178        602   \n",
              "602 0 days 00:00:12.085660        603   \n",
              "603 0 days 00:00:12.136452        604   \n",
              "604 0 days 00:00:13.493403        605   \n",
              "605 0 days 00:00:13.443245        606   \n",
              "\n",
              "                                                  text label  \n",
              "0    RE: Our friends the Palestinians, Our servants...   Ham  \n",
              "1    Re: Our friends the Palestinians, Our servants...   Ham  \n",
              "2                                     xine src package   Ham  \n",
              "3                                 Re: xine src package   Ham  \n",
              "4    Re: Our friends the Palestinians, Our servants...   Ham  \n",
              "..                                                 ...   ...  \n",
              "601                                              hurry  Spam  \n",
              "602                              [ILUG] WILSON  KAMELA  Spam  \n",
              "603  How to get 10,000 FREE hits per day to any web...  Spam  \n",
              "604                                Cannabis Difference  Spam  \n",
              "605                                            Faeries  Spam  \n",
              "\n",
              "[606 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bd39591-d0c3-49a4-bb36-0d56c6a43e0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auc_deletion</th>\n",
              "      <th>auc_insertion</th>\n",
              "      <th>comprehensiveness</th>\n",
              "      <th>jaccard_stability</th>\n",
              "      <th>computation_time</th>\n",
              "      <th>sample_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.451565</td>\n",
              "      <td>0.107920</td>\n",
              "      <td>0.005028</td>\n",
              "      <td>0.334127</td>\n",
              "      <td>0 days 00:00:12.116649</td>\n",
              "      <td>1</td>\n",
              "      <td>RE: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.615704</td>\n",
              "      <td>0.149823</td>\n",
              "      <td>0.500781</td>\n",
              "      <td>0.210714</td>\n",
              "      <td>0 days 00:00:12.005684</td>\n",
              "      <td>2</td>\n",
              "      <td>Re: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.429045</td>\n",
              "      <td>0.112967</td>\n",
              "      <td>0.004510</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0 days 00:00:11.815992</td>\n",
              "      <td>3</td>\n",
              "      <td>xine src package</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183767</td>\n",
              "      <td>0.067226</td>\n",
              "      <td>0.005919</td>\n",
              "      <td>0.346825</td>\n",
              "      <td>0 days 00:00:11.916729</td>\n",
              "      <td>4</td>\n",
              "      <td>Re: xine src package</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.218783</td>\n",
              "      <td>0.104998</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0 days 00:00:11.820961</td>\n",
              "      <td>5</td>\n",
              "      <td>Re: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>0.594187</td>\n",
              "      <td>0.444710</td>\n",
              "      <td>0.564256</td>\n",
              "      <td>0.371825</td>\n",
              "      <td>0 days 00:00:11.835178</td>\n",
              "      <td>602</td>\n",
              "      <td>hurry</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>0.846331</td>\n",
              "      <td>0.767668</td>\n",
              "      <td>0.049100</td>\n",
              "      <td>0.229762</td>\n",
              "      <td>0 days 00:00:12.085660</td>\n",
              "      <td>603</td>\n",
              "      <td>[ILUG] WILSON  KAMELA</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>0.755331</td>\n",
              "      <td>0.826747</td>\n",
              "      <td>0.008041</td>\n",
              "      <td>0.316270</td>\n",
              "      <td>0 days 00:00:12.136452</td>\n",
              "      <td>604</td>\n",
              "      <td>How to get 10,000 FREE hits per day to any web...</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>0.787173</td>\n",
              "      <td>0.894576</td>\n",
              "      <td>0.001132</td>\n",
              "      <td>0.264683</td>\n",
              "      <td>0 days 00:00:13.493403</td>\n",
              "      <td>605</td>\n",
              "      <td>Cannabis Difference</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>0.857049</td>\n",
              "      <td>0.864517</td>\n",
              "      <td>0.066490</td>\n",
              "      <td>0.242460</td>\n",
              "      <td>0 days 00:00:13.443245</td>\n",
              "      <td>606</td>\n",
              "      <td>Faeries</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>606 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bd39591-d0c3-49a4-bb36-0d56c6a43e0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bd39591-d0c3-49a4-bb36-0d56c6a43e0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bd39591-d0c3-49a4-bb36-0d56c6a43e0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b1702f4-0b64-419d-9ae1-c38633a72108\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b1702f4-0b64-419d-9ae1-c38633a72108')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b1702f4-0b64-419d-9ae1-c38633a72108 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_eb04d552-e5d5-499f-8146-d1e448b26ea6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb04d552-e5d5-499f-8146-d1e448b26ea6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 606,\n  \"fields\": [\n    {\n      \"column\": \"auc_deletion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23467892507684615,\n        \"min\": 0.08828972260888718,\n        \"max\": 0.9147141218555641,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.08828972260888718,\n          0.6617766718069713,\n          0.21311774966306984\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc_insertion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32707907546382853,\n        \"min\": 0.0,\n        \"max\": 0.9341416827269964,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.06232483837881993,\n          0.8482328876852989,\n          0.28698958989910106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1455536802690772,\n        \"min\": 3.0487775802612305e-05,\n        \"max\": 0.8491439819335938,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.00019432604312896729,\n          0.0717877745628357,\n          0.09205460175871849\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard_stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18624698181863308,\n        \"min\": 0.02222222222222222,\n        \"max\": 1.0,\n        \"num_unique_values\": 407,\n        \"samples\": [\n          0.7285714285714285,\n          0.8761904761904763,\n          0.3063492063492063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"computation_time\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 606,\n        \"samples\": [\n          \"0 days 00:00:12.002496\",\n          \"0 days 00:00:12.095412\",\n          \"0 days 00:00:11.526554\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 175,\n        \"min\": 1,\n        \"max\": 606,\n        \"num_unique_values\": 606,\n        \"samples\": [\n          573,\n          290,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 520,\n        \"samples\": [\n          \"Re: [zzzzteana] Funny News story #1\",\n          \"Iran Pushes UN Intervention Against US\",\n          \"Re: RH 8 no DMA for DVD drive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Spam\",\n          \"Ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_df.describe()"
      ],
      "metadata": {
        "id": "10zj9t61aBNK",
        "outputId": "482c2666-6685-492a-d773-d59a7c3a0d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "id": "10zj9t61aBNK",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       auc_deletion  auc_insertion  comprehensiveness  jaccard_stability  \\\n",
              "count    606.000000     606.000000         606.000000         606.000000   \n",
              "mean       0.476898       0.395897           0.092090           0.532393   \n",
              "std        0.234679       0.327079           0.145554           0.186247   \n",
              "min        0.088290       0.000000           0.000030           0.022222   \n",
              "25%        0.280918       0.099329           0.003196           0.396825   \n",
              "50%        0.392662       0.304443           0.018076           0.531349   \n",
              "75%        0.719355       0.830316           0.120473           0.677083   \n",
              "max        0.914714       0.934142           0.849144           1.000000   \n",
              "\n",
              "                computation_time  sample_id  \n",
              "count                        606  606.00000  \n",
              "mean   0 days 00:00:11.924757250  303.50000  \n",
              "std    0 days 00:00:01.247627005  175.08141  \n",
              "min       0 days 00:00:11.262604    1.00000  \n",
              "25%    0 days 00:00:11.775231750  152.25000  \n",
              "50%    0 days 00:00:11.849422500  303.50000  \n",
              "75%       0 days 00:00:11.944917  454.75000  \n",
              "max       0 days 00:00:41.811837  606.00000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35b66fe3-576b-4cc3-853a-500e117c6e3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auc_deletion</th>\n",
              "      <th>auc_insertion</th>\n",
              "      <th>comprehensiveness</th>\n",
              "      <th>jaccard_stability</th>\n",
              "      <th>computation_time</th>\n",
              "      <th>sample_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606</td>\n",
              "      <td>606.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.476898</td>\n",
              "      <td>0.395897</td>\n",
              "      <td>0.092090</td>\n",
              "      <td>0.532393</td>\n",
              "      <td>0 days 00:00:11.924757250</td>\n",
              "      <td>303.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.234679</td>\n",
              "      <td>0.327079</td>\n",
              "      <td>0.145554</td>\n",
              "      <td>0.186247</td>\n",
              "      <td>0 days 00:00:01.247627005</td>\n",
              "      <td>175.08141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.088290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0 days 00:00:11.262604</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.280918</td>\n",
              "      <td>0.099329</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>0.396825</td>\n",
              "      <td>0 days 00:00:11.775231750</td>\n",
              "      <td>152.25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.392662</td>\n",
              "      <td>0.304443</td>\n",
              "      <td>0.018076</td>\n",
              "      <td>0.531349</td>\n",
              "      <td>0 days 00:00:11.849422500</td>\n",
              "      <td>303.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.719355</td>\n",
              "      <td>0.830316</td>\n",
              "      <td>0.120473</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0 days 00:00:11.944917</td>\n",
              "      <td>454.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.914714</td>\n",
              "      <td>0.934142</td>\n",
              "      <td>0.849144</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0 days 00:00:41.811837</td>\n",
              "      <td>606.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35b66fe3-576b-4cc3-853a-500e117c6e3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35b66fe3-576b-4cc3-853a-500e117c6e3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35b66fe3-576b-4cc3-853a-500e117c6e3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-41914581-8a6d-461f-9845-292e0bac8039\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41914581-8a6d-461f-9845-292e0bac8039')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-41914581-8a6d-461f-9845-292e0bac8039 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"auc_deletion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.09656762750663,\n        \"min\": 0.08828972260888718,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.476898137852176,\n          0.3926617250378643,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc_insertion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.10757164964346,\n        \"min\": 0.0,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3958974392420282,\n          0.30444282238812825,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.19148629836462,\n        \"min\": 3.0487775802612305e-05,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0920900135015202,\n          0.018075749278068542,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard_stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.08455609268435,\n        \"min\": 0.02222222222222222,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5323930012048823,\n          0.5313492063492065,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"computation_time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0 days 00:00:11.924757250\",\n          \"0 days 00:00:11.849422500\",\n          \"606\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 218.1006213404329,\n        \"min\": 1.0,\n        \"max\": 606.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          606.0,\n          303.5,\n          454.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "349a6614",
      "metadata": {
        "id": "349a6614",
        "outputId": "a4a730ee-581f-4250-bb62-8451d734b077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute explanation quality metrics using Attention Heads\n",
        "print(\"Computing explanation quality metrics using Attention Heads...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "attention_results = []\n",
        "for (i, row) in test_df.iterrows():\n",
        "    text = row['text']\n",
        "    try:\n",
        "        # Compute metrics using Attention Weights\n",
        "        metrics = quality_evaluator.evaluate_explanation_quality(\n",
        "            text,\n",
        "            subject=row['subject'],\n",
        "            method='attention',\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        metrics['sample_id'] = i + 1\n",
        "        metrics['text'] = row['subject']\n",
        "        metrics['label'] = 'Spam' if row['label'] == 1 else 'Ham'\n",
        "\n",
        "        attention_results.append(metrics)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sample {i+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\nCompleted processing {len(attention_results)} samples with Attention Heads.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Evaluating explanation quality for text: 'Wannabe fathers ramp up testosterone'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3300 (lower is better)\n",
            "AUC-Insertion:    0.3721 (higher is better)\n",
            "Comprehensiveness: 0.0196 (higher is better)\n",
            "Jaccard Stability: 0.4921 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.031523\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Australia declares world's largest marine reserve'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5376 (lower is better)\n",
            "AUC-Insertion:    0.1682 (higher is better)\n",
            "Comprehensiveness: 0.1206 (higher is better)\n",
            "Jaccard Stability: 0.6619 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.032810\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Critical US satellites could be hacked'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2729 (lower is better)\n",
            "AUC-Insertion:    0.2359 (higher is better)\n",
            "Comprehensiveness: 0.0068 (higher is better)\n",
            "Jaccard Stability: 0.5298 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.990005\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Malicious code hidden in email software'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2459 (lower is better)\n",
            "AUC-Insertion:    0.3630 (higher is better)\n",
            "Comprehensiveness: 0.0727 (higher is better)\n",
            "Jaccard Stability: 0.6619 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.924508\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Monster molecule techniques win Chemistry Nobel'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3601 (lower is better)\n",
            "AUC-Insertion:    0.3039 (higher is better)\n",
            "Comprehensiveness: 0.0231 (higher is better)\n",
            "Jaccard Stability: 0.5587 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.947619\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'US use of lie detector tests criticised'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3487 (lower is better)\n",
            "AUC-Insertion:    0.1934 (higher is better)\n",
            "Comprehensiveness: 0.1255 (higher is better)\n",
            "Jaccard Stability: 0.7952 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.983820\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Fwd: [POLITICOS] Re: \"Bowling for Columbine,\" Opens This Friday'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3227 (lower is better)\n",
            "AUC-Insertion:    0.1772 (higher is better)\n",
            "Comprehensiveness: 0.0093 (higher is better)\n",
            "Jaccard Stability: 0.4821 (higher is better)\n",
            "Computation Time: 0 days 00:00:02.142548\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'dvd::rip on Red Hat 8.0?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2552 (lower is better)\n",
            "AUC-Insertion:    0.0532 (higher is better)\n",
            "Comprehensiveness: 0.0035 (higher is better)\n",
            "Jaccard Stability: 0.2579 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.155947\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: dvd::rip on Red Hat 8.0?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3248 (lower is better)\n",
            "AUC-Insertion:    0.0548 (higher is better)\n",
            "Comprehensiveness: 0.0146 (higher is better)\n",
            "Jaccard Stability: 0.5036 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.066025\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [SAdev] fully-public corpus of mail available '\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2827 (lower is better)\n",
            "AUC-Insertion:    0.0623 (higher is better)\n",
            "Comprehensiveness: 0.0027 (higher is better)\n",
            "Jaccard Stability: 0.3274 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.324731\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FC Sporadic for Wednesday, October 30, 2002'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3468 (lower is better)\n",
            "AUC-Insertion:    0.1797 (higher is better)\n",
            "Comprehensiveness: 0.0610 (higher is better)\n",
            "Jaccard Stability: 0.5964 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.614854\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Quicker and easier shopping with Tesco.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3892 (lower is better)\n",
            "AUC-Insertion:    0.2487 (higher is better)\n",
            "Comprehensiveness: 0.0882 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.965725\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Christmas is coming to all Ryanair passe'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7492 (lower is better)\n",
            "AUC-Insertion:    0.1207 (higher is better)\n",
            "Comprehensiveness: 0.3207 (higher is better)\n",
            "Jaccard Stability: 0.5536 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.688849\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'HTTP: The Definitive Guide'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6899 (lower is better)\n",
            "AUC-Insertion:    0.8892 (higher is better)\n",
            "Comprehensiveness: 0.2547 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.658492\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Try our new Apparel store and get a 30 dollar thank you'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7210 (lower is better)\n",
            "AUC-Insertion:    0.8330 (higher is better)\n",
            "Comprehensiveness: 0.0991 (higher is better)\n",
            "Jaccard Stability: 0.4659 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.028906\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'iSilo announcements (November 8, 2002)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3134 (lower is better)\n",
            "AUC-Insertion:    0.3717 (higher is better)\n",
            "Comprehensiveness: 0.0052 (higher is better)\n",
            "Jaccard Stability: 0.4187 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.186195\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'EFFector 15.35: ALERT UPDATE: Urge Your Representative to Co-Sponsor the DMCRA!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4520 (lower is better)\n",
            "AUC-Insertion:    0.7610 (higher is better)\n",
            "Comprehensiveness: 0.1206 (higher is better)\n",
            "Jaccard Stability: 0.4286 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.723669\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Espial TV Web Seminar Series - Register Today!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2614 (lower is better)\n",
            "AUC-Insertion:    0.2485 (higher is better)\n",
            "Comprehensiveness: 0.1658 (higher is better)\n",
            "Jaccard Stability: 0.2897 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.079718\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [Razor-users] razor-revoke, trust levels, slashdot is not  spam.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3212 (lower is better)\n",
            "AUC-Insertion:    0.0588 (higher is better)\n",
            "Comprehensiveness: 0.0052 (higher is better)\n",
            "Jaccard Stability: 0.2937 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.308780\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'CuteFTP Pro 3.0 Released!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4268 (lower is better)\n",
            "AUC-Insertion:    0.0826 (higher is better)\n",
            "Comprehensiveness: 0.0252 (higher is better)\n",
            "Jaccard Stability: 0.3075 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.362807\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Software you can be thankful for'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7055 (lower is better)\n",
            "AUC-Insertion:    0.8930 (higher is better)\n",
            "Comprehensiveness: 0.5156 (higher is better)\n",
            "Jaccard Stability: 1.0000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.558692\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'More Freebies with Ryanair.com'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6211 (lower is better)\n",
            "AUC-Insertion:    0.1901 (higher is better)\n",
            "Comprehensiveness: 0.7455 (higher is better)\n",
            "Jaccard Stability: 0.2619 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.436629\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] An announcement'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2999 (lower is better)\n",
            "AUC-Insertion:    0.1963 (higher is better)\n",
            "Comprehensiveness: 0.1815 (higher is better)\n",
            "Jaccard Stability: 0.4127 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.066204\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] An announcement'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.741062\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Cost price Guinness, Budweiser and selected spirits at tesco.ie'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7449 (lower is better)\n",
            "AUC-Insertion:    0.9021 (higher is better)\n",
            "Comprehensiveness: 0.0149 (higher is better)\n",
            "Jaccard Stability: 0.4286 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.517335\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Christians struck by lightning...'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.746158\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] An announcement'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8762 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.753902\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Daft crimes etc'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.735729\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] spam...'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3670 (lower is better)\n",
            "AUC-Insertion:    0.2179 (higher is better)\n",
            "Comprehensiveness: 0.0308 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.152715\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [SAtalk] Blocking ?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4810 (lower is better)\n",
            "AUC-Insertion:    0.0569 (higher is better)\n",
            "Comprehensiveness: 0.0515 (higher is better)\n",
            "Jaccard Stability: 0.3671 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.248564\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] Funny News story #1'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7250 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.728094\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] Time sync on dialup'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2718 (lower is better)\n",
            "AUC-Insertion:    0.1365 (higher is better)\n",
            "Comprehensiveness: 0.0041 (higher is better)\n",
            "Jaccard Stability: 0.6619 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.958645\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: Men et Toil'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5791 (lower is better)\n",
            "AUC-Insertion:    0.0629 (higher is better)\n",
            "Comprehensiveness: 0.4151 (higher is better)\n",
            "Jaccard Stability: 0.5536 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.041072\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [Spambayes] Current version'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1213 (lower is better)\n",
            "AUC-Insertion:    0.0539 (higher is better)\n",
            "Comprehensiveness: 0.0017 (higher is better)\n",
            "Jaccard Stability: 0.2964 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.239441\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG-Social] spam...'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3018 (lower is better)\n",
            "AUC-Insertion:    0.0953 (higher is better)\n",
            "Comprehensiveness: 0.0022 (higher is better)\n",
            "Jaccard Stability: 0.5298 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.033898\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: Are bad developer libraries the problem with M$ software?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2982 (lower is better)\n",
            "AUC-Insertion:    0.0993 (higher is better)\n",
            "Comprehensiveness: 0.0049 (higher is better)\n",
            "Jaccard Stability: 0.3929 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.110507\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: Are bad developer libraries the problem with M$ software?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2622 (lower is better)\n",
            "AUC-Insertion:    0.0819 (higher is better)\n",
            "Comprehensiveness: 0.0039 (higher is better)\n",
            "Jaccard Stability: 0.3865 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.154536\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [Spambayes] Current version'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1272 (lower is better)\n",
            "AUC-Insertion:    0.0652 (higher is better)\n",
            "Comprehensiveness: 0.0022 (higher is better)\n",
            "Jaccard Stability: 0.3353 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.065057\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [Spambayes] New web training interface for pop3proxy'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4114 (lower is better)\n",
            "AUC-Insertion:    0.1205 (higher is better)\n",
            "Comprehensiveness: 0.0131 (higher is better)\n",
            "Jaccard Stability: 0.3571 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.041614\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Search for missing lynx'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.730811\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Animal attraction for sale'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.725278\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: More Japanese stuff'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.729600\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] NFS slowness with SuSE 8.1'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3641 (lower is better)\n",
            "AUC-Insertion:    0.0546 (higher is better)\n",
            "Comprehensiveness: 0.0060 (higher is better)\n",
            "Jaccard Stability: 0.6190 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.077852\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [Spambayes] Guidance re pickles versus DB for Outlook'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1710 (lower is better)\n",
            "AUC-Insertion:    0.0578 (higher is better)\n",
            "Comprehensiveness: 0.0019 (higher is better)\n",
            "Jaccard Stability: 0.7857 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.543491\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [Spambayes] Guidance re pickles versus DB for Outlook'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1812 (lower is better)\n",
            "AUC-Insertion:    0.0606 (higher is better)\n",
            "Comprehensiveness: 0.0035 (higher is better)\n",
            "Jaccard Stability: 0.3373 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.061675\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Apple Store eNews : November 2002'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2270 (lower is better)\n",
            "AUC-Insertion:    0.2489 (higher is better)\n",
            "Comprehensiveness: 0.0163 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.963052\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'IMHO 1.10 - Chomsky, Fashion, and Segways'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2271 (lower is better)\n",
            "AUC-Insertion:    0.0975 (higher is better)\n",
            "Comprehensiveness: 0.0074 (higher is better)\n",
            "Jaccard Stability: 0.3750 (higher is better)\n",
            "Computation Time: 0 days 00:00:02.276926\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Neat Net Tricks Standard Issue #138, December 1, 2002'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2423 (lower is better)\n",
            "AUC-Insertion:    0.0942 (higher is better)\n",
            "Comprehensiveness: 0.0010 (higher is better)\n",
            "Jaccard Stability: 0.4619 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.764880\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: UK rich-b*st*rds TV alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.6968 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.724884\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8095 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.728177\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7762 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.722761\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.730582\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Hit a Bigfoot in Maine?  You own it!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.729487\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] RE: Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7345 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727721\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: RE: [zzzzteana] Sitting Bull Ã¼ber alles [Long]'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.732100\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Ray Wallace'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.733737\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] FWD (SK) Re: Quotation wanted [pseudoscience - a skeptic's view]'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.726851\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[IIU] Postcards from Planet Google *LONG*'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2565 (lower is better)\n",
            "AUC-Insertion:    0.1814 (higher is better)\n",
            "Comprehensiveness: 0.0181 (higher is better)\n",
            "Jaccard Stability: 0.3036 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.864212\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] eircom mail'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3020 (lower is better)\n",
            "AUC-Insertion:    0.0582 (higher is better)\n",
            "Comprehensiveness: 0.0008 (higher is better)\n",
            "Jaccard Stability: 0.3730 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.085167\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] FWD [UASR][TheHickmanReport] Jets Attempt to Intercept 'Contrail''\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.737407\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] FWD (SK) Japanese tentacle porn [was Re: Com'on Baby, Lite my Fire]'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727419\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] RE: Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.721914\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Ray Wallace (1919-2002)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8583 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.722248\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: Mercedes-Benz G55'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4217 (lower is better)\n",
            "AUC-Insertion:    0.3950 (higher is better)\n",
            "Comprehensiveness: 0.3635 (higher is better)\n",
            "Jaccard Stability: 0.5310 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.163136\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[use Perl] Stories for 2002-12-02'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2903 (lower is better)\n",
            "AUC-Insertion:    0.2266 (higher is better)\n",
            "Comprehensiveness: 0.0005 (higher is better)\n",
            "Jaccard Stability: 0.5631 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.035214\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7762 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.728911\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.723203\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: alsa:bass and treble'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3085 (lower is better)\n",
            "AUC-Insertion:    0.0977 (higher is better)\n",
            "Comprehensiveness: 0.0038 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.956171\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] re: Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7095 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.726121\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: Mercedes-Benz G55'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5371 (lower is better)\n",
            "AUC-Insertion:    0.1622 (higher is better)\n",
            "Comprehensiveness: 0.1062 (higher is better)\n",
            "Jaccard Stability: 0.4881 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.972696\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Fire fighters'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9429 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.738872\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Re: Argh!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7250 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.725006\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Amazingly Accurate (For a Sunday Morning)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727797\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7429 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727681\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8429 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727721\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.723598\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7095 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.726554\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [ILUG] eircom mail'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2509 (lower is better)\n",
            "AUC-Insertion:    0.0665 (higher is better)\n",
            "Comprehensiveness: 0.0010 (higher is better)\n",
            "Jaccard Stability: 0.3909 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.113226\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Re: Archer-UK TV Alert'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727073\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Fly free'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4151 (lower is better)\n",
            "AUC-Insertion:    0.1949 (higher is better)\n",
            "Comprehensiveness: 0.0236 (higher is better)\n",
            "Jaccard Stability: 0.4341 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.103676\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [zzzzteana] FWD (SK) Japanese tentacle porn [was Re: Com'on Baby, Lite my Fire]'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7857 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.741308\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Man uses cell phone to take snap inside schoolgirl's skirt'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3664 (lower is better)\n",
            "AUC-Insertion:    0.4043 (higher is better)\n",
            "Comprehensiveness: 0.3780 (higher is better)\n",
            "Jaccard Stability: 0.4405 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.084254\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'CuteFTP exclusive: OmniPage Pro with DNS'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7359 (lower is better)\n",
            "AUC-Insertion:    0.6456 (higher is better)\n",
            "Comprehensiveness: 0.0328 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.464353\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] University boom creates era of sexual tolerance'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.726660\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] More Michael Jackson wierdness'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7540 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.731334\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [zzzzteana] Re: FWD (ExT) USA more popular than ever in Britain'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2046 (lower is better)\n",
            "AUC-Insertion:    0.0624 (higher is better)\n",
            "Comprehensiveness: 0.0014 (higher is better)\n",
            "Jaccard Stability: 0.4266 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.110112\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] must see'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.730123\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] dual keyboards'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3581 (lower is better)\n",
            "AUC-Insertion:    0.1272 (higher is better)\n",
            "Comprehensiveness: 0.0034 (higher is better)\n",
            "Jaccard Stability: 0.5476 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.981722\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Linux Install'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2112 (lower is better)\n",
            "AUC-Insertion:    0.0685 (higher is better)\n",
            "Comprehensiveness: 0.0064 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.103820\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [ILUG] Linux Install'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2483 (lower is better)\n",
            "AUC-Insertion:    0.2053 (higher is better)\n",
            "Comprehensiveness: 0.0016 (higher is better)\n",
            "Jaccard Stability: 0.4758 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.048597\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'RE: [ILUG] NVIDIA and Debian Woody'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2313 (lower is better)\n",
            "AUC-Insertion:    0.0587 (higher is better)\n",
            "Comprehensiveness: 0.0035 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.574610\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] By the way'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.9667 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.727126\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] PostgreSQL vs. MySQL'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2022 (lower is better)\n",
            "AUC-Insertion:    0.1066 (higher is better)\n",
            "Comprehensiveness: 0.0027 (higher is better)\n",
            "Jaccard Stability: 0.4940 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.052074\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: By the way'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.724936\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Bomb Ikea'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.7917 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.722888\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] dual keyboards'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4685 (lower is better)\n",
            "AUC-Insertion:    0.0595 (higher is better)\n",
            "Comprehensiveness: 0.0008 (higher is better)\n",
            "Jaccard Stability: 0.3024 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.185968\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Re: Bomb Ikea'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.726795\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[zzzzteana] Surfing the tube'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3561 (lower is better)\n",
            "AUC-Insertion:    0.2862 (higher is better)\n",
            "Comprehensiveness: 0.3513 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.728012\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] Linux Install'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1507 (lower is better)\n",
            "AUC-Insertion:    0.0537 (higher is better)\n",
            "Comprehensiveness: 0.0025 (higher is better)\n",
            "Jaccard Stability: 0.3190 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.228166\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] Linux Install'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2415 (lower is better)\n",
            "AUC-Insertion:    0.0918 (higher is better)\n",
            "Comprehensiveness: 0.0055 (higher is better)\n",
            "Jaccard Stability: 0.6063 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.001393\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[Spambayes] Re: New Application of SpamBayesian tech?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1669 (lower is better)\n",
            "AUC-Insertion:    0.0670 (higher is better)\n",
            "Comprehensiveness: 0.0047 (higher is better)\n",
            "Jaccard Stability: 0.4996 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.114191\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: [ILUG] Linux Install'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2704 (lower is better)\n",
            "AUC-Insertion:    0.0531 (higher is better)\n",
            "Comprehensiveness: 0.0027 (higher is better)\n",
            "Jaccard Stability: 0.3770 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.150300\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: ActiveBuddy'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.1636 (lower is better)\n",
            "AUC-Insertion:    0.0694 (higher is better)\n",
            "Comprehensiveness: 0.0039 (higher is better)\n",
            "Jaccard Stability: 0.5492 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.074822\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'å…è²»ç„¡é™æ¬¡ä»»æ‰“ä¸­æ¸¯é•·é€”é›»è©±'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7779 (lower is better)\n",
            "AUC-Insertion:    0.9125 (higher is better)\n",
            "Comprehensiveness: 0.1147 (higher is better)\n",
            "Jaccard Stability: 0.7857 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.747002\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'The Flight to Safety is Upon Us'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7324 (lower is better)\n",
            "AUC-Insertion:    0.8939 (higher is better)\n",
            "Comprehensiveness: 0.0256 (higher is better)\n",
            "Jaccard Stability: 0.5774 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.087896\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Low cost quality conference calls'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7637 (lower is better)\n",
            "AUC-Insertion:    0.8363 (higher is better)\n",
            "Comprehensiveness: 0.1413 (higher is better)\n",
            "Jaccard Stability: 0.5964 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.169301\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 're:æˆ‘çŸ¥é“ä½ éœ€è¦æ›´å¤šæ©Ÿæœƒ,ä¸€ï¿½ ä¾†å§!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7610 (lower is better)\n",
            "AUC-Insertion:    0.9238 (higher is better)\n",
            "Comprehensiveness: 0.1422 (higher is better)\n",
            "Jaccard Stability: 0.4171 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.775263\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] MICHAEL ! ilug'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7050 (lower is better)\n",
            "AUC-Insertion:    0.9112 (higher is better)\n",
            "Comprehensiveness: 0.0052 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.597272\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'WARNING: Your computer may contain a virus!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7261 (lower is better)\n",
            "AUC-Insertion:    0.8525 (higher is better)\n",
            "Comprehensiveness: 0.0306 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.179057\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Funds Investment'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7850 (lower is better)\n",
            "AUC-Insertion:    0.8676 (higher is better)\n",
            "Comprehensiveness: 0.0488 (higher is better)\n",
            "Jaccard Stability: 0.4980 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.340924\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[WM] ï¿½zï¿½r dileriz'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7991 (lower is better)\n",
            "AUC-Insertion:    0.7338 (higher is better)\n",
            "Comprehensiveness: 0.0531 (higher is better)\n",
            "Jaccard Stability: 0.3294 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.072939\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 're:æƒ³è¦è‡´å¯Œ,ä½ é‚„è¦ç­‰å¤šä¹…'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7541 (lower is better)\n",
            "AUC-Insertion:    0.9035 (higher is better)\n",
            "Comprehensiveness: 0.0972 (higher is better)\n",
            "Jaccard Stability: 0.7774 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.706927\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '3 Cd Package: 300 Million Email Addresses + 1.5 Mil Fax Numbers $99.95'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7863 (lower is better)\n",
            "AUC-Insertion:    0.8435 (higher is better)\n",
            "Comprehensiveness: 0.0229 (higher is better)\n",
            "Jaccard Stability: 0.2976 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.660720\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'NEED TO FIND SOMETHING?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7571 (lower is better)\n",
            "AUC-Insertion:    0.9306 (higher is better)\n",
            "Comprehensiveness: 0.0437 (higher is better)\n",
            "Jaccard Stability: 0.7762 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.692469\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Here is the information you requested'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6985 (lower is better)\n",
            "AUC-Insertion:    0.8635 (higher is better)\n",
            "Comprehensiveness: 0.1730 (higher is better)\n",
            "Jaccard Stability: 0.2440 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.124030\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'fwd:  NORTON SYSTEMWORKS CLEARANCE SALE_ONLY $29.99 7126kyiK0-697yFCQ4277rqZm-24'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6388 (lower is better)\n",
            "AUC-Insertion:    0.8513 (higher is better)\n",
            "Comprehensiveness: 0.0530 (higher is better)\n",
            "Jaccard Stability: 0.4921 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.124948\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'May I have a moment of your Time PLEASE'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8425 (lower is better)\n",
            "AUC-Insertion:    0.8862 (higher is better)\n",
            "Comprehensiveness: 0.1190 (higher is better)\n",
            "Jaccard Stability: 0.3810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.225194\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Membership Status Notification'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7534 (lower is better)\n",
            "AUC-Insertion:    0.9070 (higher is better)\n",
            "Comprehensiveness: 0.0505 (higher is better)\n",
            "Jaccard Stability: 0.7286 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.060181\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'zzzz,Hello'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7210 (lower is better)\n",
            "AUC-Insertion:    0.8854 (higher is better)\n",
            "Comprehensiveness: 0.0166 (higher is better)\n",
            "Jaccard Stability: 0.3750 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.081263\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] ASSISTANCE'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7657 (lower is better)\n",
            "AUC-Insertion:    0.9061 (higher is better)\n",
            "Comprehensiveness: 0.0140 (higher is better)\n",
            "Jaccard Stability: 0.3393 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.586672\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Best Long Distance On the Net - 3.9 Cents With No Monthly Fees'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6497 (lower is better)\n",
            "AUC-Insertion:    0.8808 (higher is better)\n",
            "Comprehensiveness: 0.3001 (higher is better)\n",
            "Jaccard Stability: 0.4821 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.069682\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Friend, Copy ANY DVD or Playstation Game with this software......'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4771 (lower is better)\n",
            "AUC-Insertion:    0.4825 (higher is better)\n",
            "Comprehensiveness: 0.1855 (higher is better)\n",
            "Jaccard Stability: 0.3175 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.250507\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Don't get caught by rising interest rates.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7087 (lower is better)\n",
            "AUC-Insertion:    0.7609 (higher is better)\n",
            "Comprehensiveness: 0.0197 (higher is better)\n",
            "Jaccard Stability: 0.4552 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.239367\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'New Stock Pick: BBAN - Last Pick UP 309%.......................................... gsg'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8061 (lower is better)\n",
            "AUC-Insertion:    0.8180 (higher is better)\n",
            "Comprehensiveness: 0.0743 (higher is better)\n",
            "Jaccard Stability: 0.7679 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.683945\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Fwd: Norton makes the BEST software available, now ONLY $29.99! 32053'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7378 (lower is better)\n",
            "AUC-Insertion:    0.7080 (higher is better)\n",
            "Comprehensiveness: 0.0487 (higher is better)\n",
            "Jaccard Stability: 0.6024 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.172086\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'fwd:  NORTON SYSTEMWORKS CLEARANCE SALE!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6273 (lower is better)\n",
            "AUC-Insertion:    0.8830 (higher is better)\n",
            "Comprehensiveness: 0.0028 (higher is better)\n",
            "Jaccard Stability: 0.8333 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.077237\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Toners and inkjet cartridges for less....          BSJMCOIK'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7789 (lower is better)\n",
            "AUC-Insertion:    0.8886 (higher is better)\n",
            "Comprehensiveness: 0.1171 (higher is better)\n",
            "Jaccard Stability: 0.4087 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.111667\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'The Best Just Got Better'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8447 (lower is better)\n",
            "AUC-Insertion:    0.8376 (higher is better)\n",
            "Comprehensiveness: 0.1228 (higher is better)\n",
            "Jaccard Stability: 0.4147 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.438825\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] HELLO'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7663 (lower is better)\n",
            "AUC-Insertion:    0.8907 (higher is better)\n",
            "Comprehensiveness: 0.0705 (higher is better)\n",
            "Jaccard Stability: 0.3369 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.376003\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] HELLO'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7909 (lower is better)\n",
            "AUC-Insertion:    0.8719 (higher is better)\n",
            "Comprehensiveness: 0.0446 (higher is better)\n",
            "Jaccard Stability: 0.5857 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.401801\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Get on the Bus.. gbvzzzz'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7242 (lower is better)\n",
            "AUC-Insertion:    0.9076 (higher is better)\n",
            "Comprehensiveness: 0.0808 (higher is better)\n",
            "Jaccard Stability: 0.7381 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.964296\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] AWARD NOTIFICATION'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8144 (lower is better)\n",
            "AUC-Insertion:    0.8763 (higher is better)\n",
            "Comprehensiveness: 0.1056 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.367250\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'you don't satisfy me               FGTPRIL'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7429 (lower is better)\n",
            "AUC-Insertion:    0.8845 (higher is better)\n",
            "Comprehensiveness: 0.0567 (higher is better)\n",
            "Jaccard Stability: 0.4881 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.006289\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: zzzz@spamassassin.taint.org'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7058 (lower is better)\n",
            "AUC-Insertion:    0.8630 (higher is better)\n",
            "Comprehensiveness: 0.0486 (higher is better)\n",
            "Jaccard Stability: 0.3690 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.452197\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'English Well for you?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6085 (lower is better)\n",
            "AUC-Insertion:    0.8034 (higher is better)\n",
            "Comprehensiveness: 0.2059 (higher is better)\n",
            "Jaccard Stability: 0.4464 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.225972\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Introducing HGH: The Most Powerful Anti-Obesity Drug Ever'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7974 (lower is better)\n",
            "AUC-Insertion:    0.9014 (higher is better)\n",
            "Comprehensiveness: 0.0753 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.103869\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Introducing Chase Platinum for Students with a 0% Introductory APR'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5873 (lower is better)\n",
            "AUC-Insertion:    0.8825 (higher is better)\n",
            "Comprehensiveness: 0.1262 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.988851\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Never pay eBay listing fees again!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6792 (lower is better)\n",
            "AUC-Insertion:    0.8766 (higher is better)\n",
            "Comprehensiveness: 0.0267 (higher is better)\n",
            "Jaccard Stability: 0.3353 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.861826\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Last time you spent $25 did u make $100,000,s? Well this time you will. wju'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6999 (lower is better)\n",
            "AUC-Insertion:    0.8582 (higher is better)\n",
            "Comprehensiveness: 0.0783 (higher is better)\n",
            "Jaccard Stability: 0.2500 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.689316\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: Super CHARGE your desktop or laptop today!     17639'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7624 (lower is better)\n",
            "AUC-Insertion:    0.8758 (higher is better)\n",
            "Comprehensiveness: 0.0861 (higher is better)\n",
            "Jaccard Stability: 0.3909 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.295743\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Friend,Instantly Copy ANY DVD or Playstation Game with this software......'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4263 (lower is better)\n",
            "AUC-Insertion:    0.5229 (higher is better)\n",
            "Comprehensiveness: 0.1665 (higher is better)\n",
            "Jaccard Stability: 0.2897 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.257742\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Impaired Risk Case of the Month'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8288 (lower is better)\n",
            "AUC-Insertion:    0.9032 (higher is better)\n",
            "Comprehensiveness: 0.0990 (higher is better)\n",
            "Jaccard Stability: 0.5313 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.074513\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ADV: Extended Auto Warranties Here hvgxs'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5562 (lower is better)\n",
            "AUC-Insertion:    0.9230 (higher is better)\n",
            "Comprehensiveness: 0.2157 (higher is better)\n",
            "Jaccard Stability: 0.7917 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.685097\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FREE WebBook Publishing Software - Download NOW!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6916 (lower is better)\n",
            "AUC-Insertion:    0.9204 (higher is better)\n",
            "Comprehensiveness: 0.0951 (higher is better)\n",
            "Jaccard Stability: 0.5079 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.119878\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'found a secret link   ADV'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7521 (lower is better)\n",
            "AUC-Insertion:    0.9040 (higher is better)\n",
            "Comprehensiveness: 0.0571 (higher is better)\n",
            "Jaccard Stability: 0.6619 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.974143\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'fwd:  SYSTEMWORKS CLEARANCE SALE_ONLY $29.99'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5909 (lower is better)\n",
            "AUC-Insertion:    0.8743 (higher is better)\n",
            "Comprehensiveness: 0.0124 (higher is better)\n",
            "Jaccard Stability: 0.4933 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.027338\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'PROTECT YOUR INFORMATION AND YOUR COMPUTER'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6299 (lower is better)\n",
            "AUC-Insertion:    0.8936 (higher is better)\n",
            "Comprehensiveness: 0.3659 (higher is better)\n",
            "Jaccard Stability: 0.3611 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.056963\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'zzzz, do we have your money?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7518 (lower is better)\n",
            "AUC-Insertion:    0.8949 (higher is better)\n",
            "Comprehensiveness: 0.0601 (higher is better)\n",
            "Jaccard Stability: 0.5984 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.132913\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'A revolution in the PC world has arrived.          RSIRTR'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7663 (lower is better)\n",
            "AUC-Insertion:    0.8458 (higher is better)\n",
            "Comprehensiveness: 0.0681 (higher is better)\n",
            "Jaccard Stability: 0.4127 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.278197\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Slim Factors - A totally new approach to weight loss'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8301 (lower is better)\n",
            "AUC-Insertion:    0.9042 (higher is better)\n",
            "Comprehensiveness: 0.0397 (higher is better)\n",
            "Jaccard Stability: 0.5476 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.054229\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] Claim Your $25 Kmart Gift Card'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4477 (lower is better)\n",
            "AUC-Insertion:    0.7185 (higher is better)\n",
            "Comprehensiveness: 0.1757 (higher is better)\n",
            "Jaccard Stability: 0.6107 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.987404\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Lease Deal'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7391 (lower is better)\n",
            "AUC-Insertion:    0.9135 (higher is better)\n",
            "Comprehensiveness: 0.1122 (higher is better)\n",
            "Jaccard Stability: 0.9000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.592985\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Not too old to put out!                   26792'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3863 (lower is better)\n",
            "AUC-Insertion:    0.6933 (higher is better)\n",
            "Comprehensiveness: 0.5908 (higher is better)\n",
            "Jaccard Stability: 0.4048 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.001135\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Unleash your PC's Multimedia POWER at 70% off retail!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7036 (lower is better)\n",
            "AUC-Insertion:    0.8273 (higher is better)\n",
            "Comprehensiveness: 0.0725 (higher is better)\n",
            "Jaccard Stability: 0.2718 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.138465\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Definitely the answer many have been waiting for!!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8386 (lower is better)\n",
            "AUC-Insertion:    0.8691 (higher is better)\n",
            "Comprehensiveness: 0.1055 (higher is better)\n",
            "Jaccard Stability: 0.5060 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.069235\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Shipment Status'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6801 (lower is better)\n",
            "AUC-Insertion:    0.8862 (higher is better)\n",
            "Comprehensiveness: 0.0206 (higher is better)\n",
            "Jaccard Stability: 0.4742 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.281808\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '5% Guaranteed for Eight Years'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7252 (lower is better)\n",
            "AUC-Insertion:    0.9143 (higher is better)\n",
            "Comprehensiveness: 0.0290 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.020441\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Collect Your Money! Time:1:30:33 AM'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8218 (lower is better)\n",
            "AUC-Insertion:    0.9120 (higher is better)\n",
            "Comprehensiveness: 0.2024 (higher is better)\n",
            "Jaccard Stability: 0.3988 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.134260\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Re: This is NO JOKE! Speed up your CPU for under $30!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7731 (lower is better)\n",
            "AUC-Insertion:    0.7696 (higher is better)\n",
            "Comprehensiveness: 0.2816 (higher is better)\n",
            "Jaccard Stability: 0.3492 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.303299\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Hgh: safe and effective release of your own growth hormone!30543'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7294 (lower is better)\n",
            "AUC-Insertion:    0.9215 (higher is better)\n",
            "Comprehensiveness: 0.0515 (higher is better)\n",
            "Jaccard Stability: 0.5452 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.016055\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re:[1]Save over $70 on this exquisite software suite. FTS'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7959 (lower is better)\n",
            "AUC-Insertion:    0.8494 (higher is better)\n",
            "Comprehensiveness: 0.1027 (higher is better)\n",
            "Jaccard Stability: 0.4659 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.281393\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Email marketing info'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8921 (lower is better)\n",
            "AUC-Insertion:    0.0000 (higher is better)\n",
            "Comprehensiveness: 0.0786 (higher is better)\n",
            "Jaccard Stability: 1.0000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.495906\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FORTUNE 500 WORK AT HOME REPS NEEDED!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8934 (lower is better)\n",
            "AUC-Insertion:    0.9155 (higher is better)\n",
            "Comprehensiveness: 0.0119 (higher is better)\n",
            "Jaccard Stability: 0.4738 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.033305\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: What a night!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8270 (lower is better)\n",
            "AUC-Insertion:    0.8543 (higher is better)\n",
            "Comprehensiveness: 0.0398 (higher is better)\n",
            "Jaccard Stability: 0.4048 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.057959\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FREE Health Insurance Quotes'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8522 (lower is better)\n",
            "AUC-Insertion:    0.9010 (higher is better)\n",
            "Comprehensiveness: 0.0154 (higher is better)\n",
            "Jaccard Stability: 0.6107 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.972225\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] Lose 22.5lbs in 3 weeks!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6374 (lower is better)\n",
            "AUC-Insertion:    0.7107 (higher is better)\n",
            "Comprehensiveness: 0.1617 (higher is better)\n",
            "Jaccard Stability: 0.3329 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.989582\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Funds Investment'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7857 (lower is better)\n",
            "AUC-Insertion:    0.8652 (higher is better)\n",
            "Comprehensiveness: 0.0495 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.332881\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Funds Investment'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7857 (lower is better)\n",
            "AUC-Insertion:    0.8652 (higher is better)\n",
            "Comprehensiveness: 0.0495 (higher is better)\n",
            "Jaccard Stability: 0.5155 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.334039\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Adv: Mortgage Quotes Fast Online, No Cost'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8449 (lower is better)\n",
            "AUC-Insertion:    0.9195 (higher is better)\n",
            "Comprehensiveness: 0.0095 (higher is better)\n",
            "Jaccard Stability: 0.4524 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.302259\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'You have been hand selected... Free Info!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5568 (lower is better)\n",
            "AUC-Insertion:    0.8600 (higher is better)\n",
            "Comprehensiveness: 0.3126 (higher is better)\n",
            "Jaccard Stability: 0.4048 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.046958\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: Ink Prices Got You Down?              11956'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6522 (lower is better)\n",
            "AUC-Insertion:    0.8958 (higher is better)\n",
            "Comprehensiveness: 0.1962 (higher is better)\n",
            "Jaccard Stability: 0.4405 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.074091\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'One Sale - Three Commission Streams'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8602 (lower is better)\n",
            "AUC-Insertion:    0.8961 (higher is better)\n",
            "Comprehensiveness: 0.0078 (higher is better)\n",
            "Jaccard Stability: 0.2579 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.232727\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'If You Dont... Your Competition Will!              7377'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8364 (lower is better)\n",
            "AUC-Insertion:    0.9015 (higher is better)\n",
            "Comprehensiveness: 0.0328 (higher is better)\n",
            "Jaccard Stability: 0.5413 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.054734\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'zzzz, do we have your money?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7518 (lower is better)\n",
            "AUC-Insertion:    0.8949 (higher is better)\n",
            "Comprehensiveness: 0.0601 (higher is better)\n",
            "Jaccard Stability: 0.5159 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.133707\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Garden Ornaments | mvcmv'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6001 (lower is better)\n",
            "AUC-Insertion:    0.8678 (higher is better)\n",
            "Comprehensiveness: 0.0864 (higher is better)\n",
            "Jaccard Stability: 0.4579 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.127111\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'private'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7832 (lower is better)\n",
            "AUC-Insertion:    0.9110 (higher is better)\n",
            "Comprehensiveness: 0.0274 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.229608\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'This one will make you money  9/20/02 11:34:52 PM'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7296 (lower is better)\n",
            "AUC-Insertion:    0.9075 (higher is better)\n",
            "Comprehensiveness: 0.2337 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.047653\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: girls'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8213 (lower is better)\n",
            "AUC-Insertion:    0.9010 (higher is better)\n",
            "Comprehensiveness: 0.0364 (higher is better)\n",
            "Jaccard Stability: 0.7095 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.165902\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[WM] greencard 2004 ï¿½ekiliï¿½ini kaï¿½ï¿½rmayï¿½n'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7241 (lower is better)\n",
            "AUC-Insertion:    0.6794 (higher is better)\n",
            "Comprehensiveness: 0.0716 (higher is better)\n",
            "Jaccard Stability: 0.4563 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.005283\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Re: PROTECT YOUR COMPUTER,YOU NEED SYSTEMWORKS!    COXR'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7155 (lower is better)\n",
            "AUC-Insertion:    0.8476 (higher is better)\n",
            "Comprehensiveness: 0.0159 (higher is better)\n",
            "Jaccard Stability: 0.3175 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.177902\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] Low Price Tobacco'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4779 (lower is better)\n",
            "AUC-Insertion:    0.5914 (higher is better)\n",
            "Comprehensiveness: 0.3281 (higher is better)\n",
            "Jaccard Stability: 0.6397 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.078712\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] $4,000/Month with your PC ! NO SPAM ! PLEASE READ !'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7942 (lower is better)\n",
            "AUC-Insertion:    0.8418 (higher is better)\n",
            "Comprehensiveness: 0.0561 (higher is better)\n",
            "Jaccard Stability: 0.5060 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.221107\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Remeber me?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7621 (lower is better)\n",
            "AUC-Insertion:    0.8991 (higher is better)\n",
            "Comprehensiveness: 0.0766 (higher is better)\n",
            "Jaccard Stability: 0.5726 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.128561\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Welcome to OfferClub!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6792 (lower is better)\n",
            "AUC-Insertion:    0.8778 (higher is better)\n",
            "Comprehensiveness: 0.0325 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.064688\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Work at Home - $5000 a month'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8622 (lower is better)\n",
            "AUC-Insertion:    0.9041 (higher is better)\n",
            "Comprehensiveness: 0.0295 (higher is better)\n",
            "Jaccard Stability: 0.3988 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.075084\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'YOUR ACCOUNT HAS BEEN CLOSED!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5753 (lower is better)\n",
            "AUC-Insertion:    0.8955 (higher is better)\n",
            "Comprehensiveness: 0.4641 (higher is better)\n",
            "Jaccard Stability: 0.6619 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.987710\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Guaranteed Best Mortgage Rate'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8339 (lower is better)\n",
            "AUC-Insertion:    0.9158 (higher is better)\n",
            "Comprehensiveness: 0.0299 (higher is better)\n",
            "Jaccard Stability: 0.4226 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.070057\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Adv: Mortgage Quotes Fast Online, No Cost'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8449 (lower is better)\n",
            "AUC-Insertion:    0.9195 (higher is better)\n",
            "Comprehensiveness: 0.0095 (higher is better)\n",
            "Jaccard Stability: 0.2897 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.303929\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'First Time Generic V*agra under $3 per 50mg'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6031 (lower is better)\n",
            "AUC-Insertion:    0.8183 (higher is better)\n",
            "Comprehensiveness: 0.0117 (higher is better)\n",
            "Jaccard Stability: 0.5869 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.725935\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Earn 100.000$ in one year working at home'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7710 (lower is better)\n",
            "AUC-Insertion:    0.7580 (higher is better)\n",
            "Comprehensiveness: 0.0387 (higher is better)\n",
            "Jaccard Stability: 0.3036 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.711232\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Earn 100.000$ in one year working at home'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7710 (lower is better)\n",
            "AUC-Insertion:    0.7580 (higher is better)\n",
            "Comprehensiveness: 0.0387 (higher is better)\n",
            "Jaccard Stability: 0.2857 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.705395\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Guaranteed Best Mortgage Rate'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8339 (lower is better)\n",
            "AUC-Insertion:    0.9158 (higher is better)\n",
            "Comprehensiveness: 0.0299 (higher is better)\n",
            "Jaccard Stability: 0.3750 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.072571\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[scoop] ....It is not my fault. .- vwiid'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4426 (lower is better)\n",
            "AUC-Insertion:    0.3634 (higher is better)\n",
            "Comprehensiveness: 0.0224 (higher is better)\n",
            "Jaccard Stability: 0.4504 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.992753\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Have you planned for your family's future?         ZBM'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7568 (lower is better)\n",
            "AUC-Insertion:    0.9029 (higher is better)\n",
            "Comprehensiveness: 0.0230 (higher is better)\n",
            "Jaccard Stability: 0.5440 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.925559\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Your eBay account is about to expire!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6753 (lower is better)\n",
            "AUC-Insertion:    0.8787 (higher is better)\n",
            "Comprehensiveness: 0.0245 (higher is better)\n",
            "Jaccard Stability: 0.3393 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.872472\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'You can gain from lowest interest rates in 30 years'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7380 (lower is better)\n",
            "AUC-Insertion:    0.7817 (higher is better)\n",
            "Comprehensiveness: 0.0214 (higher is better)\n",
            "Jaccard Stability: 0.2718 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.240711\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'HOME REPS WANTED-FORTUNE 500 COMP HIRING'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8383 (lower is better)\n",
            "AUC-Insertion:    0.9276 (higher is better)\n",
            "Comprehensiveness: 0.0523 (higher is better)\n",
            "Jaccard Stability: 0.3214 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.048133\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Create a PAYCHECK with your COMPUTER and Enjoy Cheap ISP & shopping Discount.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7231 (lower is better)\n",
            "AUC-Insertion:    0.3844 (higher is better)\n",
            "Comprehensiveness: 0.1700 (higher is better)\n",
            "Jaccard Stability: 0.5690 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.093763\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'NORTON SYSTEMWORKS 2002 CLEARANCE SALE! 6801wbRq4-940mJbj463-19'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8642 (lower is better)\n",
            "AUC-Insertion:    0.7606 (higher is better)\n",
            "Comprehensiveness: 0.0153 (higher is better)\n",
            "Jaccard Stability: 0.9000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.896540\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ADV: Extended Auto Warranties Here iubrq'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5562 (lower is better)\n",
            "AUC-Insertion:    0.9230 (higher is better)\n",
            "Comprehensiveness: 0.2157 (higher is better)\n",
            "Jaccard Stability: 0.7381 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.687997\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Garden Ornaments | ppu'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5790 (lower is better)\n",
            "AUC-Insertion:    0.9228 (higher is better)\n",
            "Comprehensiveness: 0.0329 (higher is better)\n",
            "Jaccard Stability: 0.3988 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.122202\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Save $100's, maybe $1,000's with No Lender's Fees. Click here!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7336 (lower is better)\n",
            "AUC-Insertion:    0.9101 (higher is better)\n",
            "Comprehensiveness: 0.0220 (higher is better)\n",
            "Jaccard Stability: 0.6202 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.431562\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '*Do Your Butt, Hips And Thighs Embarrass You?*'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4789 (lower is better)\n",
            "AUC-Insertion:    0.8928 (higher is better)\n",
            "Comprehensiveness: 0.6904 (higher is better)\n",
            "Jaccard Stability: 0.6286 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.017132\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ANTICAIPTING TO HEARING FROM YOU SOON.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7865 (lower is better)\n",
            "AUC-Insertion:    0.9022 (higher is better)\n",
            "Comprehensiveness: 0.0135 (higher is better)\n",
            "Jaccard Stability: 0.3433 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.385405\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Dont waste your TIME!!! Why?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6953 (lower is better)\n",
            "AUC-Insertion:    0.8783 (higher is better)\n",
            "Comprehensiveness: 0.0287 (higher is better)\n",
            "Jaccard Stability: 0.3810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.209696\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Are you ready for 10/5/2002?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7459 (lower is better)\n",
            "AUC-Insertion:    0.8751 (higher is better)\n",
            "Comprehensiveness: 0.0120 (higher is better)\n",
            "Jaccard Stability: 0.4762 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.048754\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Join & Get 4 DVDs for 49ï¿½ ea. (+shipping & processing)! Details Inside...'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.2329 (lower is better)\n",
            "AUC-Insertion:    0.5244 (higher is better)\n",
            "Comprehensiveness: 0.2268 (higher is better)\n",
            "Jaccard Stability: 0.4980 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.165149\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Mortgage Rates Are Down.                    ptjti'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7500 (lower is better)\n",
            "AUC-Insertion:    0.9213 (higher is better)\n",
            "Comprehensiveness: 0.0109 (higher is better)\n",
            "Jaccard Stability: 0.4798 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.056845\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Vacation Time,House need work,Behind in Bills? Refinance while rates are low'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8162 (lower is better)\n",
            "AUC-Insertion:    0.8925 (higher is better)\n",
            "Comprehensiveness: 0.0761 (higher is better)\n",
            "Jaccard Stability: 0.5690 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.023716\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Congratulations on Your 6 New Signups'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7868 (lower is better)\n",
            "AUC-Insertion:    0.8165 (higher is better)\n",
            "Comprehensiveness: 0.0551 (higher is better)\n",
            "Jaccard Stability: 0.3810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.044796\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] Need a Credit Card?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3856 (lower is better)\n",
            "AUC-Insertion:    0.7304 (higher is better)\n",
            "Comprehensiveness: 0.7660 (higher is better)\n",
            "Jaccard Stability: 0.5635 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.004575\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '$250,000... as low as $6.50 per month.             edahx'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7829 (lower is better)\n",
            "AUC-Insertion:    0.9033 (higher is better)\n",
            "Comprehensiveness: 0.0139 (higher is better)\n",
            "Jaccard Stability: 0.5254 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.079807\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'New Version 7: Uncover the TRUTH about ANYONE!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6748 (lower is better)\n",
            "AUC-Insertion:    0.8269 (higher is better)\n",
            "Comprehensiveness: 0.0780 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.057159\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Lenders WILL COMPETE for your mortgage             IVX'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7708 (lower is better)\n",
            "AUC-Insertion:    0.9149 (higher is better)\n",
            "Comprehensiveness: 0.0036 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.991292\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Tired of paying big bucks for cable'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8099 (lower is better)\n",
            "AUC-Insertion:    0.8736 (higher is better)\n",
            "Comprehensiveness: 0.0405 (higher is better)\n",
            "Jaccard Stability: 0.4881 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.016061\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Get a FREE Bottle of Wine & Tasting Kit'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8039 (lower is better)\n",
            "AUC-Insertion:    0.9164 (higher is better)\n",
            "Comprehensiveness: 0.0466 (higher is better)\n",
            "Jaccard Stability: 0.4504 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.397875\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Get $100 Free - Beat the House at Royal Vegas!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6365 (lower is better)\n",
            "AUC-Insertion:    0.8750 (higher is better)\n",
            "Comprehensiveness: 0.0596 (higher is better)\n",
            "Jaccard Stability: 0.4405 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.018304\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '**** American Millionaire Reveals His Secret Source of Wealth On The Internet!!!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8182 (lower is better)\n",
            "AUC-Insertion:    0.9097 (higher is better)\n",
            "Comprehensiveness: 0.0245 (higher is better)\n",
            "Jaccard Stability: 0.4599 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.775148\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FREE TRIAL - Last Stock pick UP 309%................................................. cqhcp'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8273 (lower is better)\n",
            "AUC-Insertion:    0.8780 (higher is better)\n",
            "Comprehensiveness: 0.0072 (higher is better)\n",
            "Jaccard Stability: 0.5631 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.803954\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Financial Power You Can Depend On'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8003 (lower is better)\n",
            "AUC-Insertion:    0.8887 (higher is better)\n",
            "Comprehensiveness: 0.0337 (higher is better)\n",
            "Jaccard Stability: 0.5238 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.030309\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FW: FOCUS ON VALUE'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6603 (lower is better)\n",
            "AUC-Insertion:    0.9103 (higher is better)\n",
            "Comprehensiveness: 0.5207 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.144004\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'I was so scared... my very first DP'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7502 (lower is better)\n",
            "AUC-Insertion:    0.8848 (higher is better)\n",
            "Comprehensiveness: 0.1060 (higher is better)\n",
            "Jaccard Stability: 0.6202 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.140260\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Boost Your Cell Signal ...10782'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7554 (lower is better)\n",
            "AUC-Insertion:    0.9270 (higher is better)\n",
            "Comprehensiveness: 0.0261 (higher is better)\n",
            "Jaccard Stability: 0.4762 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.027594\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FORTUNE 500 WORK AT HOME REPS NEEDED!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8534 (lower is better)\n",
            "AUC-Insertion:    0.9182 (higher is better)\n",
            "Comprehensiveness: 0.0552 (higher is better)\n",
            "Jaccard Stability: 0.4563 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.093656\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Adult: Free Access'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8738 (lower is better)\n",
            "AUC-Insertion:    0.8835 (higher is better)\n",
            "Comprehensiveness: 0.0343 (higher is better)\n",
            "Jaccard Stability: 0.4643 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.023106\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Holidays are coming?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8652 (lower is better)\n",
            "AUC-Insertion:    0.8295 (higher is better)\n",
            "Comprehensiveness: 0.0157 (higher is better)\n",
            "Jaccard Stability: 0.4524 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.028101\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Tell Me Where to Send Your Health Card'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7436 (lower is better)\n",
            "AUC-Insertion:    0.9053 (higher is better)\n",
            "Comprehensiveness: 0.0484 (higher is better)\n",
            "Jaccard Stability: 0.4325 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.158053\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ADV: Extended Auto Warranties Here vfafu'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5562 (lower is better)\n",
            "AUC-Insertion:    0.9230 (higher is better)\n",
            "Comprehensiveness: 0.2157 (higher is better)\n",
            "Jaccard Stability: 0.8012 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.691608\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Act Now - Reach Hundreds of Prospects'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7621 (lower is better)\n",
            "AUC-Insertion:    0.8565 (higher is better)\n",
            "Comprehensiveness: 0.1107 (higher is better)\n",
            "Jaccard Stability: 0.5369 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.098110\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Account zzzz@spamassassin.taint.org'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6689 (lower is better)\n",
            "AUC-Insertion:    0.8513 (higher is better)\n",
            "Comprehensiveness: 0.0233 (higher is better)\n",
            "Jaccard Stability: 0.3849 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.348378\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Make $500 - $2500/Week on Ebay                     3352'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7997 (lower is better)\n",
            "AUC-Insertion:    0.8839 (higher is better)\n",
            "Comprehensiveness: 0.0618 (higher is better)\n",
            "Jaccard Stability: 0.4048 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.054028\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'are you in the mood             XGHTMTGGC'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7568 (lower is better)\n",
            "AUC-Insertion:    0.9047 (higher is better)\n",
            "Comprehensiveness: 0.0206 (higher is better)\n",
            "Jaccard Stability: 0.5107 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.995372\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] re: how to register one of the new domain extensions'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6698 (lower is better)\n",
            "AUC-Insertion:    0.8324 (higher is better)\n",
            "Comprehensiveness: 0.2361 (higher is better)\n",
            "Jaccard Stability: 0.3571 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.148089\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Create a PAYCHECK with your COMPUTER and Enjoy Cheap ISP & shopping Discount.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7953 (lower is better)\n",
            "AUC-Insertion:    0.5605 (higher is better)\n",
            "Comprehensiveness: 0.0483 (higher is better)\n",
            "Jaccard Stability: 0.4702 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.014990\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ADV: Are you protected? Free Life Insurance quote oefik'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5562 (lower is better)\n",
            "AUC-Insertion:    0.9230 (higher is better)\n",
            "Comprehensiveness: 0.2157 (higher is better)\n",
            "Jaccard Stability: 0.7456 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.685228\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'We Build The Internet.  WebXperts.com  (Design / Programming / Consultation)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5337 (lower is better)\n",
            "AUC-Insertion:    0.5597 (higher is better)\n",
            "Comprehensiveness: 0.7582 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.706190\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Printer Cartridges as low as $1.21 each!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7056 (lower is better)\n",
            "AUC-Insertion:    0.9181 (higher is better)\n",
            "Comprehensiveness: 0.0461 (higher is better)\n",
            "Jaccard Stability: 0.4167 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.074092\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'The Government Grants You $25,000!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7420 (lower is better)\n",
            "AUC-Insertion:    0.9156 (higher is better)\n",
            "Comprehensiveness: 0.0163 (higher is better)\n",
            "Jaccard Stability: 0.4008 (higher is better)\n",
            "Computation Time: 0 days 00:00:02.339243\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'The best possible mortgage'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8581 (lower is better)\n",
            "AUC-Insertion:    0.9227 (higher is better)\n",
            "Comprehensiveness: 0.0059 (higher is better)\n",
            "Jaccard Stability: 0.4028 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.972343\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Private Label Reseller Hosting  -  Expires 9/30/2002'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7644 (lower is better)\n",
            "AUC-Insertion:    0.7984 (higher is better)\n",
            "Comprehensiveness: 0.0158 (higher is better)\n",
            "Jaccard Stability: 0.6107 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.955905\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Got plans tonight?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5776 (lower is better)\n",
            "AUC-Insertion:    0.8832 (higher is better)\n",
            "Comprehensiveness: 0.0211 (higher is better)\n",
            "Jaccard Stability: 0.4226 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.407726\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Congratulations! You Get a Free Handheld Organizer!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7834 (lower is better)\n",
            "AUC-Insertion:    0.9103 (higher is better)\n",
            "Comprehensiveness: 0.0673 (higher is better)\n",
            "Jaccard Stability: 0.6524 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.152451\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Commissions Too High to Publish'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8130 (lower is better)\n",
            "AUC-Insertion:    0.9101 (higher is better)\n",
            "Comprehensiveness: 0.4786 (higher is better)\n",
            "Jaccard Stability: 0.7190 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.086664\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Partnership.'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8285 (lower is better)\n",
            "AUC-Insertion:    0.8654 (higher is better)\n",
            "Comprehensiveness: 0.0296 (higher is better)\n",
            "Jaccard Stability: 0.4147 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.309605\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'BUSINESS PARTNERSHIP(URGENT/CONFIDENTIAL)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8339 (lower is better)\n",
            "AUC-Insertion:    0.8578 (higher is better)\n",
            "Comprehensiveness: 0.0206 (higher is better)\n",
            "Jaccard Stability: 0.6345 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.424211\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Free Shipping on all orders at Blair.com'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6807 (lower is better)\n",
            "AUC-Insertion:    0.8646 (higher is better)\n",
            "Comprehensiveness: 0.1053 (higher is better)\n",
            "Jaccard Stability: 0.4821 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.077713\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Never pay for the goodz again (8SimUgQ)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7557 (lower is better)\n",
            "AUC-Insertion:    0.8981 (higher is better)\n",
            "Comprehensiveness: 0.1165 (higher is better)\n",
            "Jaccard Stability: 0.8095 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.682508\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ä¸€ç½‘â€œæƒ â€å¤©ä¸‹ï¼Œä¸€å±•å¤©ä¸‹çŸ¥----2003å¹´4æœˆ1æ—¥--4'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7979 (lower is better)\n",
            "AUC-Insertion:    0.8903 (higher is better)\n",
            "Comprehensiveness: 0.0134 (higher is better)\n",
            "Jaccard Stability: 0.3393 (higher is better)\n",
            "Computation Time: 0 days 00:00:30.892934\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Attn: PROTECT YOURSELF AGAINST HARMFUL VIRUSES! SONLSNAIK'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6983 (lower is better)\n",
            "AUC-Insertion:    0.8460 (higher is better)\n",
            "Comprehensiveness: 0.1696 (higher is better)\n",
            "Jaccard Stability: 0.3036 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.108449\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'MAKE MONEY GIVING AWAY FREE STUFF!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6703 (lower is better)\n",
            "AUC-Insertion:    0.8794 (higher is better)\n",
            "Comprehensiveness: 0.1158 (higher is better)\n",
            "Jaccard Stability: 0.3413 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.193790\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '$14.95 per year domain names'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6694 (lower is better)\n",
            "AUC-Insertion:    0.8882 (higher is better)\n",
            "Comprehensiveness: 0.1220 (higher is better)\n",
            "Jaccard Stability: 0.3631 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.060788\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Make a Fortune On eBay                         24772'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8072 (lower is better)\n",
            "AUC-Insertion:    0.8794 (higher is better)\n",
            "Comprehensiveness: 0.0685 (higher is better)\n",
            "Jaccard Stability: 0.3433 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.042287\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Hit the Road with CNA'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6870 (lower is better)\n",
            "AUC-Insertion:    0.8050 (higher is better)\n",
            "Comprehensiveness: 0.0781 (higher is better)\n",
            "Jaccard Stability: 0.4464 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.560108\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '$10 a hour for watching e-mmercials! No joke!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4831 (lower is better)\n",
            "AUC-Insertion:    0.8867 (higher is better)\n",
            "Comprehensiveness: 0.0768 (higher is better)\n",
            "Jaccard Stability: 0.7583 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.059739\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'FWD:Direct marketing is working                16889'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7575 (lower is better)\n",
            "AUC-Insertion:    0.9239 (higher is better)\n",
            "Comprehensiveness: 0.0054 (higher is better)\n",
            "Jaccard Stability: 0.5119 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.530019\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'See your Company sales sky rocket.                 4611'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7577 (lower is better)\n",
            "AUC-Insertion:    0.9250 (higher is better)\n",
            "Comprehensiveness: 0.0026 (higher is better)\n",
            "Jaccard Stability: 0.5810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.518078\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[WM] (no subject)'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5927 (lower is better)\n",
            "AUC-Insertion:    0.9023 (higher is better)\n",
            "Comprehensiveness: 0.0800 (higher is better)\n",
            "Jaccard Stability: 0.3452 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.102993\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Did you complete this?'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8042 (lower is better)\n",
            "AUC-Insertion:    0.9063 (higher is better)\n",
            "Comprehensiveness: 0.0151 (higher is better)\n",
            "Jaccard Stability: 0.5214 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.013085\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Do you need a second MORTGAGE?                   22956'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8073 (lower is better)\n",
            "AUC-Insertion:    0.9074 (higher is better)\n",
            "Comprehensiveness: 0.0190 (higher is better)\n",
            "Jaccard Stability: 0.6524 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.988755\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] Prevent Work Monotony ilug'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7993 (lower is better)\n",
            "AUC-Insertion:    0.9031 (higher is better)\n",
            "Comprehensiveness: 0.0720 (higher is better)\n",
            "Jaccard Stability: 0.4464 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.175927\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Thanksgiving Sale'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7686 (lower is better)\n",
            "AUC-Insertion:    0.8980 (higher is better)\n",
            "Comprehensiveness: 0.0151 (higher is better)\n",
            "Jaccard Stability: 0.3810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.220153\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Auto Protection'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.3824 (lower is better)\n",
            "AUC-Insertion:    0.1295 (higher is better)\n",
            "Comprehensiveness: 0.3592 (higher is better)\n",
            "Jaccard Stability: 0.4206 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.016195\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Sitescooper: scoop websites onto your PalmPilot - Sitescooper    automatically retrieves the stories from several news websites, trims off    extraneous HTML, and converts them into iSilo or Palm DOC format for later    reading on-the-move. It maintains a cache, and will avoid stories you've    already    read. It can handle 1-page sites, 1-page with diffing, 2- and    3-level sites as well    as My-Netscape-style RSS sites. It's also very    easy to add a new site to its list.    Even if you don't have a PalmPilot,    it's still handy for simple website-to-text    conversion. Site files are    included for many popular news sites including Slashdot,    LWN, Freshmeat    and Linux Today.  http://jmason.org/software/sitescooper/'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6148 (lower is better)\n",
            "AUC-Insertion:    0.6898 (higher is better)\n",
            "Comprehensiveness: 0.0552 (higher is better)\n",
            "Jaccard Stability: 0.3750 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.782650\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Below Wholesale Prices on Name Brand Products'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7926 (lower is better)\n",
            "AUC-Insertion:    0.8951 (higher is better)\n",
            "Comprehensiveness: 0.0132 (higher is better)\n",
            "Jaccard Stability: 0.2302 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.199539\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Best Long Distance On the Net - 3.9 Cents With No Monthly Fees'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6537 (lower is better)\n",
            "AUC-Insertion:    0.8803 (higher is better)\n",
            "Comprehensiveness: 0.2944 (higher is better)\n",
            "Jaccard Stability: 0.5036 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.067825\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Prevent Employment Monotony yyyy'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7670 (lower is better)\n",
            "AUC-Insertion:    0.9062 (higher is better)\n",
            "Comprehensiveness: 0.0525 (higher is better)\n",
            "Jaccard Stability: 0.4881 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.182154\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'yyyy Your computer can READ! ! !'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6280 (lower is better)\n",
            "AUC-Insertion:    0.8280 (higher is better)\n",
            "Comprehensiveness: 0.2008 (higher is better)\n",
            "Jaccard Stability: 0.3075 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.049010\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'It'sÂ TimeÂ toÂ InvestÂ yourÂ Way'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7293 (lower is better)\n",
            "AUC-Insertion:    0.9071 (higher is better)\n",
            "Comprehensiveness: 0.0242 (higher is better)\n",
            "Jaccard Stability: 0.5119 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.049157\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'See a Horny Teen Girl Do a horse with a 31 inch C*ck it's FREE! -pkqolhil'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6260 (lower is better)\n",
            "AUC-Insertion:    0.6198 (higher is better)\n",
            "Comprehensiveness: 0.0769 (higher is better)\n",
            "Jaccard Stability: 0.5476 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.027921\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Webmaster ganhe dinheiro !!!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7803 (lower is better)\n",
            "AUC-Insertion:    0.7451 (higher is better)\n",
            "Comprehensiveness: 0.1252 (higher is better)\n",
            "Jaccard Stability: 0.4464 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.991532\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'spamassassin.taint.org'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.4181 (lower is better)\n",
            "AUC-Insertion:    0.3085 (higher is better)\n",
            "Comprehensiveness: 0.4710 (higher is better)\n",
            "Jaccard Stability: 0.3393 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.099773\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Today's Special: Amazing Penetrations No. 17 29264'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7978 (lower is better)\n",
            "AUC-Insertion:    0.8800 (higher is better)\n",
            "Comprehensiveness: 0.5993 (higher is better)\n",
            "Jaccard Stability: 0.7250 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.061430\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'hi'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8861 (lower is better)\n",
            "AUC-Insertion:    0.8997 (higher is better)\n",
            "Comprehensiveness: 0.0266 (higher is better)\n",
            "Jaccard Stability: 0.2937 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.032431\n",
            "==================================================\n",
            "Evaluating explanation quality for text: ''\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8921 (lower is better)\n",
            "AUC-Insertion:    0.0000 (higher is better)\n",
            "Comprehensiveness: 0.0786 (higher is better)\n",
            "Jaccard Stability: 1.0000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.496769\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'GOV'T GUARANTEED HOME BUSINESS'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8667 (lower is better)\n",
            "AUC-Insertion:    0.9215 (higher is better)\n",
            "Comprehensiveness: 0.0071 (higher is better)\n",
            "Jaccard Stability: 0.4659 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.011924\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG-Social] prirodu requiremus social sample'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7386 (lower is better)\n",
            "AUC-Insertion:    0.8403 (higher is better)\n",
            "Comprehensiveness: 0.0595 (higher is better)\n",
            "Jaccard Stability: 0.5393 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.143112\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'What your wife wants for Christmass'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8307 (lower is better)\n",
            "AUC-Insertion:    0.9061 (higher is better)\n",
            "Comprehensiveness: 0.0173 (higher is better)\n",
            "Jaccard Stability: 0.2222 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.171419\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Get 12 free Burgers + 1/2 Price Omaha Steaks!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7151 (lower is better)\n",
            "AUC-Insertion:    0.8864 (higher is better)\n",
            "Comprehensiveness: 0.2021 (higher is better)\n",
            "Jaccard Stability: 0.4147 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.018350\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Vary your interests!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7766 (lower is better)\n",
            "AUC-Insertion:    0.8584 (higher is better)\n",
            "Comprehensiveness: 0.0671 (higher is better)\n",
            "Jaccard Stability: 0.4738 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.705483\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'HK Email marking !'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8358 (lower is better)\n",
            "AUC-Insertion:    0.8631 (higher is better)\n",
            "Comprehensiveness: 0.3256 (higher is better)\n",
            "Jaccard Stability: 0.3591 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.145400\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] please kindly get back to me'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7835 (lower is better)\n",
            "AUC-Insertion:    0.5517 (higher is better)\n",
            "Comprehensiveness: 0.0250 (higher is better)\n",
            "Jaccard Stability: 0.5214 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.415225\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] MANUEL OKO'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8224 (lower is better)\n",
            "AUC-Insertion:    0.8371 (higher is better)\n",
            "Comprehensiveness: 0.2812 (higher is better)\n",
            "Jaccard Stability: 0.3810 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.289493\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Reverse Aging While Burning Fat'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8129 (lower is better)\n",
            "AUC-Insertion:    0.9141 (higher is better)\n",
            "Comprehensiveness: 0.1395 (higher is better)\n",
            "Jaccard Stability: 0.4325 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.123050\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'NEW STOCK PICK: OUR LAST ONE--PICK UP 300%.............................................................................................................................................................................................. aufd iuju'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8787 (lower is better)\n",
            "AUC-Insertion:    0.9147 (higher is better)\n",
            "Comprehensiveness: 0.0029 (higher is better)\n",
            "Jaccard Stability: 0.7190 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.905792\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Earn Your Fortune on eBay!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7495 (lower is better)\n",
            "AUC-Insertion:    0.9015 (higher is better)\n",
            "Comprehensiveness: 0.0069 (higher is better)\n",
            "Jaccard Stability: 0.3631 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.592768\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Finally! Sexy DVDs for FREE. Christmas is Great! NMV'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7590 (lower is better)\n",
            "AUC-Insertion:    0.8725 (higher is better)\n",
            "Comprehensiveness: 0.5329 (higher is better)\n",
            "Jaccard Stability: 0.7190 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.060522\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'ADV: Free Mortgage Rate Quote mbvod'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.5211 (lower is better)\n",
            "AUC-Insertion:    0.9030 (higher is better)\n",
            "Comprehensiveness: 0.5751 (higher is better)\n",
            "Jaccard Stability: 0.8000 (higher is better)\n",
            "Computation Time: 0 days 00:00:00.673370\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Busy? Home Study Makes Sense!'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8550 (lower is better)\n",
            "AUC-Insertion:    0.8989 (higher is better)\n",
            "Comprehensiveness: 0.0135 (higher is better)\n",
            "Jaccard Stability: 0.4583 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.253326\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Preferred Non-Smoker Rates for Smokers'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8196 (lower is better)\n",
            "AUC-Insertion:    0.9144 (higher is better)\n",
            "Comprehensiveness: 0.0451 (higher is better)\n",
            "Jaccard Stability: 0.5492 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.111233\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'hurry'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7134 (lower is better)\n",
            "AUC-Insertion:    0.3435 (higher is better)\n",
            "Comprehensiveness: 0.6712 (higher is better)\n",
            "Jaccard Stability: 0.5476 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.080186\n",
            "==================================================\n",
            "Evaluating explanation quality for text: '[ILUG] WILSON  KAMELA'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8146 (lower is better)\n",
            "AUC-Insertion:    0.8269 (higher is better)\n",
            "Comprehensiveness: 0.2843 (higher is better)\n",
            "Jaccard Stability: 0.3452 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.289566\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'How to get 10,000 FREE hits per day to any website'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.6495 (lower is better)\n",
            "AUC-Insertion:    0.8918 (higher is better)\n",
            "Comprehensiveness: 0.0239 (higher is better)\n",
            "Jaccard Stability: 0.2579 (higher is better)\n",
            "Computation Time: 0 days 00:00:01.320918\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Cannabis Difference'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.8130 (lower is better)\n",
            "AUC-Insertion:    0.9090 (higher is better)\n",
            "Comprehensiveness: 0.0140 (higher is better)\n",
            "Jaccard Stability: 0.6524 (higher is better)\n",
            "Computation Time: 0 days 00:00:02.741550\n",
            "==================================================\n",
            "Evaluating explanation quality for text: 'Faeries'\n",
            "Using method: attention\n",
            "Computing AUC-Del...\n",
            "Computing AUC-Ins...\n",
            "Computing Comprehensiveness...\n",
            "Computing Jaccard Stability...\n",
            "\n",
            "==================================================\n",
            "EXPLANATION QUALITY METRICS\n",
            "==================================================\n",
            "Method:           attention\n",
            "AUC-Deletion:     0.7612 (lower is better)\n",
            "AUC-Insertion:    0.8875 (higher is better)\n",
            "Comprehensiveness: 0.1075 (higher is better)\n",
            "Jaccard Stability: 0.5357 (higher is better)\n",
            "Computation Time: 0 days 00:00:02.686268\n",
            "==================================================\n",
            "\n",
            "Completed processing 606 samples with Attention Heads.\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "metadata": {
        "id": "2767dd5221d5bac",
        "outputId": "116591f7-2a59-4fac-a8ae-f83707a28887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     auc_deletion  auc_insertion  comprehensiveness  jaccard_stability  \\\n",
              "0        0.553344       0.120436           0.068414           0.553571   \n",
              "1        0.539277       0.141726           0.027357           0.345238   \n",
              "2        0.379974       0.126468           0.003247           0.604762   \n",
              "3        0.280834       0.063366           0.007177           0.474206   \n",
              "4        0.307057       0.072941           0.001085           0.586905   \n",
              "..            ...            ...                ...                ...   \n",
              "601      0.713385       0.343468           0.671166           0.547619   \n",
              "602      0.814591       0.826935           0.284308           0.345238   \n",
              "603      0.649499       0.891758           0.023864           0.257937   \n",
              "604      0.812971       0.909017           0.013985           0.652381   \n",
              "605      0.761248       0.887534           0.107489           0.535714   \n",
              "\n",
              "          computation_time  sample_id  \\\n",
              "0   0 days 00:00:01.272183          1   \n",
              "1   0 days 00:00:01.239677          2   \n",
              "2   0 days 00:00:01.037393          3   \n",
              "3   0 days 00:00:01.148540          4   \n",
              "4   0 days 00:00:01.035079          5   \n",
              "..                     ...        ...   \n",
              "601 0 days 00:00:01.080186        602   \n",
              "602 0 days 00:00:01.289566        603   \n",
              "603 0 days 00:00:01.320918        604   \n",
              "604 0 days 00:00:02.741550        605   \n",
              "605 0 days 00:00:02.686268        606   \n",
              "\n",
              "                                                  text label  \n",
              "0    RE: Our friends the Palestinians, Our servants...   Ham  \n",
              "1    Re: Our friends the Palestinians, Our servants...   Ham  \n",
              "2                                     xine src package   Ham  \n",
              "3                                 Re: xine src package   Ham  \n",
              "4    Re: Our friends the Palestinians, Our servants...   Ham  \n",
              "..                                                 ...   ...  \n",
              "601                                              hurry  Spam  \n",
              "602                              [ILUG] WILSON  KAMELA  Spam  \n",
              "603  How to get 10,000 FREE hits per day to any web...  Spam  \n",
              "604                                Cannabis Difference  Spam  \n",
              "605                                            Faeries  Spam  \n",
              "\n",
              "[606 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-289052ea-78c9-42a8-b198-f93a57fbfa9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auc_deletion</th>\n",
              "      <th>auc_insertion</th>\n",
              "      <th>comprehensiveness</th>\n",
              "      <th>jaccard_stability</th>\n",
              "      <th>computation_time</th>\n",
              "      <th>sample_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.553344</td>\n",
              "      <td>0.120436</td>\n",
              "      <td>0.068414</td>\n",
              "      <td>0.553571</td>\n",
              "      <td>0 days 00:00:01.272183</td>\n",
              "      <td>1</td>\n",
              "      <td>RE: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.539277</td>\n",
              "      <td>0.141726</td>\n",
              "      <td>0.027357</td>\n",
              "      <td>0.345238</td>\n",
              "      <td>0 days 00:00:01.239677</td>\n",
              "      <td>2</td>\n",
              "      <td>Re: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.379974</td>\n",
              "      <td>0.126468</td>\n",
              "      <td>0.003247</td>\n",
              "      <td>0.604762</td>\n",
              "      <td>0 days 00:00:01.037393</td>\n",
              "      <td>3</td>\n",
              "      <td>xine src package</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.280834</td>\n",
              "      <td>0.063366</td>\n",
              "      <td>0.007177</td>\n",
              "      <td>0.474206</td>\n",
              "      <td>0 days 00:00:01.148540</td>\n",
              "      <td>4</td>\n",
              "      <td>Re: xine src package</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.307057</td>\n",
              "      <td>0.072941</td>\n",
              "      <td>0.001085</td>\n",
              "      <td>0.586905</td>\n",
              "      <td>0 days 00:00:01.035079</td>\n",
              "      <td>5</td>\n",
              "      <td>Re: Our friends the Palestinians, Our servants...</td>\n",
              "      <td>Ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>0.713385</td>\n",
              "      <td>0.343468</td>\n",
              "      <td>0.671166</td>\n",
              "      <td>0.547619</td>\n",
              "      <td>0 days 00:00:01.080186</td>\n",
              "      <td>602</td>\n",
              "      <td>hurry</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>0.814591</td>\n",
              "      <td>0.826935</td>\n",
              "      <td>0.284308</td>\n",
              "      <td>0.345238</td>\n",
              "      <td>0 days 00:00:01.289566</td>\n",
              "      <td>603</td>\n",
              "      <td>[ILUG] WILSON  KAMELA</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>0.649499</td>\n",
              "      <td>0.891758</td>\n",
              "      <td>0.023864</td>\n",
              "      <td>0.257937</td>\n",
              "      <td>0 days 00:00:01.320918</td>\n",
              "      <td>604</td>\n",
              "      <td>How to get 10,000 FREE hits per day to any web...</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>0.812971</td>\n",
              "      <td>0.909017</td>\n",
              "      <td>0.013985</td>\n",
              "      <td>0.652381</td>\n",
              "      <td>0 days 00:00:02.741550</td>\n",
              "      <td>605</td>\n",
              "      <td>Cannabis Difference</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>0.761248</td>\n",
              "      <td>0.887534</td>\n",
              "      <td>0.107489</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0 days 00:00:02.686268</td>\n",
              "      <td>606</td>\n",
              "      <td>Faeries</td>\n",
              "      <td>Spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>606 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-289052ea-78c9-42a8-b198-f93a57fbfa9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-289052ea-78c9-42a8-b198-f93a57fbfa9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-289052ea-78c9-42a8-b198-f93a57fbfa9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f017eb60-8681-4e9a-b718-6f081afeaa3b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f017eb60-8681-4e9a-b718-6f081afeaa3b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f017eb60-8681-4e9a-b718-6f081afeaa3b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_828448d9-8456-4303-8252-4e0a1b32aab3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('attention_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_828448d9-8456-4303-8252-4e0a1b32aab3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('attention_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "attention_metrics_df",
              "summary": "{\n  \"name\": \"attention_metrics_df\",\n  \"rows\": 606,\n  \"fields\": [\n    {\n      \"column\": \"auc_deletion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21956156840587726,\n        \"min\": 0.10623165464722642,\n        \"max\": 0.8934055607645743,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.12127115106694912,\n          0.739107092221578,\n          0.43296450306661427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc_insertion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33116885890162623,\n        \"min\": 0.0,\n        \"max\": 0.9305596083402634,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.05391914624849269,\n          0.9135363176465034,\n          0.12120959848504173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16124054900112272,\n        \"min\": 3.539770841598511e-05,\n        \"max\": 0.8608549907803535,\n        \"num_unique_values\": 527,\n        \"samples\": [\n          0.001653514802455902,\n          0.11218690872192383,\n          0.2790432833135128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard_stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17116717802907963,\n        \"min\": 0.22222222222222224,\n        \"max\": 1.0,\n        \"num_unique_values\": 290,\n        \"samples\": [\n          0.9,\n          0.5154761904761905,\n          0.4658730158730158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"computation_time\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 605,\n        \"samples\": [\n          \"0 days 00:00:01.150300\",\n          \"0 days 00:00:01.309422\",\n          \"0 days 00:00:00.729948\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 175,\n        \"min\": 1,\n        \"max\": 606,\n        \"num_unique_values\": 606,\n        \"samples\": [\n          573,\n          290,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 520,\n        \"samples\": [\n          \"Re: [zzzzteana] Funny News story #1\",\n          \"Iran Pushes UN Intervention Against US\",\n          \"Re: RH 8 no DMA for DVD drive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Spam\",\n          \"Ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12,
      "source": [
        "attention_metrics_df = pd.DataFrame(attention_results)\n",
        "attention_metrics_df"
      ],
      "id": "2767dd5221d5bac"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_metrics_df.describe()"
      ],
      "metadata": {
        "id": "hs5YteRbaPa5",
        "outputId": "f6d99252-4d1f-4e09-f379-1f18ec3962d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "id": "hs5YteRbaPa5",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       auc_deletion  auc_insertion  comprehensiveness  jaccard_stability  \\\n",
              "count    606.000000     606.000000         606.000000         606.000000   \n",
              "mean       0.454475       0.403134           0.113369           0.535107   \n",
              "std        0.219562       0.331169           0.161241           0.171167   \n",
              "min        0.106232       0.000000           0.000035           0.222222   \n",
              "25%        0.277430       0.103772           0.005184           0.412698   \n",
              "50%        0.364780       0.286194           0.031868           0.498810   \n",
              "75%        0.679843       0.836890           0.160058           0.652381   \n",
              "max        0.893406       0.930560           0.860855           1.000000   \n",
              "\n",
              "                computation_time  sample_id  \n",
              "count                        606  606.00000  \n",
              "mean   0 days 00:00:01.138515914  303.50000  \n",
              "std    0 days 00:00:01.245813205  175.08141  \n",
              "min       0 days 00:00:00.495906    1.00000  \n",
              "25%    0 days 00:00:00.983575500  152.25000  \n",
              "50%    0 days 00:00:01.061230500  303.50000  \n",
              "75%    0 days 00:00:01.157919250  454.75000  \n",
              "max       0 days 00:00:30.892934  606.00000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae0d889e-770c-4082-8db0-b10ace2f423f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auc_deletion</th>\n",
              "      <th>auc_insertion</th>\n",
              "      <th>comprehensiveness</th>\n",
              "      <th>jaccard_stability</th>\n",
              "      <th>computation_time</th>\n",
              "      <th>sample_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606.000000</td>\n",
              "      <td>606</td>\n",
              "      <td>606.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.454475</td>\n",
              "      <td>0.403134</td>\n",
              "      <td>0.113369</td>\n",
              "      <td>0.535107</td>\n",
              "      <td>0 days 00:00:01.138515914</td>\n",
              "      <td>303.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.219562</td>\n",
              "      <td>0.331169</td>\n",
              "      <td>0.161241</td>\n",
              "      <td>0.171167</td>\n",
              "      <td>0 days 00:00:01.245813205</td>\n",
              "      <td>175.08141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.106232</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0 days 00:00:00.495906</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.277430</td>\n",
              "      <td>0.103772</td>\n",
              "      <td>0.005184</td>\n",
              "      <td>0.412698</td>\n",
              "      <td>0 days 00:00:00.983575500</td>\n",
              "      <td>152.25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.364780</td>\n",
              "      <td>0.286194</td>\n",
              "      <td>0.031868</td>\n",
              "      <td>0.498810</td>\n",
              "      <td>0 days 00:00:01.061230500</td>\n",
              "      <td>303.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.679843</td>\n",
              "      <td>0.836890</td>\n",
              "      <td>0.160058</td>\n",
              "      <td>0.652381</td>\n",
              "      <td>0 days 00:00:01.157919250</td>\n",
              "      <td>454.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.893406</td>\n",
              "      <td>0.930560</td>\n",
              "      <td>0.860855</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0 days 00:00:30.892934</td>\n",
              "      <td>606.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae0d889e-770c-4082-8db0-b10ace2f423f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae0d889e-770c-4082-8db0-b10ace2f423f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae0d889e-770c-4082-8db0-b10ace2f423f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-334443d5-2757-48ff-8061-3efa3af6b337\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-334443d5-2757-48ff-8061-3efa3af6b337')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-334443d5-2757-48ff-8061-3efa3af6b337 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"attention_metrics_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"auc_deletion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.10219919074623,\n        \"min\": 0.10623165464722642,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4544754376229227,\n          0.3647803417171793,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"auc_insertion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.1075466193148,\n        \"min\": 0.0,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.4031338225354513,\n          0.28619409104188276,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comprehensiveness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.18623212365713,\n        \"min\": 3.539770841598511e-05,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.11336948300893157,\n          0.03186783380806446,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard_stability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214.0771185631798,\n        \"min\": 0.17116717802907963,\n        \"max\": 606.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5351066058986851,\n          0.49880952380952376,\n          606.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"computation_time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0 days 00:00:01.138515914\",\n          \"0 days 00:00:01.061230500\",\n          \"606\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 218.1006213404329,\n        \"min\": 1.0,\n        \"max\": 606.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          606.0,\n          303.5,\n          454.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "b6332860",
      "metadata": {
        "id": "b6332860",
        "outputId": "c2d47ca3-2be6-44de-c7dd-48a2c36bbf39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create comprehensive results summary\n",
        "import pandas as pd\n",
        "\n",
        "# Convert results to DataFrames for better visualization\n",
        "if ig_results:\n",
        "    ig_df = pd.DataFrame(ig_results)\n",
        "    ig_df['method'] = 'Integrated_Gradients'\n",
        "\n",
        "if attention_results:\n",
        "    attention_df = pd.DataFrame(attention_results)\n",
        "    attention_df['method'] = 'Attention_Heads'\n",
        "\n",
        "# Combine results if both methods were successful\n",
        "if ig_results and attention_results:\n",
        "    combined_df = pd.concat([ig_df, attention_df], ignore_index=True)\n",
        "\n",
        "    print(\"COMPREHENSIVE EXPLANATION QUALITY RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Summary statistics by method\n",
        "    summary_stats = combined_df.groupby('method')[['auc_deletion', 'auc_insertion', 'comprehensiveness', 'jaccard_stability']].agg(['mean', 'std'])\n",
        "    print(\"\\nSummary Statistics by Method:\")\n",
        "    print(summary_stats)\n",
        "\n",
        "    # Detailed results by sample\n",
        "    print(\"\\nDetailed Results by Sample:\")\n",
        "    display_cols = ['sample_id', 'method', 'auc_deletion', 'auc_insertion', 'comprehensiveness', 'jaccard_stability', 'label']\n",
        "    print(combined_df[display_cols].to_string(index=False))\n",
        "\n",
        "elif ig_results:\n",
        "    print(\"Results using Integrated Gradients only:\")\n",
        "    display_cols = ['sample_id', 'auc_deletion', 'auc_insertion', 'comprehensiveness', 'jaccard_stability', 'label']\n",
        "    print(ig_df[display_cols].to_string(index=False))\n",
        "\n",
        "elif attention_results:\n",
        "    print(\"Results using Attention Heads only:\")\n",
        "    display_cols = ['sample_id', 'auc_deletion', 'auc_insertion', 'comprehensiveness', 'jaccard_stability', 'label']\n",
        "    print(attention_df[display_cols].to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"No results available for analysis.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPREHENSIVE EXPLANATION QUALITY RESULTS\n",
            "============================================================\n",
            "\n",
            "Summary Statistics by Method:\n",
            "                     auc_deletion           auc_insertion            \\\n",
            "                             mean       std          mean       std   \n",
            "method                                                                \n",
            "Attention_Heads          0.454475  0.219562      0.403134  0.331169   \n",
            "Integrated_Gradients     0.476898  0.234679      0.395897  0.327079   \n",
            "\n",
            "                     comprehensiveness           jaccard_stability            \n",
            "                                  mean       std              mean       std  \n",
            "method                                                                        \n",
            "Attention_Heads               0.113369  0.161241          0.535107  0.171167  \n",
            "Integrated_Gradients          0.092090  0.145554          0.532393  0.186247  \n",
            "\n",
            "Detailed Results by Sample:\n",
            " sample_id               method  auc_deletion  auc_insertion  comprehensiveness  jaccard_stability label\n",
            "         1 Integrated_Gradients      0.451565       0.107920           0.005028           0.334127   Ham\n",
            "         2 Integrated_Gradients      0.615704       0.149823           0.500781           0.210714   Ham\n",
            "         3 Integrated_Gradients      0.429045       0.112967           0.004510           0.535714   Ham\n",
            "         4 Integrated_Gradients      0.183767       0.067226           0.005919           0.346825   Ham\n",
            "         5 Integrated_Gradients      0.218783       0.104998           0.005007           0.966667   Ham\n",
            "         6 Integrated_Gradients      0.498639       0.414239           0.132168           0.776190   Ham\n",
            "         7 Integrated_Gradients      0.213118       0.286990           0.092055           0.695238   Ham\n",
            "         8 Integrated_Gradients      0.284897       0.118722           0.038109           0.933333   Ham\n",
            "         9 Integrated_Gradients      0.313304       0.484967           0.317489           0.558730   Ham\n",
            "        10 Integrated_Gradients      0.394461       0.194164           0.000030           0.621825   Ham\n",
            "        11 Integrated_Gradients      0.355330       0.134594           0.005712           0.752381   Ham\n",
            "        12 Integrated_Gradients      0.451501       0.173642           0.004811           0.357143   Ham\n",
            "        13 Integrated_Gradients      0.382323       0.067063           0.004371           0.563095   Ham\n",
            "        14 Integrated_Gradients      0.204907       0.121401           0.002589           0.661905   Ham\n",
            "        15 Integrated_Gradients      0.295765       0.058228           0.002982           0.232937   Ham\n",
            "        16 Integrated_Gradients      0.523505       0.091474           0.034092           0.307540   Ham\n",
            "        17 Integrated_Gradients      0.736188       0.681648           0.277127           0.398810   Ham\n",
            "        18 Integrated_Gradients      0.316357       0.236103           0.006579           0.687302   Ham\n",
            "        19 Integrated_Gradients      0.230572       0.233504           0.000319           0.709524   Ham\n",
            "        20 Integrated_Gradients      0.270881       0.071302           0.017038           0.583333   Ham\n",
            "        21 Integrated_Gradients      0.693234       0.152204           0.136238           0.321429   Ham\n",
            "        22 Integrated_Gradients      0.474959       0.066809           0.034104           0.759524   Ham\n",
            "        23 Integrated_Gradients      0.163553       0.085355           0.027132           0.763492   Ham\n",
            "        24 Integrated_Gradients      0.458079       0.275126           0.033549           0.357937   Ham\n",
            "        25 Integrated_Gradients      0.297813       0.125578           0.018502           0.438095   Ham\n",
            "        26 Integrated_Gradients      0.297398       0.160769           0.034881           0.404762   Ham\n",
            "        27 Integrated_Gradients      0.202582       0.107834           0.001677           0.858333   Ham\n",
            "        28 Integrated_Gradients      0.280809       0.140889           0.000610           0.610714   Ham\n",
            "        29 Integrated_Gradients      0.221305       0.175940           0.000894           0.704762   Ham\n",
            "        30 Integrated_Gradients      0.253562       0.108927           0.056037           0.709524   Ham\n",
            "        31 Integrated_Gradients      0.258751       0.271996           0.168626           0.501587   Ham\n",
            "        32 Integrated_Gradients      0.357226       0.147583           0.008725           0.638095   Ham\n",
            "        33 Integrated_Gradients      0.336056       0.147870           0.015979           0.644048   Ham\n",
            "        34 Integrated_Gradients      0.260140       0.291602           0.003067           0.653571   Ham\n",
            "        35 Integrated_Gradients      0.364428       0.111134           0.021388           0.653968   Ham\n",
            "        36 Integrated_Gradients      0.414392       0.084854           0.045177           0.800000   Ham\n",
            "        37 Integrated_Gradients      0.251918       0.201570           0.004211           0.586905   Ham\n",
            "        38 Integrated_Gradients      0.190609       0.187678           0.022850           0.680952   Ham\n",
            "        39 Integrated_Gradients      0.206182       0.144214           0.012172           0.776190   Ham\n",
            "        40 Integrated_Gradients      0.204578       0.098620           0.001328           0.650000   Ham\n",
            "        41 Integrated_Gradients      0.678573       0.240735           0.464412           0.719048   Ham\n",
            "        42 Integrated_Gradients      0.320934       0.168484           0.022268           0.515873   Ham\n",
            "        43 Integrated_Gradients      0.437946       0.146940           0.238702           0.658333   Ham\n",
            "        44 Integrated_Gradients      0.241864       0.228947           0.000546           0.825000   Ham\n",
            "        45 Integrated_Gradients      0.485229       0.294327           0.147904           0.709524   Ham\n",
            "        46 Integrated_Gradients      0.612427       0.280989           0.460322           0.696825   Ham\n",
            "        47 Integrated_Gradients      0.333341       0.243151           0.030007           0.712302   Ham\n",
            "        48 Integrated_Gradients      0.290915       0.255508           0.025960           0.677381   Ham\n",
            "        49 Integrated_Gradients      0.278586       0.244506           0.015618           0.529762   Ham\n",
            "        50 Integrated_Gradients      0.285307       0.369601           0.026174           0.578571   Ham\n",
            "        51 Integrated_Gradients      0.439935       0.258777           0.089139           0.652381   Ham\n",
            "        52 Integrated_Gradients      0.702900       0.231514           0.444507           0.620238   Ham\n",
            "        53 Integrated_Gradients      0.351181       0.361806           0.077809           0.296825   Ham\n",
            "        54 Integrated_Gradients      0.592480       0.497965           0.299677           0.580952   Ham\n",
            "        55 Integrated_Gradients      0.542579       0.320186           0.069885           0.809524   Ham\n",
            "        56 Integrated_Gradients      0.413187       0.084554           0.003673           0.336111   Ham\n",
            "        57 Integrated_Gradients      0.276675       0.081697           0.000863           0.267857   Ham\n",
            "        58 Integrated_Gradients      0.263538       0.073814           0.000853           0.432143   Ham\n",
            "        59 Integrated_Gradients      0.191898       0.054885           0.021789           0.470635   Ham\n",
            "        60 Integrated_Gradients      0.233745       0.067861           0.001734           0.659524   Ham\n",
            "        61 Integrated_Gradients      0.237405       0.071600           0.003094           0.545238   Ham\n",
            "        62 Integrated_Gradients      0.233691       0.070299           0.000824           0.521429   Ham\n",
            "        63 Integrated_Gradients      0.237547       0.076694           0.006061           0.335317   Ham\n",
            "        64 Integrated_Gradients      0.372332       0.060342           0.001957           0.319444   Ham\n",
            "        65 Integrated_Gradients      0.424995       0.067369           0.001968           0.488095   Ham\n",
            "        66 Integrated_Gradients      0.325340       0.092030           0.000783           0.634524   Ham\n",
            "        67 Integrated_Gradients      0.408152       0.115400           0.000664           0.610714   Ham\n",
            "        68 Integrated_Gradients      0.121574       0.068940           0.000554           0.554762   Ham\n",
            "        69 Integrated_Gradients      0.376115       0.074268           0.002076           0.290079   Ham\n",
            "        70 Integrated_Gradients      0.284199       0.098971           0.054037           0.477778   Ham\n",
            "        71 Integrated_Gradients      0.392662       0.318419           0.281794           0.933333   Ham\n",
            "        72 Integrated_Gradients      0.300795       0.065155           0.007862           0.345238   Ham\n",
            "        73 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "        74 Integrated_Gradients      0.347636       0.126220           0.004051           0.634524   Ham\n",
            "        75 Integrated_Gradients      0.311936       0.158811           0.000906           0.619048   Ham\n",
            "        76 Integrated_Gradients      0.392662       0.318419           0.281794           0.728571   Ham\n",
            "        77 Integrated_Gradients      0.392662       0.318419           0.281794           0.811111   Ham\n",
            "        78 Integrated_Gradients      0.392662       0.318419           0.281794           0.809524   Ham\n",
            "        79 Integrated_Gradients      0.271381       0.096191           0.000734           0.230159   Ham\n",
            "        80 Integrated_Gradients      0.273186       0.172058           0.050002           0.545238   Ham\n",
            "        81 Integrated_Gradients      0.149236       0.058322           0.000209           0.281746   Ham\n",
            "        82 Integrated_Gradients      0.345834       0.072843           0.003097           0.511905   Ham\n",
            "        83 Integrated_Gradients      0.234740       0.065171           0.000844           0.357143   Ham\n",
            "        84 Integrated_Gradients      0.162087       0.053053           0.003420           0.518651   Ham\n",
            "        85 Integrated_Gradients      0.293802       0.078324           0.001134           0.351984   Ham\n",
            "        86 Integrated_Gradients      0.253046       0.071914           0.002398           0.302381   Ham\n",
            "        87 Integrated_Gradients      0.500530       0.068527           0.001801           0.353571   Ham\n",
            "        88 Integrated_Gradients      0.507478       0.137910           0.001214           0.595238   Ham\n",
            "        89 Integrated_Gradients      0.422566       0.081557           0.009910           0.620238   Ham\n",
            "        90 Integrated_Gradients      0.407058       0.063827           0.001175           0.363095   Ham\n",
            "        91 Integrated_Gradients      0.203864       0.073894           0.005040           0.270635   Ham\n",
            "        92 Integrated_Gradients      0.317811       0.142797           0.013917           0.572619   Ham\n",
            "        93 Integrated_Gradients      0.399943       0.093709           0.036377           0.394841   Ham\n",
            "        94 Integrated_Gradients      0.195145       0.158628           0.109386           0.620238   Ham\n",
            "        95 Integrated_Gradients      0.618931       0.225766           0.375470           0.687302   Ham\n",
            "        96 Integrated_Gradients      0.214764       0.059279           0.004997           0.488095   Ham\n",
            "        97 Integrated_Gradients      0.392662       0.318419           0.281794           0.900000   Ham\n",
            "        98 Integrated_Gradients      0.392662       0.318419           0.281794           0.858333   Ham\n",
            "        99 Integrated_Gradients      0.281245       0.185301           0.039599           0.463095   Ham\n",
            "       100 Integrated_Gradients      0.382579       0.116552           0.044762           0.676190   Ham\n",
            "       101 Integrated_Gradients      0.534700       0.127467           0.002565           0.532540   Ham\n",
            "       102 Integrated_Gradients      0.341105       0.054533           0.001193           0.653571   Ham\n",
            "       103 Integrated_Gradients      0.388011       0.246754           0.018001           0.505952   Ham\n",
            "       104 Integrated_Gradients      0.319990       0.103671           0.001843           0.453571   Ham\n",
            "       105 Integrated_Gradients      0.392662       0.318419           0.281794           0.866667   Ham\n",
            "       106 Integrated_Gradients      0.392662       0.318419           0.281794           0.734524   Ham\n",
            "       107 Integrated_Gradients      0.440393       0.060154           0.002407           0.343254   Ham\n",
            "       108 Integrated_Gradients      0.224659       0.076501           0.000971           0.475397   Ham\n",
            "       109 Integrated_Gradients      0.392662       0.318419           0.281794           0.677381   Ham\n",
            "       110 Integrated_Gradients      0.231031       0.070071           0.008516           0.553571   Ham\n",
            "       111 Integrated_Gradients      0.346485       0.080979           0.012199           0.444444   Ham\n",
            "       112 Integrated_Gradients      0.583348       0.207254           0.566730           0.539286   Ham\n",
            "       113 Integrated_Gradients      0.325550       0.096420           0.000747           0.531349   Ham\n",
            "       114 Integrated_Gradients      0.157287       0.071583           0.000384           0.561111   Ham\n",
            "       115 Integrated_Gradients      0.392662       0.318419           0.281794           0.842857   Ham\n",
            "       116 Integrated_Gradients      0.392662       0.318419           0.281794           0.777778   Ham\n",
            "       117 Integrated_Gradients      0.392662       0.318419           0.281794           0.842857   Ham\n",
            "       118 Integrated_Gradients      0.392662       0.318419           0.281794           0.734524   Ham\n",
            "       119 Integrated_Gradients      0.392662       0.318419           0.281794           0.667857   Ham\n",
            "       120 Integrated_Gradients      0.214996       0.066825           0.002824           0.418651   Ham\n",
            "       121 Integrated_Gradients      0.335777       0.156550           0.011480           0.479762   Ham\n",
            "       122 Integrated_Gradients      0.240608       0.079773           0.022693           0.761905   Ham\n",
            "       123 Integrated_Gradients      0.265422       0.133760           0.000406           0.400794   Ham\n",
            "       124 Integrated_Gradients      0.328856       0.131123           0.025957           0.555159   Ham\n",
            "       125 Integrated_Gradients      0.350860       0.243201           0.004660           0.412302   Ham\n",
            "       126 Integrated_Gradients      0.442488       0.173611           0.035376           0.261905   Ham\n",
            "       127 Integrated_Gradients      0.213881       0.106716           0.007961           0.604762   Ham\n",
            "       128 Integrated_Gradients      0.428339       0.161196           0.107927           0.704762   Ham\n",
            "       129 Integrated_Gradients      0.259587       0.095584           0.003228           0.652381   Ham\n",
            "       130 Integrated_Gradients      0.209884       0.289741           0.005753           0.576190   Ham\n",
            "       131 Integrated_Gradients      0.184485       0.080390           0.005612           0.825000   Ham\n",
            "       132 Integrated_Gradients      0.157291       0.229716           0.003649           0.652381   Ham\n",
            "       133 Integrated_Gradients      0.342483       0.097318           0.010081           0.572619   Ham\n",
            "       134 Integrated_Gradients      0.337260       0.181112           0.029787           0.655159   Ham\n",
            "       135 Integrated_Gradients      0.253865       0.113070           0.004954           0.505952   Ham\n",
            "       136 Integrated_Gradients      0.559759       0.253863           0.086406           0.545238   Ham\n",
            "       137 Integrated_Gradients      0.292753       0.092167           0.001613           0.458333   Ham\n",
            "       138 Integrated_Gradients      0.335077       0.102383           0.032560           0.636111   Ham\n",
            "       139 Integrated_Gradients      0.227312       0.139852           0.025493           0.588492   Ham\n",
            "       140 Integrated_Gradients      0.214824       0.134461           0.001144           0.573016   Ham\n",
            "       141 Integrated_Gradients      0.204526       0.203246           0.003844           0.667857   Ham\n",
            "       142 Integrated_Gradients      0.264431       0.327606           0.008998           0.753968   Ham\n",
            "       143 Integrated_Gradients      0.400417       0.393670           0.215829           0.844444   Ham\n",
            "       144 Integrated_Gradients      0.305940       0.312843           0.066143           0.450397   Ham\n",
            "       145 Integrated_Gradients      0.507314       0.285576           0.264313           0.635714   Ham\n",
            "       146 Integrated_Gradients      0.273123       0.184498           0.008437           0.563095   Ham\n",
            "       147 Integrated_Gradients      0.584982       0.199244           0.254478           0.424206   Ham\n",
            "       148 Integrated_Gradients      0.287676       0.304885           0.023278           0.767857   Ham\n",
            "       149 Integrated_Gradients      0.312440       0.387426           0.100787           0.553571   Ham\n",
            "       150 Integrated_Gradients      0.395981       0.255376           0.020719           0.416667   Ham\n",
            "       151 Integrated_Gradients      0.324627       0.394951           0.120602           0.586905   Ham\n",
            "       152 Integrated_Gradients      0.342970       0.166907           0.010300           0.440873   Ham\n",
            "       153 Integrated_Gradients      0.205229       0.124841           0.001734           0.422619   Ham\n",
            "       154 Integrated_Gradients      0.374526       0.241532           0.041845           0.685714   Ham\n",
            "       155 Integrated_Gradients      0.585826       0.402670           0.497106           0.571429   Ham\n",
            "       156 Integrated_Gradients      0.300796       0.359427           0.043790           0.436905   Ham\n",
            "       157 Integrated_Gradients      0.333984       0.329263           0.030563           0.557143   Ham\n",
            "       158 Integrated_Gradients      0.254275       0.164601           0.024576           0.652381   Ham\n",
            "       159 Integrated_Gradients      0.178015       0.063667           0.001266           0.425794   Ham\n",
            "       160 Integrated_Gradients      0.276071       0.074962           0.004039           0.603968   Ham\n",
            "       161 Integrated_Gradients      0.239786       0.082489           0.003945           0.407143   Ham\n",
            "       162 Integrated_Gradients      0.197123       0.069651           0.000576           0.582540   Ham\n",
            "       163 Integrated_Gradients      0.256385       0.054565           0.002897           0.577381   Ham\n",
            "       164 Integrated_Gradients      0.251090       0.063331           0.003574           0.595238   Ham\n",
            "       165 Integrated_Gradients      0.189147       0.057925           0.002553           0.240079   Ham\n",
            "       166 Integrated_Gradients      0.242727       0.059700           0.000220           0.541667   Ham\n",
            "       167 Integrated_Gradients      0.301253       0.057023           0.011441           0.592857   Ham\n",
            "       168 Integrated_Gradients      0.330539       0.082327           0.001073           0.356349   Ham\n",
            "       169 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       170 Integrated_Gradients      0.392662       0.318419           0.281794           0.776190   Ham\n",
            "       171 Integrated_Gradients      0.356014       0.064042           0.009122           0.342063   Ham\n",
            "       172 Integrated_Gradients      0.392662       0.318419           0.281794           0.710714   Ham\n",
            "       173 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       174 Integrated_Gradients      0.227839       0.066637           0.000075           0.376984   Ham\n",
            "       175 Integrated_Gradients      0.392662       0.318419           0.281794           0.728571   Ham\n",
            "       176 Integrated_Gradients      0.392662       0.318419           0.281794           0.852381   Ham\n",
            "       177 Integrated_Gradients      0.392662       0.318419           0.281794           0.685714   Ham\n",
            "       178 Integrated_Gradients      0.392662       0.318419           0.281794           0.900000   Ham\n",
            "       179 Integrated_Gradients      0.392662       0.318419           0.281794           0.876190   Ham\n",
            "       180 Integrated_Gradients      0.339212       0.087932           0.078002           0.397222   Ham\n",
            "       181 Integrated_Gradients      0.273516       0.062326           0.000499           0.578968   Ham\n",
            "       182 Integrated_Gradients      0.610324       0.259908           0.611197           0.186111   Ham\n",
            "       183 Integrated_Gradients      0.220003       0.066032           0.004121           0.327381   Ham\n",
            "       184 Integrated_Gradients      0.214260       0.087595           0.001937           0.521429   Ham\n",
            "       185 Integrated_Gradients      0.367795       0.070798           0.003815           0.548810   Ham\n",
            "       186 Integrated_Gradients      0.168621       0.054341           0.003190           0.596429   Ham\n",
            "       187 Integrated_Gradients      0.295645       0.088386           0.000809           0.415476   Ham\n",
            "       188 Integrated_Gradients      0.370252       0.058818           0.001202           0.275794   Ham\n",
            "       189 Integrated_Gradients      0.392662       0.318419           0.281794           0.809524   Ham\n",
            "       190 Integrated_Gradients      0.392662       0.318419           0.281794           0.800000   Ham\n",
            "       191 Integrated_Gradients      0.392662       0.318419           0.281794           0.766667   Ham\n",
            "       192 Integrated_Gradients      0.357426       0.086979           0.003453           0.488095   Ham\n",
            "       193 Integrated_Gradients      0.405237       0.816875           0.253820           0.418651   Ham\n",
            "       194 Integrated_Gradients      0.290572       0.550347           0.849144           0.653571   Ham\n",
            "       195 Integrated_Gradients      0.362416       0.055785           0.017544           0.317460   Ham\n",
            "       196 Integrated_Gradients      0.541099       0.103598           0.000540           0.293651   Ham\n",
            "       197 Integrated_Gradients      0.518649       0.131003           0.047530           0.677778   Ham\n",
            "       198 Integrated_Gradients      0.274964       0.068629           0.000457           0.509127   Ham\n",
            "       199 Integrated_Gradients      0.226532       0.080658           0.000776           0.580159   Ham\n",
            "       200 Integrated_Gradients      0.216629       0.068654           0.003886           0.551190   Ham\n",
            "       201 Integrated_Gradients      0.509918       0.140725           0.019201           0.686905   Ham\n",
            "       202 Integrated_Gradients      0.368311       0.350200           0.043211           0.531349   Ham\n",
            "       203 Integrated_Gradients      0.228665       0.233192           0.002279           0.571429   Ham\n",
            "       204 Integrated_Gradients      0.304414       0.081103           0.004202           0.686905   Ham\n",
            "       205 Integrated_Gradients      0.275668       0.129618           0.001772           0.292460   Ham\n",
            "       206 Integrated_Gradients      0.189953       0.064529           0.001635           0.236905   Ham\n",
            "       207 Integrated_Gradients      0.135460       0.060800           0.001175           0.466270   Ham\n",
            "       208 Integrated_Gradients      0.216345       0.167606           0.000998           0.512302   Ham\n",
            "       209 Integrated_Gradients      0.271955       0.107216           0.005827           0.580952   Ham\n",
            "       210 Integrated_Gradients      0.278237       0.110601           0.007852           0.577381   Ham\n",
            "       211 Integrated_Gradients      0.196625       0.074173           0.002394           0.535714   Ham\n",
            "       212 Integrated_Gradients      0.349072       0.073236           0.000555           0.484127   Ham\n",
            "       213 Integrated_Gradients      0.368311       0.350200           0.043211           0.620238   Ham\n",
            "       214 Integrated_Gradients      0.279160       0.065201           0.003028           0.517460   Ham\n",
            "       215 Integrated_Gradients      0.133992       0.072699           0.002977           0.324603   Ham\n",
            "       216 Integrated_Gradients      0.345768       0.215755           0.002175           0.652381   Ham\n",
            "       217 Integrated_Gradients      0.335267       0.080339           0.011099           0.634524   Ham\n",
            "       218 Integrated_Gradients      0.345283       0.085450           0.003384           0.480159   Ham\n",
            "       219 Integrated_Gradients      0.367142       0.121027           0.074117           0.742857   Ham\n",
            "       220 Integrated_Gradients      0.282941       0.094625           0.000650           0.533333   Ham\n",
            "       221 Integrated_Gradients      0.280598       0.066498           0.001982           0.430952   Ham\n",
            "       222 Integrated_Gradients      0.150641       0.060774           0.000331           0.497619   Ham\n",
            "       223 Integrated_Gradients      0.200582       0.072976           0.000188           0.401190   Ham\n",
            "       224 Integrated_Gradients      0.167973       0.056304           0.005419           0.463492   Ham\n",
            "       225 Integrated_Gradients      0.272039       0.066325           0.000119           0.328968   Ham\n",
            "       226 Integrated_Gradients      0.335121       0.102636           0.028774           0.471825   Ham\n",
            "       227 Integrated_Gradients      0.239330       0.139069           0.002448           0.501190   Ham\n",
            "       228 Integrated_Gradients      0.468887       0.099214           0.040163           0.519048   Ham\n",
            "       229 Integrated_Gradients      0.186825       0.127495           0.001436           0.503571   Ham\n",
            "       230 Integrated_Gradients      0.194871       0.157299           0.019012           0.396825   Ham\n",
            "       231 Integrated_Gradients      0.382856       0.196925           0.426700           0.400794   Ham\n",
            "       232 Integrated_Gradients      0.339065       0.081006           0.042340           0.511905   Ham\n",
            "       233 Integrated_Gradients      0.385383       0.136591           0.000938           0.503571   Ham\n",
            "       234 Integrated_Gradients      0.249205       0.118676           0.024739           0.686905   Ham\n",
            "       235 Integrated_Gradients      0.323422       0.122603           0.017119           0.545238   Ham\n",
            "       236 Integrated_Gradients      0.510122       0.164086           0.178886           0.403571   Ham\n",
            "       237 Integrated_Gradients      0.393576       0.191792           0.182481           0.577381   Ham\n",
            "       238 Integrated_Gradients      0.357210       0.103746           0.298902           0.659524   Ham\n",
            "       239 Integrated_Gradients      0.368829       0.187657           0.023382           0.531349   Ham\n",
            "       240 Integrated_Gradients      0.268454       0.144342           0.011602           0.539286   Ham\n",
            "       241 Integrated_Gradients      0.175124       0.089203           0.000282           0.783333   Ham\n",
            "       242 Integrated_Gradients      0.175633       0.112861           0.001891           0.558730   Ham\n",
            "       243 Integrated_Gradients      0.368685       0.339085           0.100579           0.619048   Ham\n",
            "       244 Integrated_Gradients      0.236746       0.337061           0.001046           0.601190   Ham\n",
            "       245 Integrated_Gradients      0.459085       0.391470           0.038040           0.631349   Ham\n",
            "       246 Integrated_Gradients      0.537786       0.431497           0.166995           0.560714   Ham\n",
            "       247 Integrated_Gradients      0.143392       0.324666           0.026137           0.866667   Ham\n",
            "       248 Integrated_Gradients      0.397612       0.258401           0.009001           0.627778   Ham\n",
            "       249 Integrated_Gradients      0.345879       0.281808           0.012504           0.710714   Ham\n",
            "       250 Integrated_Gradients      0.296967       0.211741           0.001579           0.776190   Ham\n",
            "       251 Integrated_Gradients      0.264658       0.146010           0.003039           0.701190   Ham\n",
            "       252 Integrated_Gradients      0.411859       0.303133           0.169884           0.440476   Ham\n",
            "       253 Integrated_Gradients      0.354280       0.238042           0.035429           0.538095   Ham\n",
            "       254 Integrated_Gradients      0.443586       0.367122           0.055617           0.502381   Ham\n",
            "       255 Integrated_Gradients      0.255788       0.250340           0.006061           0.629762   Ham\n",
            "       256 Integrated_Gradients      0.242590       0.257805           0.010961           0.719048   Ham\n",
            "       257 Integrated_Gradients      0.241118       0.099943           0.005048           0.539683   Ham\n",
            "       258 Integrated_Gradients      0.307690       0.090099           0.001854           0.317460   Ham\n",
            "       259 Integrated_Gradients      0.266862       0.068181           0.004195           0.469048   Ham\n",
            "       260 Integrated_Gradients      0.202862       0.052045           0.001425           0.422619   Ham\n",
            "       261 Integrated_Gradients      0.173649       0.056783           0.003050           0.501190   Ham\n",
            "       262 Integrated_Gradients      0.347240       0.057409           0.002719           0.833333   Ham\n",
            "       263 Integrated_Gradients      0.256440       0.060417           0.001899           0.382540   Ham\n",
            "       264 Integrated_Gradients      0.201711       0.064154           0.000368           0.345238   Ham\n",
            "       265 Integrated_Gradients      0.162400       0.061779           0.000244           0.442460   Ham\n",
            "       266 Integrated_Gradients      0.168482       0.062351           0.001559           0.232937   Ham\n",
            "       267 Integrated_Gradients      0.380222       0.232972           0.007121           0.309127   Ham\n",
            "       268 Integrated_Gradients      0.135507       0.056795           0.001460           0.440476   Ham\n",
            "       269 Integrated_Gradients      0.330694       0.099676           0.000525           0.519048   Ham\n",
            "       270 Integrated_Gradients      0.251920       0.060845           0.001318           0.177381   Ham\n",
            "       271 Integrated_Gradients      0.549339       0.071220           0.002135           0.517460   Ham\n",
            "       272 Integrated_Gradients      0.250516       0.065163           0.000851           0.405159   Ham\n",
            "       273 Integrated_Gradients      0.127945       0.061497           0.000572           0.404762   Ham\n",
            "       274 Integrated_Gradients      0.298630       0.073133           0.007297           0.299206   Ham\n",
            "       275 Integrated_Gradients      0.233361       0.092155           0.004132           0.577381   Ham\n",
            "       276 Integrated_Gradients      0.157521       0.061265           0.000249           0.669444   Ham\n",
            "       277 Integrated_Gradients      0.545658       0.193202           0.231652           0.369048   Ham\n",
            "       278 Integrated_Gradients      0.648493       0.216398           0.771434           0.449206   Ham\n",
            "       279 Integrated_Gradients      0.378336       0.190205           0.006920           0.570635   Ham\n",
            "       280 Integrated_Gradients      0.271058       0.085251           0.014587           0.440476   Ham\n",
            "       281 Integrated_Gradients      0.235430       0.079942           0.005622           0.876190   Ham\n",
            "       282 Integrated_Gradients      0.439235       0.070626           0.006998           0.567857   Ham\n",
            "       283 Integrated_Gradients      0.449599       0.076179           0.002726           0.313492   Ham\n",
            "       284 Integrated_Gradients      0.648493       0.216398           0.771434           0.582540   Ham\n",
            "       285 Integrated_Gradients      0.443999       0.069283           0.002513           0.505556   Ham\n",
            "       286 Integrated_Gradients      0.155971       0.087963           0.004658           0.569048   Ham\n",
            "       287 Integrated_Gradients      0.269827       0.267169           0.002629           0.547619   Ham\n",
            "       288 Integrated_Gradients      0.162462       0.057881           0.002389           0.574603   Ham\n",
            "       289 Integrated_Gradients      0.196490       0.068915           0.003030           0.582540   Ham\n",
            "       290 Integrated_Gradients      0.370768       0.124768           0.030266           0.321429   Ham\n",
            "       291 Integrated_Gradients      0.460127       0.179585           0.013985           0.573016   Ham\n",
            "       292 Integrated_Gradients      0.233016       0.095309           0.001056           0.497619   Ham\n",
            "       293 Integrated_Gradients      0.330541       0.123548           0.003634           0.293651   Ham\n",
            "       294 Integrated_Gradients      0.282540       0.096842           0.019266           0.396825   Ham\n",
            "       295 Integrated_Gradients      0.331554       0.201519           0.023122           0.738095   Ham\n",
            "       296 Integrated_Gradients      0.474538       0.367709           0.134226           0.734524   Ham\n",
            "       297 Integrated_Gradients      0.399325       0.094455           0.010880           0.685714   Ham\n",
            "       298 Integrated_Gradients      0.218302       0.246312           0.000507           0.687302   Ham\n",
            "       299 Integrated_Gradients      0.366454       0.249513           0.013115           0.671429   Ham\n",
            "       300 Integrated_Gradients      0.549896       0.195106           0.421870           0.402778   Ham\n",
            "       301 Integrated_Gradients      0.361366       0.291618           0.043259           0.580952   Ham\n",
            "       302 Integrated_Gradients      0.232989       0.465105           0.110347           0.527381   Ham\n",
            "       303 Integrated_Gradients      0.555617       0.775381           0.192536           0.560714   Ham\n",
            "       304 Integrated_Gradients      0.570865       0.306374           0.174209           0.683333   Ham\n",
            "       305 Integrated_Gradients      0.276174       0.283515           0.006214           0.866667   Ham\n",
            "       306 Integrated_Gradients      0.201521       0.208691           0.009199           0.621825   Ham\n",
            "       307 Integrated_Gradients      0.474435       0.556337           0.292701           0.530952   Ham\n",
            "       308 Integrated_Gradients      0.263399       0.367209           0.092490           0.642857   Ham\n",
            "       309 Integrated_Gradients      0.205108       0.258351           0.004241           0.606349   Ham\n",
            "       310 Integrated_Gradients      0.385972       0.342362           0.095535           0.505952   Ham\n",
            "       311 Integrated_Gradients      0.504988       0.418800           0.100879           0.677381   Ham\n",
            "       312 Integrated_Gradients      0.350825       0.358915           0.008151           0.416270   Ham\n",
            "       313 Integrated_Gradients      0.483645       0.461412           0.198712           0.750000   Ham\n",
            "       314 Integrated_Gradients      0.403743       0.397764           0.058298           0.456349   Ham\n",
            "       315 Integrated_Gradients      0.207214       0.304001           0.006039           0.645635   Ham\n",
            "       316 Integrated_Gradients      0.244046       0.297989           0.063128           0.509524   Ham\n",
            "       317 Integrated_Gradients      0.255927       0.383325           0.095014           0.709524   Ham\n",
            "       318 Integrated_Gradients      0.358253       0.245822           0.061096           0.545238   Ham\n",
            "       319 Integrated_Gradients      0.317432       0.075263           0.004351           0.750000   Ham\n",
            "       320 Integrated_Gradients      0.197415       0.071905           0.001033           0.194048   Ham\n",
            "       321 Integrated_Gradients      0.407065       0.059142           0.001759           0.342857   Ham\n",
            "       322 Integrated_Gradients      0.251879       0.072468           0.000660           0.515476   Ham\n",
            "       323 Integrated_Gradients      0.385292       0.102631           0.000066           0.293651   Ham\n",
            "       324 Integrated_Gradients      0.452650       0.318700           0.121352           0.676190   Ham\n",
            "       325 Integrated_Gradients      0.696270       0.238813           0.427481           0.257937   Ham\n",
            "       326 Integrated_Gradients      0.684562       0.845263           0.407115           0.582143   Ham\n",
            "       327 Integrated_Gradients      0.538416       0.900916           0.201798           0.363095   Ham\n",
            "       328 Integrated_Gradients      0.346852       0.390128           0.013576           0.728571   Ham\n",
            "       329 Integrated_Gradients      0.560684       0.636134           0.131740           0.212302   Ham\n",
            "       330 Integrated_Gradients      0.246109       0.156070           0.018918           0.183333   Ham\n",
            "       331 Integrated_Gradients      0.220625       0.069346           0.000370           0.453571   Ham\n",
            "       332 Integrated_Gradients      0.339210       0.211721           0.036182           0.293651   Ham\n",
            "       333 Integrated_Gradients      0.745370       0.893000           0.515563           1.000000   Ham\n",
            "       334 Integrated_Gradients      0.652338       0.191606           0.004327           0.173413   Ham\n",
            "       335 Integrated_Gradients      0.535742       0.072471           0.006125           0.420635   Ham\n",
            "       336 Integrated_Gradients      0.392662       0.318419           0.281794           0.761905   Ham\n",
            "       337 Integrated_Gradients      0.844568       0.884989           0.000886           0.236905   Ham\n",
            "       338 Integrated_Gradients      0.392662       0.318419           0.281794           0.742857   Ham\n",
            "       339 Integrated_Gradients      0.392662       0.318419           0.281794           0.852381   Ham\n",
            "       340 Integrated_Gradients      0.392662       0.318419           0.281794           0.776190   Ham\n",
            "       341 Integrated_Gradients      0.438513       0.230417           0.016639           0.264683   Ham\n",
            "       342 Integrated_Gradients      0.357170       0.059349           0.004053           0.306349   Ham\n",
            "       343 Integrated_Gradients      0.392662       0.318419           0.281794           0.852381   Ham\n",
            "       344 Integrated_Gradients      0.281523       0.102363           0.005143           0.602381   Ham\n",
            "       345 Integrated_Gradients      0.495757       0.147021           0.000045           0.477778   Ham\n",
            "       346 Integrated_Gradients      0.088290       0.062325           0.000194           0.258333   Ham\n",
            "       347 Integrated_Gradients      0.241907       0.112556           0.002920           0.446429   Ham\n",
            "       348 Integrated_Gradients      0.239082       0.156945           0.002263           0.384921   Ham\n",
            "       349 Integrated_Gradients      0.295858       0.121685           0.002732           0.225000   Ham\n",
            "       350 Integrated_Gradients      0.244833       0.079102           0.001932           0.389683   Ham\n",
            "       351 Integrated_Gradients      0.376512       0.077353           0.005319           0.292460   Ham\n",
            "       352 Integrated_Gradients      0.392662       0.318419           0.281794           0.809524   Ham\n",
            "       353 Integrated_Gradients      0.392662       0.318419           0.281794           0.844444   Ham\n",
            "       354 Integrated_Gradients      0.392662       0.318419           0.281794           0.758333   Ham\n",
            "       355 Integrated_Gradients      0.293799       0.053273           0.002475           0.596429   Ham\n",
            "       356 Integrated_Gradients      0.144755       0.061693           0.000933           0.264683   Ham\n",
            "       357 Integrated_Gradients      0.236254       0.071264           0.003044           0.289683   Ham\n",
            "       358 Integrated_Gradients      0.190839       0.296389           0.002104           0.410714   Ham\n",
            "       359 Integrated_Gradients      0.124947       0.117108           0.001838           0.230159   Ham\n",
            "       360 Integrated_Gradients      0.242892       0.086309           0.003213           0.430159   Ham\n",
            "       361 Integrated_Gradients      0.392662       0.318419           0.281794           0.825000   Ham\n",
            "       362 Integrated_Gradients      0.392662       0.318419           0.281794           0.776190   Ham\n",
            "       363 Integrated_Gradients      0.392662       0.318419           0.281794           0.858333   Ham\n",
            "       364 Integrated_Gradients      0.392662       0.318419           0.281794           0.809524   Ham\n",
            "       365 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       366 Integrated_Gradients      0.392662       0.318419           0.281794           0.728571   Ham\n",
            "       367 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       368 Integrated_Gradients      0.392662       0.318419           0.281794           0.801190   Ham\n",
            "       369 Integrated_Gradients      0.392662       0.318419           0.281794           0.752381   Ham\n",
            "       370 Integrated_Gradients      0.249451       0.072215           0.001998           0.375794   Ham\n",
            "       371 Integrated_Gradients      0.228882       0.084991           0.001319           0.653571   Ham\n",
            "       372 Integrated_Gradients      0.392662       0.318419           0.281794           0.909524   Ham\n",
            "       373 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       374 Integrated_Gradients      0.392662       0.318419           0.281794           0.752381   Ham\n",
            "       375 Integrated_Gradients      0.392662       0.318419           0.281794           0.809524   Ham\n",
            "       376 Integrated_Gradients      0.496139       0.346287           0.123224           0.438095   Ham\n",
            "       377 Integrated_Gradients      0.269827       0.267169           0.002629           0.636111   Ham\n",
            "       378 Integrated_Gradients      0.392662       0.318419           0.281794           0.866667   Ham\n",
            "       379 Integrated_Gradients      0.392662       0.318419           0.281794           0.701190   Ham\n",
            "       380 Integrated_Gradients      0.298267       0.099941           0.001729           0.404762   Ham\n",
            "       381 Integrated_Gradients      0.392662       0.318419           0.281794           0.842857   Ham\n",
            "       382 Integrated_Gradients      0.641711       0.198339           0.417902           0.677381   Ham\n",
            "       383 Integrated_Gradients      0.392662       0.318419           0.281794           0.785714   Ham\n",
            "       384 Integrated_Gradients      0.392662       0.318419           0.281794           0.776190   Ham\n",
            "       385 Integrated_Gradients      0.392662       0.318419           0.281794           0.671429   Ham\n",
            "       386 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       387 Integrated_Gradients      0.392662       0.318419           0.281794           0.766667   Ham\n",
            "       388 Integrated_Gradients      0.392662       0.318419           0.281794           0.842857   Ham\n",
            "       389 Integrated_Gradients      0.392662       0.318419           0.281794           0.686905   Ham\n",
            "       390 Integrated_Gradients      0.187516       0.063380           0.001788           0.503968   Ham\n",
            "       391 Integrated_Gradients      0.392662       0.318419           0.281794           0.776190   Ham\n",
            "       392 Integrated_Gradients      0.470692       0.180975           0.118984           0.292460   Ham\n",
            "       393 Integrated_Gradients      0.392662       0.318419           0.281794           0.766667   Ham\n",
            "       394 Integrated_Gradients      0.396072       0.287619           0.381144           0.744048   Ham\n",
            "       395 Integrated_Gradients      0.744709       0.819407           0.014470           0.187302   Ham\n",
            "       396 Integrated_Gradients      0.392662       0.318419           0.281794           0.842857   Ham\n",
            "       397 Integrated_Gradients      0.392662       0.318419           0.281794           0.900000   Ham\n",
            "       398 Integrated_Gradients      0.248382       0.062129           0.002516           0.431349   Ham\n",
            "       399 Integrated_Gradients      0.392662       0.318419           0.281794           0.752381   Ham\n",
            "       400 Integrated_Gradients      0.336829       0.095016           0.010346           0.553571   Ham\n",
            "       401 Integrated_Gradients      0.364663       0.161188           0.002008           0.190079   Ham\n",
            "       402 Integrated_Gradients      0.337681       0.077593           0.007275           0.700000   Ham\n",
            "       403 Integrated_Gradients      0.133716       0.059018           0.001527           0.521429   Ham\n",
            "       404 Integrated_Gradients      0.392662       0.318419           0.281794           0.709524   Ham\n",
            "       405 Integrated_Gradients      0.115781       0.056309           0.006402           0.569444   Ham\n",
            "       406 Integrated_Gradients      0.392662       0.318419           0.281794           0.833333   Ham\n",
            "       407 Integrated_Gradients      0.392662       0.318419           0.281794           0.733333   Ham\n",
            "       408 Integrated_Gradients      0.403148       0.055224           0.000826           0.523016   Ham\n",
            "       409 Integrated_Gradients      0.392662       0.318419           0.281794           0.891667   Ham\n",
            "       410 Integrated_Gradients      0.392662       0.318419           0.281794           0.900000   Ham\n",
            "       411 Integrated_Gradients      0.233943       0.060898           0.003659           0.513095   Ham\n",
            "       412 Integrated_Gradients      0.398757       0.061771           0.001327           0.505952   Ham\n",
            "       413 Integrated_Gradients      0.145507       0.097756           0.002199           0.382937   Ham\n",
            "       414 Integrated_Gradients      0.121080       0.053447           0.001845           0.275000   Ham\n",
            "       415 Integrated_Gradients      0.364469       0.087859           0.001769           0.809524   Ham\n",
            "       416 Integrated_Gradients      0.813879       0.933598           0.109137           0.701190  Spam\n",
            "       417 Integrated_Gradients      0.847422       0.869582           0.017920           0.644048  Spam\n",
            "       418 Integrated_Gradients      0.685398       0.784683           0.233367           0.439286  Spam\n",
            "       419 Integrated_Gradients      0.777047       0.934142           0.063435           0.578571  Spam\n",
            "       420 Integrated_Gradients      0.811810       0.877721           0.006541           0.628571  Spam\n",
            "       421 Integrated_Gradients      0.801644       0.905728           0.010220           0.339286  Spam\n",
            "       422 Integrated_Gradients      0.802850       0.879117           0.000193           0.253571  Spam\n",
            "       423 Integrated_Gradients      0.770061       0.831506           0.047598           0.494048  Spam\n",
            "       424 Integrated_Gradients      0.814482       0.919649           0.151117           0.800000  Spam\n",
            "       425 Integrated_Gradients      0.717385       0.847600           0.032853           0.498016  Spam\n",
            "       426 Integrated_Gradients      0.742978       0.927651           0.127803           0.627381  Spam\n",
            "       427 Integrated_Gradients      0.821361       0.730050           0.042074           0.282540  Spam\n",
            "       428 Integrated_Gradients      0.658853       0.907489           0.184044           0.371825  Spam\n",
            "       429 Integrated_Gradients      0.864887       0.874977           0.007484           0.590079  Spam\n",
            "       430 Integrated_Gradients      0.729870       0.916550           0.131923           0.704762  Spam\n",
            "       431 Integrated_Gradients      0.843573       0.902366           0.021119           0.695238  Spam\n",
            "       432 Integrated_Gradients      0.848479       0.895870           0.011456           0.384921  Spam\n",
            "       433 Integrated_Gradients      0.753511       0.881269           0.185152           0.521429  Spam\n",
            "       434 Integrated_Gradients      0.506835       0.618819           0.024616           0.289683  Spam\n",
            "       435 Integrated_Gradients      0.859228       0.666008           0.000412           0.430952  Spam\n",
            "       436 Integrated_Gradients      0.794868       0.834878           0.054944           0.719048  Spam\n",
            "       437 Integrated_Gradients      0.772038       0.784410           0.081637           0.410317  Spam\n",
            "       438 Integrated_Gradients      0.870883       0.649607           0.006935           0.415476  Spam\n",
            "       439 Integrated_Gradients      0.767339       0.860382           0.012858           0.493651  Spam\n",
            "       440 Integrated_Gradients      0.871905       0.808120           0.012950           0.080556  Spam\n",
            "       441 Integrated_Gradients      0.785825       0.910756           0.061156           0.375794  Spam\n",
            "       442 Integrated_Gradients      0.767970       0.887670           0.028019           0.636111  Spam\n",
            "       443 Integrated_Gradients      0.731470       0.835560           0.178805           0.752381  Spam\n",
            "       444 Integrated_Gradients      0.824537       0.884309           0.031119           0.281746  Spam\n",
            "       445 Integrated_Gradients      0.811679       0.915755           0.000946           0.434524  Spam\n",
            "       446 Integrated_Gradients      0.730112       0.808666           0.026619           0.244048  Spam\n",
            "       447 Integrated_Gradients      0.609504       0.790392           0.092166           0.341270  Spam\n",
            "       448 Integrated_Gradients      0.787199       0.911736           0.009046           0.445238  Spam\n",
            "       449 Integrated_Gradients      0.519603       0.867797           0.056452           0.302381  Spam\n",
            "       450 Integrated_Gradients      0.762185       0.835689           0.019206           0.303571  Spam\n",
            "       451 Integrated_Gradients      0.808656       0.896327           0.018370           0.145635  Spam\n",
            "       452 Integrated_Gradients      0.847172       0.874688           0.011200           0.275794  Spam\n",
            "       453 Integrated_Gradients      0.604133       0.583737           0.080128           0.203968  Spam\n",
            "       454 Integrated_Gradients      0.845797       0.892380           0.021223           0.192857  Spam\n",
            "       455 Integrated_Gradients      0.666158       0.875065           0.140094           0.795238  Spam\n",
            "       456 Integrated_Gradients      0.781941       0.921573           0.118442           0.291667  Spam\n",
            "       457 Integrated_Gradients      0.818254       0.880828           0.038384           0.531349  Spam\n",
            "       458 Integrated_Gradients      0.808188       0.529916           0.012888           0.578571  Spam\n",
            "       459 Integrated_Gradients      0.605996       0.877557           0.001729           0.323016  Spam\n",
            "       460 Integrated_Gradients      0.854392       0.849567           0.010699           0.448810  Spam\n",
            "       461 Integrated_Gradients      0.804675       0.867306           0.000462           0.201190  Spam\n",
            "       462 Integrated_Gradients      0.811011       0.878920           0.024089           0.709524  Spam\n",
            "       463 Integrated_Gradients      0.584657       0.801148           0.095430           0.588492  Spam\n",
            "       464 Integrated_Gradients      0.661777       0.848233           0.071788           0.900000  Spam\n",
            "       465 Integrated_Gradients      0.424377       0.777960           0.277358           0.293651  Spam\n",
            "       466 Integrated_Gradients      0.738384       0.889916           0.037310           0.388492  Spam\n",
            "       467 Integrated_Gradients      0.830062       0.844772           0.095131           0.432540  Spam\n",
            "       468 Integrated_Gradients      0.789363       0.909030           0.013216           0.295238  Spam\n",
            "       469 Integrated_Gradients      0.843440       0.885359           0.043968           0.626190  Spam\n",
            "       470 Integrated_Gradients      0.856591       0.909926           0.023576           0.428571  Spam\n",
            "       471 Integrated_Gradients      0.795858       0.722794           0.043012           0.397619  Spam\n",
            "       472 Integrated_Gradients      0.776347       0.929821           0.037016           0.590476  Spam\n",
            "       473 Integrated_Gradients      0.781366       0.870424           0.008359           0.250794  Spam\n",
            "       474 Integrated_Gradients      0.892101       0.000000           0.078647           1.000000  Spam\n",
            "       475 Integrated_Gradients      0.873961       0.897476           0.011408           0.458333  Spam\n",
            "       476 Integrated_Gradients      0.872311       0.894332           0.047991           0.436111  Spam\n",
            "       477 Integrated_Gradients      0.822439       0.909563           0.030318           0.701190  Spam\n",
            "       478 Integrated_Gradients      0.688188       0.716717           0.101036           0.563095  Spam\n",
            "       479 Integrated_Gradients      0.812255       0.870434           0.002064           0.256746  Spam\n",
            "       480 Integrated_Gradients      0.812255       0.870434           0.002064           0.268651  Spam\n",
            "       481 Integrated_Gradients      0.879581       0.881284           0.007193           0.215079  Spam\n",
            "       482 Integrated_Gradients      0.400476       0.886777           0.563437           0.317460  Spam\n",
            "       483 Integrated_Gradients      0.869133       0.854542           0.011500           0.610714  Spam\n",
            "       484 Integrated_Gradients      0.860560       0.890351           0.010435           0.403571  Spam\n",
            "       485 Integrated_Gradients      0.857302       0.880806           0.040689           0.661905  Spam\n",
            "       486 Integrated_Gradients      0.854392       0.849567           0.010699           0.323413  Spam\n",
            "       487 Integrated_Gradients      0.584971       0.906289           0.012686           0.361905  Spam\n",
            "       488 Integrated_Gradients      0.833993       0.888446           0.001505           0.365079  Spam\n",
            "       489 Integrated_Gradients      0.838135       0.919529           0.078284           0.458333  Spam\n",
            "       490 Integrated_Gradients      0.685495       0.907850           0.149796           0.644048  Spam\n",
            "       491 Integrated_Gradients      0.714126       0.623515           0.082049           0.370635  Spam\n",
            "       492 Integrated_Gradients      0.834501       0.907419           0.004690           0.300397  Spam\n",
            "       493 Integrated_Gradients      0.265987       0.621174           0.318971           0.330159  Spam\n",
            "       494 Integrated_Gradients      0.800788       0.823078           0.018151           0.235714  Spam\n",
            "       495 Integrated_Gradients      0.876749       0.876157           0.018722           0.588492  Spam\n",
            "       496 Integrated_Gradients      0.865167       0.890396           0.050483           0.432540  Spam\n",
            "       497 Integrated_Gradients      0.898714       0.905584           0.004482           0.380952  Spam\n",
            "       498 Integrated_Gradients      0.661879       0.842179           0.433070           0.505952  Spam\n",
            "       499 Integrated_Gradients      0.851351       0.920830           0.004808           0.440079  Spam\n",
            "       500 Integrated_Gradients      0.879581       0.881284           0.007193           0.311508  Spam\n",
            "       501 Integrated_Gradients      0.683398       0.656367           0.107172           0.744048  Spam\n",
            "       502 Integrated_Gradients      0.780171       0.854970           0.000369           0.022222  Spam\n",
            "       503 Integrated_Gradients      0.780171       0.854970           0.000369           0.047222  Spam\n",
            "       504 Integrated_Gradients      0.851351       0.920830           0.004808           0.545238  Spam\n",
            "       505 Integrated_Gradients      0.588800       0.365575           0.312789           0.338095  Spam\n",
            "       506 Integrated_Gradients      0.745184       0.846254           0.108698           0.461508  Spam\n",
            "       507 Integrated_Gradients      0.755713       0.842364           0.017088           0.418254  Spam\n",
            "       508 Integrated_Gradients      0.846760       0.634810           0.000752           0.423016  Spam\n",
            "       509 Integrated_Gradients      0.872587       0.887733           0.015489           0.653571  Spam\n",
            "       510 Integrated_Gradients      0.751299       0.506163           0.566882           0.488095  Spam\n",
            "       511 Integrated_Gradients      0.874140       0.798526           0.009614           0.686905  Spam\n",
            "       512 Integrated_Gradients      0.666158       0.875065           0.140094           0.688492  Spam\n",
            "       513 Integrated_Gradients      0.753399       0.911182           0.014236           0.586905  Spam\n",
            "       514 Integrated_Gradients      0.854542       0.885078           0.010504           0.402778  Spam\n",
            "       515 Integrated_Gradients      0.586370       0.866941           0.595715           0.418651  Spam\n",
            "       516 Integrated_Gradients      0.798719       0.869528           0.008970           0.268651  Spam\n",
            "       517 Integrated_Gradients      0.786552       0.846696           0.020855           0.420238  Spam\n",
            "       518 Integrated_Gradients      0.865929       0.895261           0.002032           0.497619  Spam\n",
            "       519 Integrated_Gradients      0.414118       0.539710           0.117789           0.596825  Spam\n",
            "       520 Integrated_Gradients      0.886337       0.911539           0.006537           0.414683  Spam\n",
            "       521 Integrated_Gradients      0.832419       0.902913           0.062896           0.531349  Spam\n",
            "       522 Integrated_Gradients      0.698900       0.869577           0.546707           0.207937  Spam\n",
            "       523 Integrated_Gradients      0.433504       0.857968           0.685460           0.317857  Spam\n",
            "       524 Integrated_Gradients      0.834077       0.893010           0.008851           0.776190  Spam\n",
            "       525 Integrated_Gradients      0.538461       0.901514           0.446439           0.602381  Spam\n",
            "       526 Integrated_Gradients      0.880913       0.906348           0.004163           0.667857  Spam\n",
            "       527 Integrated_Gradients      0.840868       0.875995           0.001332           0.316270  Spam\n",
            "       528 Integrated_Gradients      0.791368       0.903469           0.037167           0.439286  Spam\n",
            "       529 Integrated_Gradients      0.641634       0.870873           0.098999           0.517460  Spam\n",
            "       530 Integrated_Gradients      0.888786       0.901540           0.004192           0.331349  Spam\n",
            "       531 Integrated_Gradients      0.850747       0.875002           0.024248           0.530952  Spam\n",
            "       532 Integrated_Gradients      0.824075       0.876468           0.038209           0.728571  Spam\n",
            "       533 Integrated_Gradients      0.792741       0.896302           0.140252           0.488095  Spam\n",
            "       534 Integrated_Gradients      0.756906       0.890112           0.015248           0.339683  Spam\n",
            "       535 Integrated_Gradients      0.799399       0.908182           0.101210           0.719048  Spam\n",
            "       536 Integrated_Gradients      0.914714       0.909928           0.001888           0.422619  Spam\n",
            "       537 Integrated_Gradients      0.881395       0.843889           0.029077           0.373016  Spam\n",
            "       538 Integrated_Gradients      0.868317       0.900581           0.020738           0.521825  Spam\n",
            "       539 Integrated_Gradients      0.857570       0.891872           0.010249           0.513095  Spam\n",
            "       540 Integrated_Gradients      0.666158       0.875065           0.140094           0.785714  Spam\n",
            "       541 Integrated_Gradients      0.767722       0.789035           0.299347           0.719048  Spam\n",
            "       542 Integrated_Gradients      0.719651       0.863055           0.026155           0.185714  Spam\n",
            "       543 Integrated_Gradients      0.788402       0.882734           0.034971           0.574603  Spam\n",
            "       544 Integrated_Gradients      0.860643       0.891128           0.010385           0.701190  Spam\n",
            "       545 Integrated_Gradients      0.682342       0.791268           0.060865           0.444444  Spam\n",
            "       546 Integrated_Gradients      0.772495       0.424977           0.125700           0.325397  Spam\n",
            "       547 Integrated_Gradients      0.666158       0.875065           0.140094           0.776190  Spam\n",
            "       548 Integrated_Gradients      0.641832       0.500687           0.632315           0.752381  Spam\n",
            "       549 Integrated_Gradients      0.839090       0.905200           0.005812           0.463095  Spam\n",
            "       550 Integrated_Gradients      0.867717       0.892998           0.016071           0.424603  Spam\n",
            "       551 Integrated_Gradients      0.860328       0.910763           0.001605           0.535714  Spam\n",
            "       552 Integrated_Gradients      0.649490       0.841670           0.033958           0.710714  Spam\n",
            "       553 Integrated_Gradients      0.638465       0.846911           0.014892           0.374206  Spam\n",
            "       554 Integrated_Gradients      0.846079       0.867212           0.042111           0.378968  Spam\n",
            "       555 Integrated_Gradients      0.885821       0.882223           0.015723           0.420635  Spam\n",
            "       556 Integrated_Gradients      0.831770       0.876152           0.016770           0.492063  Spam\n",
            "       557 Integrated_Gradients      0.841517       0.879006           0.016010           0.365079  Spam\n",
            "       558 Integrated_Gradients      0.769985       0.864740           0.056858           0.489683  Spam\n",
            "       559 Integrated_Gradients      0.736681       0.895574           0.120408           0.686111  Spam\n",
            "       560 Integrated_Gradients      0.829821       0.882595           0.004673           0.580952  Spam\n",
            "       561 Integrated_Gradients      0.708394       0.875900           0.035465           0.384524  Spam\n",
            "       562 Integrated_Gradients      0.736517       0.895593           0.012953           0.357143  Spam\n",
            "       563 Integrated_Gradients      0.695707       0.903822           0.200201           0.293651  Spam\n",
            "       564 Integrated_Gradients      0.808097       0.878675           0.030356           0.440476  Spam\n",
            "       565 Integrated_Gradients      0.714785       0.841894           0.067136           0.303571  Spam\n",
            "       566 Integrated_Gradients      0.385787       0.835172           0.542842           0.430159  Spam\n",
            "       567 Integrated_Gradients      0.826420       0.926638           0.004376           0.513095  Spam\n",
            "       568 Integrated_Gradients      0.809207       0.923067           0.001227           0.450397  Spam\n",
            "       569 Integrated_Gradients      0.711922       0.908347           0.120495           0.191270  Spam\n",
            "       570 Integrated_Gradients      0.877682       0.908478           0.018942           0.523810  Spam\n",
            "       571 Integrated_Gradients      0.892024       0.908987           0.011696           0.652381  Spam\n",
            "       572 Integrated_Gradients      0.861990       0.911562           0.029610           0.465873  Spam\n",
            "       573 Integrated_Gradients      0.880792       0.886641           0.002110           0.505952  Spam\n",
            "       574 Integrated_Gradients      0.737446       0.058525           0.790327           0.370635  Spam\n",
            "       575 Integrated_Gradients      0.718467       0.503188           0.047256           0.448016  Spam\n",
            "       576 Integrated_Gradients      0.865026       0.922811           0.006161           0.414683  Spam\n",
            "       577 Integrated_Gradients      0.744623       0.880971           0.183627           0.462302  Spam\n",
            "       578 Integrated_Gradients      0.819563       0.912124           0.025461           0.535714  Spam\n",
            "       579 Integrated_Gradients      0.765196       0.702046           0.398826           0.344048  Spam\n",
            "       580 Integrated_Gradients      0.876245       0.893725           0.012949           0.359127  Spam\n",
            "       581 Integrated_Gradients      0.737392       0.525919           0.098172           0.274603  Spam\n",
            "       582 Integrated_Gradients      0.818783       0.800553           0.056124           0.215079  Spam\n",
            "       583 Integrated_Gradients      0.455836       0.613452           0.643225           0.172222  Spam\n",
            "       584 Integrated_Gradients      0.837146       0.806862           0.076003           0.481349  Spam\n",
            "       585 Integrated_Gradients      0.891395       0.892169           0.023500           0.710714  Spam\n",
            "       586 Integrated_Gradients      0.892101       0.000000           0.078647           1.000000  Spam\n",
            "       587 Integrated_Gradients      0.896217       0.913403           0.011240           0.588095  Spam\n",
            "       588 Integrated_Gradients      0.841897       0.805312           0.067699           0.361111  Spam\n",
            "       589 Integrated_Gradients      0.831977       0.890642           0.015728           0.511905  Spam\n",
            "       590 Integrated_Gradients      0.662153       0.837076           0.171641           0.535714  Spam\n",
            "       591 Integrated_Gradients      0.809405       0.849002           0.066573           0.293651  Spam\n",
            "       592 Integrated_Gradients      0.824789       0.913435           0.335128           0.540873  Spam\n",
            "       593 Integrated_Gradients      0.821646       0.567405           0.552507           0.244048  Spam\n",
            "       594 Integrated_Gradients      0.857482       0.777844           0.023826           0.282540  Spam\n",
            "       595 Integrated_Gradients      0.820399       0.917310           0.011553           0.537302  Spam\n",
            "       596 Integrated_Gradients      0.881137       0.861566           0.013424           0.602381  Spam\n",
            "       597 Integrated_Gradients      0.834106       0.850107           0.006920           0.349206  Spam\n",
            "       598 Integrated_Gradients      0.816168       0.837375           0.000179           0.364683  Spam\n",
            "       599 Integrated_Gradients      0.724566       0.832582           0.129759           0.726190  Spam\n",
            "       600 Integrated_Gradients      0.881970       0.868139           0.007540           0.349206  Spam\n",
            "       601 Integrated_Gradients      0.845407       0.887719           0.031088           0.465873  Spam\n",
            "       602 Integrated_Gradients      0.594187       0.444710           0.564256           0.371825  Spam\n",
            "       603 Integrated_Gradients      0.846331       0.767668           0.049100           0.229762  Spam\n",
            "       604 Integrated_Gradients      0.755331       0.826747           0.008041           0.316270  Spam\n",
            "       605 Integrated_Gradients      0.787173       0.894576           0.001132           0.264683  Spam\n",
            "       606 Integrated_Gradients      0.857049       0.864517           0.066490           0.242460  Spam\n",
            "         1      Attention_Heads      0.553344       0.120436           0.068414           0.553571   Ham\n",
            "         2      Attention_Heads      0.539277       0.141726           0.027357           0.345238   Ham\n",
            "         3      Attention_Heads      0.379974       0.126468           0.003247           0.604762   Ham\n",
            "         4      Attention_Heads      0.280834       0.063366           0.007177           0.474206   Ham\n",
            "         5      Attention_Heads      0.307057       0.072941           0.001085           0.586905   Ham\n",
            "         6      Attention_Heads      0.497930       0.270311           0.324000           0.709524   Ham\n",
            "         7      Attention_Heads      0.432965       0.121210           0.279043           0.742857   Ham\n",
            "         8      Attention_Heads      0.323997       0.067104           0.006480           0.464286   Ham\n",
            "         9      Attention_Heads      0.411349       0.422216           0.304515           0.866667   Ham\n",
            "        10      Attention_Heads      0.251745       0.191977           0.016235           0.422619   Ham\n",
            "        11      Attention_Heads      0.293086       0.158569           0.006082           0.410714   Ham\n",
            "        12      Attention_Heads      0.491507       0.159787           0.000798           0.390873   Ham\n",
            "        13      Attention_Heads      0.474299       0.073496           0.000329           0.373016   Ham\n",
            "        14      Attention_Heads      0.376706       0.083049           0.001860           0.380952   Ham\n",
            "        15      Attention_Heads      0.462547       0.074261           0.000330           0.442063   Ham\n",
            "        16      Attention_Heads      0.414517       0.174386           0.381332           0.521429   Ham\n",
            "        17      Attention_Heads      0.468982       0.867822           0.124636           0.577381   Ham\n",
            "        18      Attention_Heads      0.232933       0.181822           0.000251           0.612302   Ham\n",
            "        19      Attention_Heads      0.249849       0.265167           0.003286           0.349206   Ham\n",
            "        20      Attention_Heads      0.308627       0.101199           0.009175           0.349206   Ham\n",
            "        21      Attention_Heads      0.649724       0.282897           0.222610           0.503571   Ham\n",
            "        22      Attention_Heads      0.159012       0.204167           0.019320           0.571429   Ham\n",
            "        23      Attention_Heads      0.131449       0.078466           0.031441           0.444444   Ham\n",
            "        24      Attention_Heads      0.274970       0.575834           0.018991           0.676190   Ham\n",
            "        25      Attention_Heads      0.214389       0.119429           0.008565           0.367063   Ham\n",
            "        26      Attention_Heads      0.254332       0.222835           0.095372           0.418254   Ham\n",
            "        27      Attention_Heads      0.209451       0.132484           0.002363           0.596429   Ham\n",
            "        28      Attention_Heads      0.182070       0.187738           0.003907           0.531349   Ham\n",
            "        29      Attention_Heads      0.184604       0.126329           0.038511           0.462302   Ham\n",
            "        30      Attention_Heads      0.286491       0.099368           0.130208           0.628571   Ham\n",
            "        31      Attention_Heads      0.263178       0.118590           0.050018           0.498016   Ham\n",
            "        32      Attention_Heads      0.165018       0.107054           0.017763           0.521429   Ham\n",
            "        33      Attention_Heads      0.301576       0.247956           0.011157           0.685714   Ham\n",
            "        34      Attention_Heads      0.300111       0.264775           0.003373           0.710714   Ham\n",
            "        35      Attention_Heads      0.250278       0.238057           0.002240           0.505952   Ham\n",
            "        36      Attention_Heads      0.263380       0.288081           0.006243           0.582540   Ham\n",
            "        37      Attention_Heads      0.124188       0.220029           0.004082           0.573016   Ham\n",
            "        38      Attention_Heads      0.224457       0.136347           0.006255           0.375000   Ham\n",
            "        39      Attention_Heads      0.242100       0.192067           0.032023           0.531349   Ham\n",
            "        40      Attention_Heads      0.231533       0.090386           0.001891           0.582540   Ham\n",
            "        41      Attention_Heads      0.714584       0.507773           0.711566           0.676190   Ham\n",
            "        42      Attention_Heads      0.249887       0.111363           0.058047           0.434524   Ham\n",
            "        43      Attention_Heads      0.221958       0.285923           0.080786           0.426587   Ham\n",
            "        44      Attention_Heads      0.365468       0.124088           0.012302           0.809524   Ham\n",
            "        45      Attention_Heads      0.335594       0.476431           0.032399           0.595238   Ham\n",
            "        46      Attention_Heads      0.528341       0.384533           0.182861           0.650000   Ham\n",
            "        47      Attention_Heads      0.383929       0.245712           0.005545           0.563095   Ham\n",
            "        48      Attention_Heads      0.307569       0.263793           0.043378           0.720635   Ham\n",
            "        49      Attention_Heads      0.385566       0.406485           0.047101           0.776190   Ham\n",
            "        50      Attention_Heads      0.244697       0.441560           0.012623           0.465873   Ham\n",
            "        51      Attention_Heads      0.401123       0.279105           0.035217           0.563095   Ham\n",
            "        52      Attention_Heads      0.570099       0.540773           0.646751           0.521429   Ham\n",
            "        53      Attention_Heads      0.460091       0.323737           0.111000           0.653571   Ham\n",
            "        54      Attention_Heads      0.507212       0.535558           0.231150           0.539286   Ham\n",
            "        55      Attention_Heads      0.319635       0.361546           0.087521           0.695238   Ham\n",
            "        56      Attention_Heads      0.366402       0.096319           0.004823           0.420238   Ham\n",
            "        57      Attention_Heads      0.359835       0.053823           0.001331           0.384921   Ham\n",
            "        58      Attention_Heads      0.180978       0.057700           0.003939           0.432540   Ham\n",
            "        59      Attention_Heads      0.152830       0.067357           0.014331           0.408730   Ham\n",
            "        60      Attention_Heads      0.358491       0.068198           0.002114           0.376984   Ham\n",
            "        61      Attention_Heads      0.402279       0.065240           0.004257           0.444444   Ham\n",
            "        62      Attention_Heads      0.276584       0.084372           0.001285           0.285317   Ham\n",
            "        63      Attention_Heads      0.196105       0.063366           0.052104           0.408730   Ham\n",
            "        64      Attention_Heads      0.391738       0.061321           0.001311           0.432143   Ham\n",
            "        65      Attention_Heads      0.362214       0.099621           0.026894           0.434524   Ham\n",
            "        66      Attention_Heads      0.461812       0.070405           0.002004           0.483730   Ham\n",
            "        67      Attention_Heads      0.319762       0.133474           0.001680           0.426587   Ham\n",
            "        68      Attention_Heads      0.229084       0.051802           0.002449           0.335317   Ham\n",
            "        69      Attention_Heads      0.110635       0.080599           0.001360           0.450397   Ham\n",
            "        70      Attention_Heads      0.176063       0.181457           0.034571           0.226190   Ham\n",
            "        71      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "        72      Attention_Heads      0.188397       0.065537           0.020336           0.431746   Ham\n",
            "        73      Attention_Heads      0.356138       0.286194           0.351273           0.800000   Ham\n",
            "        74      Attention_Heads      0.257058       0.125467           0.001915           0.571429   Ham\n",
            "        75      Attention_Heads      0.237985       0.239706           0.000035           0.578968   Ham\n",
            "        76      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "        77      Attention_Heads      0.356138       0.286194           0.351273           0.909524   Ham\n",
            "        78      Attention_Heads      0.356138       0.286194           0.351273           0.719048   Ham\n",
            "        79      Attention_Heads      0.235945       0.090901           0.010685           0.422619   Ham\n",
            "        80      Attention_Heads      0.351691       0.103387           0.070683           0.253968   Ham\n",
            "        81      Attention_Heads      0.228256       0.053267           0.002077           0.426587   Ham\n",
            "        82      Attention_Heads      0.366793       0.073544           0.003659           0.474206   Ham\n",
            "        83      Attention_Heads      0.287688       0.055041           0.006880           0.253968   Ham\n",
            "        84      Attention_Heads      0.266669       0.052493           0.004279           0.523016   Ham\n",
            "        85      Attention_Heads      0.211226       0.074698           0.001464           0.384921   Ham\n",
            "        86      Attention_Heads      0.319407       0.066204           0.001497           0.343254   Ham\n",
            "        87      Attention_Heads      0.279971       0.075230           0.002969           0.685714   Ham\n",
            "        88      Attention_Heads      0.468823       0.091538           0.020964           0.547619   Ham\n",
            "        89      Attention_Heads      0.433744       0.069900           0.029713           0.432540   Ham\n",
            "        90      Attention_Heads      0.357615       0.054453           0.016218           0.586905   Ham\n",
            "        91      Attention_Heads      0.179753       0.061156           0.003077           0.531349   Ham\n",
            "        92      Attention_Heads      0.303063       0.138478           0.038807           0.448016   Ham\n",
            "        93      Attention_Heads      0.389801       0.073872           0.096059           0.313492   Ham\n",
            "        94      Attention_Heads      0.205513       0.155596           0.026103           0.344048   Ham\n",
            "        95      Attention_Heads      0.471564       0.222604           0.162137           0.477778   Ham\n",
            "        96      Attention_Heads      0.220348       0.054755           0.000873           0.386905   Ham\n",
            "        97      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "        98      Attention_Heads      0.356138       0.286194           0.351273           0.742857   Ham\n",
            "        99      Attention_Heads      0.459948       0.162016           0.000295           0.577381   Ham\n",
            "       100      Attention_Heads      0.507894       0.086512           0.057827           0.371032   Ham\n",
            "       101      Attention_Heads      0.411076       0.205078           0.710886           0.303571   Ham\n",
            "       102      Attention_Heads      0.265983       0.060593           0.002594           0.440476   Ham\n",
            "       103      Attention_Heads      0.400494       0.280093           0.010073           0.414683   Ham\n",
            "       104      Attention_Heads      0.403274       0.071067           0.007684           0.357143   Ham\n",
            "       105      Attention_Heads      0.356138       0.286194           0.351273           0.752381   Ham\n",
            "       106      Attention_Heads      0.356138       0.286194           0.351273           0.900000   Ham\n",
            "       107      Attention_Heads      0.474534       0.064078           0.001704           0.375000   Ham\n",
            "       108      Attention_Heads      0.407162       0.057587           0.006301           0.315476   Ham\n",
            "       109      Attention_Heads      0.356138       0.286194           0.351273           0.665079   Ham\n",
            "       110      Attention_Heads      0.184186       0.063953           0.023107           0.432540   Ham\n",
            "       111      Attention_Heads      0.404864       0.105248           0.045675           0.434524   Ham\n",
            "       112      Attention_Heads      0.515163       0.372547           0.128860           0.404762   Ham\n",
            "       113      Attention_Heads      0.234453       0.134258           0.001872           0.422619   Ham\n",
            "       114      Attention_Heads      0.360643       0.064168           0.000756           0.434524   Ham\n",
            "       115      Attention_Heads      0.356138       0.286194           0.351273           0.900000   Ham\n",
            "       116      Attention_Heads      0.356138       0.286194           0.351273           0.776190   Ham\n",
            "       117      Attention_Heads      0.356138       0.286194           0.351273           0.785714   Ham\n",
            "       118      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       119      Attention_Heads      0.356138       0.286194           0.351273           0.776190   Ham\n",
            "       120      Attention_Heads      0.304553       0.066589           0.022687           0.446429   Ham\n",
            "       121      Attention_Heads      0.444754       0.176150           0.137196           0.529762   Ham\n",
            "       122      Attention_Heads      0.279978       0.099665           0.006758           0.380952   Ham\n",
            "       123      Attention_Heads      0.138694       0.211870           0.596798           0.456349   Ham\n",
            "       124      Attention_Heads      0.272767       0.160407           0.262304           0.345238   Ham\n",
            "       125      Attention_Heads      0.198288       0.384430           0.028148           0.638095   Ham\n",
            "       126      Attention_Heads      0.433031       0.410064           0.038841           0.610714   Ham\n",
            "       127      Attention_Heads      0.223928       0.128509           0.049021           0.586905   Ham\n",
            "       128      Attention_Heads      0.311576       0.229237           0.067110           0.685714   Ham\n",
            "       129      Attention_Heads      0.179978       0.215602           0.002441           0.505952   Ham\n",
            "       130      Attention_Heads      0.190009       0.136760           0.000755           0.511905   Ham\n",
            "       131      Attention_Heads      0.161422       0.121082           0.009501           0.363095   Ham\n",
            "       132      Attention_Heads      0.217752       0.088783           0.001828           0.440476   Ham\n",
            "       133      Attention_Heads      0.283200       0.111646           0.634277           0.357143   Ham\n",
            "       134      Attention_Heads      0.237576       0.413373           0.034145           0.488095   Ham\n",
            "       135      Attention_Heads      0.156309       0.159223           0.000136           0.507540   Ham\n",
            "       136      Attention_Heads      0.422295       0.332267           0.370305           0.673016   Ham\n",
            "       137      Attention_Heads      0.204446       0.191528           0.000198           0.418651   Ham\n",
            "       138      Attention_Heads      0.387163       0.099785           0.069791           0.776190   Ham\n",
            "       139      Attention_Heads      0.125271       0.197067           0.031713           0.396825   Ham\n",
            "       140      Attention_Heads      0.213223       0.169914           0.005945           0.549206   Ham\n",
            "       141      Attention_Heads      0.280643       0.178563           0.009080           0.652381   Ham\n",
            "       142      Attention_Heads      0.244306       0.270630           0.026884           0.728571   Ham\n",
            "       143      Attention_Heads      0.363440       0.356128           0.075595           0.719048   Ham\n",
            "       144      Attention_Heads      0.330689       0.325300           0.047289           0.776190   Ham\n",
            "       145      Attention_Heads      0.394829       0.506390           0.206486           0.709524   Ham\n",
            "       146      Attention_Heads      0.261450       0.132182           0.002903           0.482143   Ham\n",
            "       147      Attention_Heads      0.499320       0.224118           0.325996           0.652381   Ham\n",
            "       148      Attention_Heads      0.367875       0.257148           0.106498           0.776190   Ham\n",
            "       149      Attention_Heads      0.184610       0.446567           0.001188           0.577381   Ham\n",
            "       150      Attention_Heads      0.417026       0.394434           0.014418           0.610714   Ham\n",
            "       151      Attention_Heads      0.257583       0.539087           0.054536           0.638095   Ham\n",
            "       152      Attention_Heads      0.211721       0.368730           0.010520           0.426587   Ham\n",
            "       153      Attention_Heads      0.171781       0.072790           0.002805           0.602381   Ham\n",
            "       154      Attention_Heads      0.363107       0.286251           0.115707           0.677381   Ham\n",
            "       155      Attention_Heads      0.584140       0.429017           0.466886           0.776190   Ham\n",
            "       156      Attention_Heads      0.387702       0.245524           0.117338           0.545238   Ham\n",
            "       157      Attention_Heads      0.336041       0.307876           0.012559           0.776190   Ham\n",
            "       158      Attention_Heads      0.359510       0.104925           0.005273           0.734524   Ham\n",
            "       159      Attention_Heads      0.129931       0.072882           0.000286           0.584127   Ham\n",
            "       160      Attention_Heads      0.297810       0.087200           0.015063           0.313492   Ham\n",
            "       161      Attention_Heads      0.183485       0.075414           0.007424           0.776190   Ham\n",
            "       162      Attention_Heads      0.293248       0.068636           0.002828           0.606349   Ham\n",
            "       163      Attention_Heads      0.375110       0.069745           0.013761           0.436508   Ham\n",
            "       164      Attention_Heads      0.198373       0.068581           0.001371           0.474206   Ham\n",
            "       165      Attention_Heads      0.151532       0.062770           0.000275           0.588492   Ham\n",
            "       166      Attention_Heads      0.280407       0.060391           0.000319           0.363095   Ham\n",
            "       167      Attention_Heads      0.362475       0.051452           0.012678           0.563492   Ham\n",
            "       168      Attention_Heads      0.209813       0.077867           0.004012           0.547619   Ham\n",
            "       169      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       170      Attention_Heads      0.356138       0.286194           0.351273           0.825000   Ham\n",
            "       171      Attention_Heads      0.418041       0.101855           0.000549           0.432540   Ham\n",
            "       172      Attention_Heads      0.356138       0.286194           0.351273           0.766667   Ham\n",
            "       173      Attention_Heads      0.356138       0.286194           0.351273           0.933333   Ham\n",
            "       174      Attention_Heads      0.251883       0.078656           0.000321           0.299603   Ham\n",
            "       175      Attention_Heads      0.356138       0.286194           0.351273           0.752381   Ham\n",
            "       176      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       177      Attention_Heads      0.356138       0.286194           0.351273           0.825000   Ham\n",
            "       178      Attention_Heads      0.356138       0.286194           0.351273           0.752381   Ham\n",
            "       179      Attention_Heads      0.356138       0.286194           0.351273           0.809524   Ham\n",
            "       180      Attention_Heads      0.367027       0.098464           0.002350           0.343254   Ham\n",
            "       181      Attention_Heads      0.136446       0.060928           0.000970           0.569048   Ham\n",
            "       182      Attention_Heads      0.475545       0.516257           0.219736           0.265873   Ham\n",
            "       183      Attention_Heads      0.208132       0.170743           0.004095           0.364683   Ham\n",
            "       184      Attention_Heads      0.224287       0.324183           0.001691           0.497619   Ham\n",
            "       185      Attention_Heads      0.469193       0.088920           0.002756           0.470238   Ham\n",
            "       186      Attention_Heads      0.200485       0.052485           0.000097           0.545635   Ham\n",
            "       187      Attention_Heads      0.160620       0.053844           0.002219           0.430159   Ham\n",
            "       188      Attention_Heads      0.435785       0.056887           0.012749           0.563095   Ham\n",
            "       189      Attention_Heads      0.356138       0.286194           0.351273           0.809524   Ham\n",
            "       190      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       191      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       192      Attention_Heads      0.368547       0.098997           0.001055           0.408730   Ham\n",
            "       193      Attention_Heads      0.545769       0.835374           0.388532           0.497619   Ham\n",
            "       194      Attention_Heads      0.273926       0.774306           0.860855           0.685714   Ham\n",
            "       195      Attention_Heads      0.464053       0.061882           0.005685           0.329365   Ham\n",
            "       196      Attention_Heads      0.645865       0.071195           0.367977           0.345238   Ham\n",
            "       197      Attention_Heads      0.478468       0.164400           0.033684           0.592857   Ham\n",
            "       198      Attention_Heads      0.196691       0.069015           0.079344           0.521429   Ham\n",
            "       199      Attention_Heads      0.106232       0.073208           0.002333           0.349206   Ham\n",
            "       200      Attention_Heads      0.268994       0.090276           0.003224           0.424603   Ham\n",
            "       201      Attention_Heads      0.454030       0.122754           0.104430           0.644048   Ham\n",
            "       202      Attention_Heads      0.509753       0.172151           0.026257           0.482143   Ham\n",
            "       203      Attention_Heads      0.218682       0.145444           0.000244           0.577381   Ham\n",
            "       204      Attention_Heads      0.349691       0.072156           0.002277           0.351190   Ham\n",
            "       205      Attention_Heads      0.273447       0.077956           0.003120           0.498016   Ham\n",
            "       206      Attention_Heads      0.271938       0.053450           0.001288           0.331349   Ham\n",
            "       207      Attention_Heads      0.288521       0.052754           0.000973           0.348016   Ham\n",
            "       208      Attention_Heads      0.289922       0.159806           0.001954           0.349206   Ham\n",
            "       209      Attention_Heads      0.252338       0.157605           0.002964           0.422619   Ham\n",
            "       210      Attention_Heads      0.272870       0.062062           0.004285           0.275794   Ham\n",
            "       211      Attention_Heads      0.185659       0.065518           0.001713           0.420238   Ham\n",
            "       212      Attention_Heads      0.220137       0.141856           0.001878           0.323413   Ham\n",
            "       213      Attention_Heads      0.509753       0.172151           0.026257           0.529762   Ham\n",
            "       214      Attention_Heads      0.245695       0.083557           0.000583           0.422619   Ham\n",
            "       215      Attention_Heads      0.322992       0.057348           0.000053           0.390873   Ham\n",
            "       216      Attention_Heads      0.378818       0.266610           0.006405           0.473810   Ham\n",
            "       217      Attention_Heads      0.382368       0.062190           0.031495           0.303571   Ham\n",
            "       218      Attention_Heads      0.297240       0.096112           0.001364           0.493651   Ham\n",
            "       219      Attention_Heads      0.380363       0.100794           0.364962           0.450397   Ham\n",
            "       220      Attention_Heads      0.249392       0.144616           0.001741           0.499603   Ham\n",
            "       221      Attention_Heads      0.213941       0.066617           0.002206           0.331349   Ham\n",
            "       222      Attention_Heads      0.224590       0.095147           0.003403           0.267857   Ham\n",
            "       223      Attention_Heads      0.174707       0.052830           0.003175           0.596825   Ham\n",
            "       224      Attention_Heads      0.230594       0.057964           0.000294           0.482143   Ham\n",
            "       225      Attention_Heads      0.204223       0.054085           0.000755           0.529762   Ham\n",
            "       226      Attention_Heads      0.189468       0.205847           0.003413           0.414683   Ham\n",
            "       227      Attention_Heads      0.147238       0.099501           0.003902           0.428571   Ham\n",
            "       228      Attention_Heads      0.269080       0.222419           0.017868           0.271825   Ham\n",
            "       229      Attention_Heads      0.182897       0.076310           0.001966           0.474206   Ham\n",
            "       230      Attention_Heads      0.296165       0.162000           0.063186           0.464286   Ham\n",
            "       231      Attention_Heads      0.401760       0.398653           0.729734           0.551190   Ham\n",
            "       232      Attention_Heads      0.221849       0.154414           0.005286           0.545238   Ham\n",
            "       233      Attention_Heads      0.307860       0.289042           0.229714           0.483730   Ham\n",
            "       234      Attention_Heads      0.177569       0.160785           0.009843           0.393651   Ham\n",
            "       235      Attention_Heads      0.333039       0.152463           0.007800           0.507937   Ham\n",
            "       236      Attention_Heads      0.458683       0.281541           0.070302           0.505952   Ham\n",
            "       237      Attention_Heads      0.262254       0.319637           0.267885           0.728571   Ham\n",
            "       238      Attention_Heads      0.269872       0.115384           0.120367           0.438095   Ham\n",
            "       239      Attention_Heads      0.452595       0.158057           0.155094           0.652381   Ham\n",
            "       240      Attention_Heads      0.355432       0.279820           0.006316           0.488095   Ham\n",
            "       241      Attention_Heads      0.264285       0.063416           0.008886           0.363095   Ham\n",
            "       242      Attention_Heads      0.254545       0.075766           0.000931           0.402778   Ham\n",
            "       243      Attention_Heads      0.240233       0.261116           0.029999           0.709524   Ham\n",
            "       244      Attention_Heads      0.241465       0.207327           0.001892           0.470238   Ham\n",
            "       245      Attention_Heads      0.462769       0.456879           0.195034           0.725000   Ham\n",
            "       246      Attention_Heads      0.402938       0.497507           0.340435           0.685714   Ham\n",
            "       247      Attention_Heads      0.166299       0.265814           0.000090           0.677381   Ham\n",
            "       248      Attention_Heads      0.435319       0.224549           0.009440           0.700000   Ham\n",
            "       249      Attention_Heads      0.271916       0.386989           0.000045           0.349206   Ham\n",
            "       250      Attention_Heads      0.397191       0.133044           0.008494           0.446429   Ham\n",
            "       251      Attention_Heads      0.321724       0.218041           0.000068           0.728571   Ham\n",
            "       252      Attention_Heads      0.356704       0.360876           0.129347           0.776190   Ham\n",
            "       253      Attention_Heads      0.348867       0.175627           0.125012           0.800000   Ham\n",
            "       254      Attention_Heads      0.427892       0.464495           0.097682           0.742857   Ham\n",
            "       255      Attention_Heads      0.307489       0.284263           0.001888           0.422619   Ham\n",
            "       256      Attention_Heads      0.330420       0.107209           0.044196           0.776190   Ham\n",
            "       257      Attention_Heads      0.221763       0.060654           0.003396           0.349206   Ham\n",
            "       258      Attention_Heads      0.285325       0.066416           0.000118           0.483730   Ham\n",
            "       259      Attention_Heads      0.236927       0.080930           0.001552           0.450397   Ham\n",
            "       260      Attention_Heads      0.169844       0.052293           0.004176           0.450397   Ham\n",
            "       261      Attention_Heads      0.265591       0.060070           0.000491           0.442460   Ham\n",
            "       262      Attention_Heads      0.254756       0.062068           0.002920           0.564683   Ham\n",
            "       263      Attention_Heads      0.393622       0.051909           0.000718           0.482143   Ham\n",
            "       264      Attention_Heads      0.347396       0.054763           0.001386           0.463492   Ham\n",
            "       265      Attention_Heads      0.139032       0.056661           0.002916           0.414683   Ham\n",
            "       266      Attention_Heads      0.316882       0.051495           0.003801           0.638095   Ham\n",
            "       267      Attention_Heads      0.439713       0.105261           0.003118           0.557143   Ham\n",
            "       268      Attention_Heads      0.252427       0.050471           0.001002           0.480159   Ham\n",
            "       269      Attention_Heads      0.385789       0.098469           0.002959           0.281746   Ham\n",
            "       270      Attention_Heads      0.344618       0.059250           0.002306           0.507540   Ham\n",
            "       271      Attention_Heads      0.580631       0.069490           0.003709           0.398810   Ham\n",
            "       272      Attention_Heads      0.155507       0.076040           0.001226           0.549206   Ham\n",
            "       273      Attention_Heads      0.130104       0.052602           0.000249           0.267857   Ham\n",
            "       274      Attention_Heads      0.326723       0.060164           0.006698           0.394841   Ham\n",
            "       275      Attention_Heads      0.173587       0.073386           0.000091           0.257937   Ham\n",
            "       276      Attention_Heads      0.296412       0.056860           0.006078           0.476190   Ham\n",
            "       277      Attention_Heads      0.685753       0.132363           0.614751           0.257937   Ham\n",
            "       278      Attention_Heads      0.733831       0.325731           0.229135           0.488095   Ham\n",
            "       279      Attention_Heads      0.510820       0.115506           0.011540           0.476190   Ham\n",
            "       280      Attention_Heads      0.342455       0.071070           0.010152           0.267857   Ham\n",
            "       281      Attention_Heads      0.190321       0.102100           0.008257           0.458333   Ham\n",
            "       282      Attention_Heads      0.419546       0.085178           0.019264           0.375000   Ham\n",
            "       283      Attention_Heads      0.301098       0.057477           0.005087           0.542857   Ham\n",
            "       284      Attention_Heads      0.733831       0.325731           0.229135           0.513492   Ham\n",
            "       285      Attention_Heads      0.491286       0.055312           0.014038           0.353175   Ham\n",
            "       286      Attention_Heads      0.231667       0.182231           0.004471           0.505952   Ham\n",
            "       287      Attention_Heads      0.290305       0.226550           0.000509           0.336905   Ham\n",
            "       288      Attention_Heads      0.248834       0.070977           0.013856           0.394841   Ham\n",
            "       289      Attention_Heads      0.255862       0.090483           0.000299           0.505952   Ham\n",
            "       290      Attention_Heads      0.388847       0.106015           0.069615           0.321429   Ham\n",
            "       291      Attention_Heads      0.264511       0.284063           0.112722           0.620238   Ham\n",
            "       292      Attention_Heads      0.196791       0.118181           0.000154           0.474206   Ham\n",
            "       293      Attention_Heads      0.116251       0.128658           0.045654           0.620238   Ham\n",
            "       294      Attention_Heads      0.181260       0.164859           0.034685           0.426587   Ham\n",
            "       295      Attention_Heads      0.327767       0.158185           0.017421           0.752381   Ham\n",
            "       296      Attention_Heads      0.346260       0.350574           0.240332           0.695238   Ham\n",
            "       297      Attention_Heads      0.201845       0.278594           0.028047           0.572619   Ham\n",
            "       298      Attention_Heads      0.234021       0.276239           0.001090           0.692857   Ham\n",
            "       299      Attention_Heads      0.376235       0.301924           0.026883           0.710714   Ham\n",
            "       300      Attention_Heads      0.302917       0.230095           0.117167           0.667857   Ham\n",
            "       301      Attention_Heads      0.340298       0.273184           0.001784           0.728571   Ham\n",
            "       302      Attention_Heads      0.481215       0.297545           0.009439           0.529762   Ham\n",
            "       303      Attention_Heads      0.483174       0.795405           0.254191           0.616667   Ham\n",
            "       304      Attention_Heads      0.289380       0.586027           0.154770           0.604762   Ham\n",
            "       305      Attention_Heads      0.284281       0.464981           0.000729           0.833333   Ham\n",
            "       306      Attention_Heads      0.235956       0.209979           0.010830           0.742857   Ham\n",
            "       307      Attention_Heads      0.586031       0.546493           0.698123           0.586905   Ham\n",
            "       308      Attention_Heads      0.335876       0.278328           0.126715           0.676190   Ham\n",
            "       309      Attention_Heads      0.244131       0.240705           0.001948           0.539286   Ham\n",
            "       310      Attention_Heads      0.471409       0.455515           0.022883           0.628571   Ham\n",
            "       311      Attention_Heads      0.436983       0.343882           0.047044           0.629762   Ham\n",
            "       312      Attention_Heads      0.386632       0.276399           0.073695           0.725000   Ham\n",
            "       313      Attention_Heads      0.330013       0.372092           0.019620           0.492063   Ham\n",
            "       314      Attention_Heads      0.537634       0.168248           0.120586           0.661905   Ham\n",
            "       315      Attention_Heads      0.272895       0.235916           0.006809           0.529762   Ham\n",
            "       316      Attention_Heads      0.245885       0.363039           0.072724           0.661905   Ham\n",
            "       317      Attention_Heads      0.360132       0.303948           0.023075           0.558730   Ham\n",
            "       318      Attention_Heads      0.348709       0.193370           0.125482           0.795238   Ham\n",
            "       319      Attention_Heads      0.322711       0.177203           0.009270           0.482143   Ham\n",
            "       320      Attention_Heads      0.255165       0.053217           0.003492           0.257937   Ham\n",
            "       321      Attention_Heads      0.324801       0.054784           0.014588           0.503571   Ham\n",
            "       322      Attention_Heads      0.282713       0.062290           0.002728           0.327381   Ham\n",
            "       323      Attention_Heads      0.346821       0.179684           0.061032           0.596429   Ham\n",
            "       324      Attention_Heads      0.389234       0.248667           0.088226           0.580952   Ham\n",
            "       325      Attention_Heads      0.749210       0.120703           0.320683           0.553571   Ham\n",
            "       326      Attention_Heads      0.689864       0.889202           0.254669           0.866667   Ham\n",
            "       327      Attention_Heads      0.720985       0.833031           0.099064           0.465873   Ham\n",
            "       328      Attention_Heads      0.313368       0.371710           0.005223           0.418651   Ham\n",
            "       329      Attention_Heads      0.452034       0.761014           0.120571           0.428571   Ham\n",
            "       330      Attention_Heads      0.261435       0.248521           0.165800           0.289683   Ham\n",
            "       331      Attention_Heads      0.321203       0.058765           0.005167           0.293651   Ham\n",
            "       332      Attention_Heads      0.426815       0.082628           0.025171           0.307540   Ham\n",
            "       333      Attention_Heads      0.705461       0.893000           0.515563           1.000000   Ham\n",
            "       334      Attention_Heads      0.621052       0.190148           0.745534           0.261905   Ham\n",
            "       335      Attention_Heads      0.299898       0.196289           0.181543           0.412698   Ham\n",
            "       336      Attention_Heads      0.356138       0.286194           0.351273           0.900000   Ham\n",
            "       337      Attention_Heads      0.744942       0.902128           0.014921           0.428571   Ham\n",
            "       338      Attention_Heads      0.356138       0.286194           0.351273           0.800000   Ham\n",
            "       339      Attention_Heads      0.356138       0.286194           0.351273           0.876190   Ham\n",
            "       340      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       341      Attention_Heads      0.367019       0.217895           0.030837           0.464286   Ham\n",
            "       342      Attention_Heads      0.481027       0.056855           0.051543           0.367063   Ham\n",
            "       343      Attention_Heads      0.356138       0.286194           0.351273           0.725000   Ham\n",
            "       344      Attention_Heads      0.271849       0.136472           0.004076           0.661905   Ham\n",
            "       345      Attention_Heads      0.579123       0.062908           0.415079           0.553571   Ham\n",
            "       346      Attention_Heads      0.121271       0.053919           0.001654           0.296429   Ham\n",
            "       347      Attention_Heads      0.301832       0.095319           0.002155           0.529762   Ham\n",
            "       348      Attention_Heads      0.298182       0.099298           0.004924           0.392857   Ham\n",
            "       349      Attention_Heads      0.262199       0.081916           0.003896           0.386508   Ham\n",
            "       350      Attention_Heads      0.127171       0.065195           0.002199           0.335317   Ham\n",
            "       351      Attention_Heads      0.411430       0.120471           0.013071           0.357143   Ham\n",
            "       352      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       353      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       354      Attention_Heads      0.356138       0.286194           0.351273           0.900000   Ham\n",
            "       355      Attention_Heads      0.364093       0.054573           0.005996           0.619048   Ham\n",
            "       356      Attention_Heads      0.170963       0.057807           0.001909           0.785714   Ham\n",
            "       357      Attention_Heads      0.181176       0.060572           0.003550           0.337302   Ham\n",
            "       358      Attention_Heads      0.226966       0.248930           0.016277           0.464286   Ham\n",
            "       359      Attention_Heads      0.227086       0.097528           0.007380           0.375000   Ham\n",
            "       360      Attention_Heads      0.242288       0.094176           0.000999           0.461905   Ham\n",
            "       361      Attention_Heads      0.356138       0.286194           0.351273           0.696825   Ham\n",
            "       362      Attention_Heads      0.356138       0.286194           0.351273           0.809524   Ham\n",
            "       363      Attention_Heads      0.356138       0.286194           0.351273           0.776190   Ham\n",
            "       364      Attention_Heads      0.356138       0.286194           0.351273           0.933333   Ham\n",
            "       365      Attention_Heads      0.356138       0.286194           0.351273           0.933333   Ham\n",
            "       366      Attention_Heads      0.356138       0.286194           0.351273           0.734524   Ham\n",
            "       367      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       368      Attention_Heads      0.356138       0.286194           0.351273           0.800000   Ham\n",
            "       369      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       370      Attention_Heads      0.256481       0.181395           0.018100           0.303571   Ham\n",
            "       371      Attention_Heads      0.301989       0.058236           0.000836           0.373016   Ham\n",
            "       372      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       373      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       374      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       375      Attention_Heads      0.356138       0.286194           0.351273           0.858333   Ham\n",
            "       376      Attention_Heads      0.421747       0.394974           0.363499           0.530952   Ham\n",
            "       377      Attention_Heads      0.290305       0.226550           0.000509           0.563095   Ham\n",
            "       378      Attention_Heads      0.356138       0.286194           0.351273           0.776190   Ham\n",
            "       379      Attention_Heads      0.356138       0.286194           0.351273           0.800000   Ham\n",
            "       380      Attention_Heads      0.308520       0.097665           0.003787           0.580952   Ham\n",
            "       381      Attention_Heads      0.356138       0.286194           0.351273           0.709524   Ham\n",
            "       382      Attention_Heads      0.537140       0.162191           0.106197           0.488095   Ham\n",
            "       383      Attention_Heads      0.356138       0.286194           0.351273           0.942857   Ham\n",
            "       384      Attention_Heads      0.356138       0.286194           0.351273           0.725000   Ham\n",
            "       385      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       386      Attention_Heads      0.356138       0.286194           0.351273           0.742857   Ham\n",
            "       387      Attention_Heads      0.356138       0.286194           0.351273           0.842857   Ham\n",
            "       388      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       389      Attention_Heads      0.356138       0.286194           0.351273           0.709524   Ham\n",
            "       390      Attention_Heads      0.250899       0.066482           0.001000           0.390873   Ham\n",
            "       391      Attention_Heads      0.356138       0.286194           0.351273           0.866667   Ham\n",
            "       392      Attention_Heads      0.415115       0.194891           0.023572           0.434127   Ham\n",
            "       393      Attention_Heads      0.356138       0.286194           0.351273           0.785714   Ham\n",
            "       394      Attention_Heads      0.366380       0.404311           0.378048           0.440476   Ham\n",
            "       395      Attention_Heads      0.735862       0.645582           0.032754           0.416667   Ham\n",
            "       396      Attention_Heads      0.356138       0.286194           0.351273           0.800000   Ham\n",
            "       397      Attention_Heads      0.356138       0.286194           0.351273           0.753968   Ham\n",
            "       398      Attention_Heads      0.204564       0.062444           0.001405           0.426587   Ham\n",
            "       399      Attention_Heads      0.356138       0.286194           0.351273           0.933333   Ham\n",
            "       400      Attention_Heads      0.358069       0.127172           0.003413           0.547619   Ham\n",
            "       401      Attention_Heads      0.211220       0.068453           0.006427           0.464286   Ham\n",
            "       402      Attention_Heads      0.248343       0.205276           0.001628           0.475794   Ham\n",
            "       403      Attention_Heads      0.231318       0.058712           0.003453           0.416667   Ham\n",
            "       404      Attention_Heads      0.356138       0.286194           0.351273           0.966667   Ham\n",
            "       405      Attention_Heads      0.202157       0.106556           0.002662           0.494048   Ham\n",
            "       406      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       407      Attention_Heads      0.356138       0.286194           0.351273           0.791667   Ham\n",
            "       408      Attention_Heads      0.468532       0.059535           0.000772           0.302381   Ham\n",
            "       409      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       410      Attention_Heads      0.356138       0.286194           0.351273           0.833333   Ham\n",
            "       411      Attention_Heads      0.150730       0.053691           0.002462           0.319048   Ham\n",
            "       412      Attention_Heads      0.241485       0.091792           0.005463           0.606349   Ham\n",
            "       413      Attention_Heads      0.166901       0.066969           0.004699           0.499603   Ham\n",
            "       414      Attention_Heads      0.270351       0.053085           0.002685           0.376984   Ham\n",
            "       415      Attention_Heads      0.163631       0.069372           0.003941           0.549206   Ham\n",
            "       416      Attention_Heads      0.777875       0.912537           0.114736           0.785714  Spam\n",
            "       417      Attention_Heads      0.732390       0.893912           0.025586           0.577381  Spam\n",
            "       418      Attention_Heads      0.763742       0.836289           0.141280           0.596429  Spam\n",
            "       419      Attention_Heads      0.761004       0.923838           0.142247           0.417063  Spam\n",
            "       420      Attention_Heads      0.704973       0.911228           0.005171           0.416667  Spam\n",
            "       421      Attention_Heads      0.726090       0.852494           0.030553           0.416667  Spam\n",
            "       422      Attention_Heads      0.785043       0.867602           0.048760           0.498016  Spam\n",
            "       423      Attention_Heads      0.799134       0.733753           0.053142           0.329365  Spam\n",
            "       424      Attention_Heads      0.754076       0.903534           0.097225           0.777381  Spam\n",
            "       425      Attention_Heads      0.786286       0.843486           0.022866           0.297619  Spam\n",
            "       426      Attention_Heads      0.757126       0.930560           0.043658           0.776190  Spam\n",
            "       427      Attention_Heads      0.698508       0.863540           0.173022           0.244048  Spam\n",
            "       428      Attention_Heads      0.638799       0.851315           0.053022           0.492063  Spam\n",
            "       429      Attention_Heads      0.842491       0.886218           0.118955           0.380952  Spam\n",
            "       430      Attention_Heads      0.753431       0.906970           0.050533           0.728571  Spam\n",
            "       431      Attention_Heads      0.721004       0.885446           0.016595           0.375000  Spam\n",
            "       432      Attention_Heads      0.765744       0.906107           0.014027           0.339286  Spam\n",
            "       433      Attention_Heads      0.649708       0.880780           0.300079           0.482143  Spam\n",
            "       434      Attention_Heads      0.477054       0.482452           0.185542           0.317460  Spam\n",
            "       435      Attention_Heads      0.708709       0.760948           0.019699           0.455159  Spam\n",
            "       436      Attention_Heads      0.806097       0.818012           0.074307           0.767857  Spam\n",
            "       437      Attention_Heads      0.737840       0.707951           0.048726           0.602381  Spam\n",
            "       438      Attention_Heads      0.627271       0.883025           0.002769           0.833333  Spam\n",
            "       439      Attention_Heads      0.778945       0.888622           0.117132           0.408730  Spam\n",
            "       440      Attention_Heads      0.844677       0.837615           0.122794           0.414683  Spam\n",
            "       441      Attention_Heads      0.766280       0.890688           0.070496           0.336905  Spam\n",
            "       442      Attention_Heads      0.790890       0.871945           0.044630           0.585714  Spam\n",
            "       443      Attention_Heads      0.724238       0.907593           0.080829           0.738095  Spam\n",
            "       444      Attention_Heads      0.814413       0.876346           0.105581           0.580952  Spam\n",
            "       445      Attention_Heads      0.742862       0.884457           0.056683           0.488095  Spam\n",
            "       446      Attention_Heads      0.705755       0.863004           0.048599           0.369048  Spam\n",
            "       447      Attention_Heads      0.608472       0.803408           0.205893           0.446429  Spam\n",
            "       448      Attention_Heads      0.797409       0.901364           0.075304           0.464286  Spam\n",
            "       449      Attention_Heads      0.587258       0.882503           0.126167           0.580952  Spam\n",
            "       450      Attention_Heads      0.679188       0.876573           0.026679           0.335317  Spam\n",
            "       451      Attention_Heads      0.699950       0.858185           0.078284           0.250000  Spam\n",
            "       452      Attention_Heads      0.762394       0.875821           0.086125           0.390873  Spam\n",
            "       453      Attention_Heads      0.426347       0.522857           0.166472           0.289683  Spam\n",
            "       454      Attention_Heads      0.828841       0.903195           0.098997           0.531349  Spam\n",
            "       455      Attention_Heads      0.556155       0.923034           0.215669           0.791667  Spam\n",
            "       456      Attention_Heads      0.691593       0.920403           0.095128           0.507937  Spam\n",
            "       457      Attention_Heads      0.752070       0.903954           0.057118           0.661905  Spam\n",
            "       458      Attention_Heads      0.590934       0.874342           0.012400           0.493254  Spam\n",
            "       459      Attention_Heads      0.629854       0.893583           0.365929           0.361111  Spam\n",
            "       460      Attention_Heads      0.751761       0.894904           0.060091           0.598413  Spam\n",
            "       461      Attention_Heads      0.766337       0.845798           0.068130           0.412698  Spam\n",
            "       462      Attention_Heads      0.830137       0.904207           0.039738           0.547619  Spam\n",
            "       463      Attention_Heads      0.447714       0.718545           0.175659           0.610714  Spam\n",
            "       464      Attention_Heads      0.739107       0.913536           0.112187           0.900000  Spam\n",
            "       465      Attention_Heads      0.386254       0.693326           0.590811           0.404762  Spam\n",
            "       466      Attention_Heads      0.703650       0.827284           0.072517           0.271825  Spam\n",
            "       467      Attention_Heads      0.838550       0.869131           0.105501           0.505952  Spam\n",
            "       468      Attention_Heads      0.680056       0.886210           0.020601           0.474206  Spam\n",
            "       469      Attention_Heads      0.725186       0.914259           0.028953           0.580952  Spam\n",
            "       470      Attention_Heads      0.821843       0.912050           0.202417           0.398810  Spam\n",
            "       471      Attention_Heads      0.773098       0.769637           0.281619           0.349206  Spam\n",
            "       472      Attention_Heads      0.729435       0.921501           0.051507           0.545238  Spam\n",
            "       473      Attention_Heads      0.795853       0.849366           0.102693           0.465873  Spam\n",
            "       474      Attention_Heads      0.892101       0.000000           0.078647           1.000000  Spam\n",
            "       475      Attention_Heads      0.893406       0.915509           0.011911           0.473810  Spam\n",
            "       476      Attention_Heads      0.827001       0.854319           0.039828           0.404762  Spam\n",
            "       477      Attention_Heads      0.852197       0.900992           0.015448           0.610714  Spam\n",
            "       478      Attention_Heads      0.637361       0.710743           0.161712           0.332937  Spam\n",
            "       479      Attention_Heads      0.785655       0.865153           0.049512           0.416667  Spam\n",
            "       480      Attention_Heads      0.785655       0.865153           0.049512           0.515476  Spam\n",
            "       481      Attention_Heads      0.844896       0.919535           0.009539           0.452381  Spam\n",
            "       482      Attention_Heads      0.556846       0.860038           0.312581           0.404762  Spam\n",
            "       483      Attention_Heads      0.652198       0.895787           0.196209           0.440476  Spam\n",
            "       484      Attention_Heads      0.860206       0.896074           0.007772           0.257937  Spam\n",
            "       485      Attention_Heads      0.836402       0.901518           0.032837           0.541270  Spam\n",
            "       486      Attention_Heads      0.751761       0.894904           0.060091           0.515873  Spam\n",
            "       487      Attention_Heads      0.600126       0.867848           0.086399           0.457937  Spam\n",
            "       488      Attention_Heads      0.783216       0.910990           0.027362           0.464286  Spam\n",
            "       489      Attention_Heads      0.729570       0.907478           0.233670           0.580952  Spam\n",
            "       490      Attention_Heads      0.821320       0.901005           0.036443           0.709524  Spam\n",
            "       491      Attention_Heads      0.724101       0.679441           0.071586           0.456349  Spam\n",
            "       492      Attention_Heads      0.715466       0.847590           0.015935           0.317460  Spam\n",
            "       493      Attention_Heads      0.477865       0.591426           0.328082           0.639683  Spam\n",
            "       494      Attention_Heads      0.794169       0.841818           0.056104           0.505952  Spam\n",
            "       495      Attention_Heads      0.762099       0.899100           0.076602           0.572619  Spam\n",
            "       496      Attention_Heads      0.679203       0.877796           0.032467           0.464286  Spam\n",
            "       497      Attention_Heads      0.862176       0.904139           0.029490           0.398810  Spam\n",
            "       498      Attention_Heads      0.575328       0.895468           0.464061           0.661905  Spam\n",
            "       499      Attention_Heads      0.833877       0.915774           0.029935           0.422619  Spam\n",
            "       500      Attention_Heads      0.844896       0.919535           0.009539           0.289683  Spam\n",
            "       501      Attention_Heads      0.603143       0.818259           0.011714           0.586905  Spam\n",
            "       502      Attention_Heads      0.771042       0.757952           0.038707           0.303571  Spam\n",
            "       503      Attention_Heads      0.771042       0.757952           0.038707           0.285714  Spam\n",
            "       504      Attention_Heads      0.833877       0.915774           0.029935           0.375000  Spam\n",
            "       505      Attention_Heads      0.442596       0.363378           0.022432           0.450397  Spam\n",
            "       506      Attention_Heads      0.756813       0.902941           0.022965           0.544048  Spam\n",
            "       507      Attention_Heads      0.675264       0.878654           0.024467           0.339286  Spam\n",
            "       508      Attention_Heads      0.737958       0.781672           0.021434           0.271825  Spam\n",
            "       509      Attention_Heads      0.838289       0.927646           0.052279           0.321429  Spam\n",
            "       510      Attention_Heads      0.723076       0.384426           0.170017           0.569048  Spam\n",
            "       511      Attention_Heads      0.864196       0.760605           0.015278           0.900000  Spam\n",
            "       512      Attention_Heads      0.556155       0.923034           0.215669           0.738095  Spam\n",
            "       513      Attention_Heads      0.579001       0.922813           0.032899           0.398810  Spam\n",
            "       514      Attention_Heads      0.733577       0.910051           0.021977           0.620238  Spam\n",
            "       515      Attention_Heads      0.478899       0.892816           0.690443           0.628571  Spam\n",
            "       516      Attention_Heads      0.786532       0.902156           0.013524           0.343254  Spam\n",
            "       517      Attention_Heads      0.695290       0.878310           0.028706           0.380952  Spam\n",
            "       518      Attention_Heads      0.745888       0.875141           0.011958           0.476190  Spam\n",
            "       519      Attention_Heads      0.232896       0.524439           0.226802           0.498016  Spam\n",
            "       520      Attention_Heads      0.749997       0.921326           0.010912           0.479762  Spam\n",
            "       521      Attention_Heads      0.816228       0.892452           0.076067           0.569048  Spam\n",
            "       522      Attention_Heads      0.786809       0.816514           0.055061           0.380952  Spam\n",
            "       523      Attention_Heads      0.385609       0.730367           0.765959           0.563492  Spam\n",
            "       524      Attention_Heads      0.782890       0.903257           0.013901           0.525397  Spam\n",
            "       525      Attention_Heads      0.674814       0.826944           0.077962           0.580952  Spam\n",
            "       526      Attention_Heads      0.770825       0.914885           0.003591           0.416667  Spam\n",
            "       527      Attention_Heads      0.809884       0.873589           0.040470           0.488095  Spam\n",
            "       528      Attention_Heads      0.803885       0.916376           0.046554           0.450397  Spam\n",
            "       529      Attention_Heads      0.636453       0.875032           0.059561           0.440476  Spam\n",
            "       530      Attention_Heads      0.818200       0.909669           0.024539           0.459921  Spam\n",
            "       531      Attention_Heads      0.827331       0.878018           0.007164           0.563095  Spam\n",
            "       532      Attention_Heads      0.800264       0.888659           0.033681           0.523810  Spam\n",
            "       533      Attention_Heads      0.660334       0.910280           0.520746           0.800000  Spam\n",
            "       534      Attention_Heads      0.750157       0.884796           0.106030           0.620238  Spam\n",
            "       535      Attention_Heads      0.755444       0.927044           0.026092           0.476190  Spam\n",
            "       536      Attention_Heads      0.853353       0.918237           0.055203           0.456349  Spam\n",
            "       537      Attention_Heads      0.873784       0.883506           0.034252           0.464286  Spam\n",
            "       538      Attention_Heads      0.865219       0.829536           0.015750           0.452381  Spam\n",
            "       539      Attention_Heads      0.743624       0.905278           0.048436           0.432540  Spam\n",
            "       540      Attention_Heads      0.556155       0.923034           0.215669           0.801190  Spam\n",
            "       541      Attention_Heads      0.762120       0.856524           0.110710           0.536905  Spam\n",
            "       542      Attention_Heads      0.668922       0.851258           0.023328           0.384921  Spam\n",
            "       543      Attention_Heads      0.799696       0.883933           0.061801           0.404762  Spam\n",
            "       544      Attention_Heads      0.756844       0.904656           0.020610           0.510714  Spam\n",
            "       545      Attention_Heads      0.669777       0.832445           0.236118           0.357143  Spam\n",
            "       546      Attention_Heads      0.795312       0.560529           0.048317           0.470238  Spam\n",
            "       547      Attention_Heads      0.556155       0.923034           0.215669           0.745635  Spam\n",
            "       548      Attention_Heads      0.533695       0.559659           0.758181           0.800000  Spam\n",
            "       549      Attention_Heads      0.705619       0.918139           0.046060           0.416667  Spam\n",
            "       550      Attention_Heads      0.741981       0.915588           0.016273           0.400794  Spam\n",
            "       551      Attention_Heads      0.858068       0.922709           0.005899           0.402778  Spam\n",
            "       552      Attention_Heads      0.764417       0.798417           0.015787           0.610714  Spam\n",
            "       553      Attention_Heads      0.577568       0.883217           0.021119           0.422619  Spam\n",
            "       554      Attention_Heads      0.783426       0.910330           0.067345           0.652381  Spam\n",
            "       555      Attention_Heads      0.812955       0.910112           0.478578           0.719048  Spam\n",
            "       556      Attention_Heads      0.828533       0.865390           0.029596           0.414683  Spam\n",
            "       557      Attention_Heads      0.833872       0.857758           0.020565           0.634524  Spam\n",
            "       558      Attention_Heads      0.680695       0.864578           0.105295           0.482143  Spam\n",
            "       559      Attention_Heads      0.755745       0.898067           0.116453           0.809524  Spam\n",
            "       560      Attention_Heads      0.797937       0.890315           0.013409           0.339286  Spam\n",
            "       561      Attention_Heads      0.698304       0.845972           0.169649           0.303571  Spam\n",
            "       562      Attention_Heads      0.670345       0.879366           0.115750           0.341270  Spam\n",
            "       563      Attention_Heads      0.669446       0.888159           0.122034           0.363095  Spam\n",
            "       564      Attention_Heads      0.807182       0.879429           0.068452           0.343254  Spam\n",
            "       565      Attention_Heads      0.687044       0.804978           0.078103           0.446429  Spam\n",
            "       566      Attention_Heads      0.483124       0.886713           0.076813           0.758333  Spam\n",
            "       567      Attention_Heads      0.757481       0.923863           0.005419           0.511905  Spam\n",
            "       568      Attention_Heads      0.757666       0.925049           0.002638           0.580952  Spam\n",
            "       569      Attention_Heads      0.592736       0.902296           0.079970           0.345238  Spam\n",
            "       570      Attention_Heads      0.804237       0.906257           0.015112           0.521429  Spam\n",
            "       571      Attention_Heads      0.807330       0.907391           0.018971           0.652381  Spam\n",
            "       572      Attention_Heads      0.799296       0.903150           0.071974           0.446429  Spam\n",
            "       573      Attention_Heads      0.768603       0.898028           0.015090           0.380952  Spam\n",
            "       574      Attention_Heads      0.382411       0.129451           0.359212           0.420635  Spam\n",
            "       575      Attention_Heads      0.614761       0.689801           0.055166           0.375000  Spam\n",
            "       576      Attention_Heads      0.792562       0.895053           0.013216           0.230159  Spam\n",
            "       577      Attention_Heads      0.653724       0.880263           0.294432           0.503571  Spam\n",
            "       578      Attention_Heads      0.767037       0.906208           0.052526           0.488095  Spam\n",
            "       579      Attention_Heads      0.628018       0.828038           0.200849           0.307540  Spam\n",
            "       580      Attention_Heads      0.729309       0.907086           0.024165           0.511905  Spam\n",
            "       581      Attention_Heads      0.625952       0.619822           0.076864           0.547619  Spam\n",
            "       582      Attention_Heads      0.780308       0.745077           0.125218           0.446429  Spam\n",
            "       583      Attention_Heads      0.418131       0.308478           0.470987           0.339286  Spam\n",
            "       584      Attention_Heads      0.797845       0.880023           0.599257           0.725000  Spam\n",
            "       585      Attention_Heads      0.886104       0.899698           0.026645           0.293651  Spam\n",
            "       586      Attention_Heads      0.892101       0.000000           0.078647           1.000000  Spam\n",
            "       587      Attention_Heads      0.866699       0.921507           0.007127           0.465873  Spam\n",
            "       588      Attention_Heads      0.738552       0.840342           0.059543           0.539286  Spam\n",
            "       589      Attention_Heads      0.830723       0.906134           0.017300           0.222222  Spam\n",
            "       590      Attention_Heads      0.715124       0.886424           0.202094           0.414683  Spam\n",
            "       591      Attention_Heads      0.776609       0.858406           0.067128           0.473810  Spam\n",
            "       592      Attention_Heads      0.835759       0.863076           0.325560           0.359127  Spam\n",
            "       593      Attention_Heads      0.783460       0.551736           0.025006           0.521429  Spam\n",
            "       594      Attention_Heads      0.822370       0.837090           0.281244           0.380952  Spam\n",
            "       595      Attention_Heads      0.812912       0.914095           0.139506           0.432540  Spam\n",
            "       596      Attention_Heads      0.878677       0.914669           0.002863           0.719048  Spam\n",
            "       597      Attention_Heads      0.749544       0.901485           0.006927           0.363095  Spam\n",
            "       598      Attention_Heads      0.758966       0.872478           0.532920           0.719048  Spam\n",
            "       599      Attention_Heads      0.521068       0.903002           0.575088           0.800000  Spam\n",
            "       600      Attention_Heads      0.854973       0.898863           0.013480           0.458333  Spam\n",
            "       601      Attention_Heads      0.819637       0.914405           0.045120           0.549206  Spam\n",
            "       602      Attention_Heads      0.713385       0.343468           0.671166           0.547619  Spam\n",
            "       603      Attention_Heads      0.814591       0.826935           0.284308           0.345238  Spam\n",
            "       604      Attention_Heads      0.649499       0.891758           0.023864           0.257937  Spam\n",
            "       605      Attention_Heads      0.812971       0.909017           0.013985           0.652381  Spam\n",
            "       606      Attention_Heads      0.761248       0.887534           0.107489           0.535714  Spam\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "id": "e9035d5b",
      "metadata": {
        "id": "e9035d5b",
        "outputId": "c889376d-bbfa-465b-a815-9e7acbb5e020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save results for further analysis\n",
        "import os\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "results_dir = os.path.join(DATA_PATH, 'results', 'explanation_quality')\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Save detailed results\n",
        "if 'combined_df' in locals():\n",
        "    results_file = os.path.join(results_dir, 'bert_explanation_quality_metrics.csv')\n",
        "    combined_df.to_csv(results_file, index=False)\n",
        "    print(f\"Detailed results saved to: {results_file}\")\n",
        "elif 'ig_df' in locals():\n",
        "    results_file = os.path.join(results_dir, 'bert_ig_metrics.csv')\n",
        "    ig_df.to_csv(results_file, index=False)\n",
        "    print(f\"Integrated Gradients results saved to: {results_file}\")\n",
        "elif 'attention_df' in locals():\n",
        "    results_file = os.path.join(results_dir, 'bert_attention_metrics.csv')\n",
        "    attention_df.to_csv(results_file, index=False)\n",
        "    print(f\"Attention results saved to: {results_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BERT EXPLANATION QUALITY ANALYSIS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nKey Findings:\")\n",
        "print(\"- Successfully computed AUC-Del, AUC-Ins, Comprehensiveness, and Jaccard Stability\")\n",
        "print(\"- Compared LayerIntegratedGradients vs Attention Head explanations\")\n",
        "print(\"- Generated deletion and insertion curve visualizations\")\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"- Analyze metric patterns across spam vs ham samples\")\n",
        "print(\"- Compare with other model explanation methods\")\n",
        "print(\"- Use insights to improve model interpretability\")\n",
        "\n",
        "print(f\"\\nResults saved in: {results_dir}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detailed results saved to: /content/drive/MyDrive/Projects/spam-detection-data/results/explanation_quality/bert_explanation_quality_metrics.csv\n",
            "\n",
            "============================================================\n",
            "BERT EXPLANATION QUALITY ANALYSIS COMPLETE\n",
            "============================================================\n",
            "\n",
            "Key Findings:\n",
            "- Successfully computed AUC-Del, AUC-Ins, Comprehensiveness, and Jaccard Stability\n",
            "- Compared LayerIntegratedGradients vs Attention Head explanations\n",
            "- Generated deletion and insertion curve visualizations\n",
            "\n",
            "Next Steps:\n",
            "- Analyze metric patterns across spam vs ham samples\n",
            "- Compare with other model explanation methods\n",
            "- Use insights to improve model interpretability\n",
            "\n",
            "Results saved in: /content/drive/MyDrive/Projects/spam-detection-data/results/explanation_quality\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "from explainability.BertExplanationMetrics import analyze_test_dataset_influential_words\n",
        "\n",
        "# Analyze your test dataset\n",
        "results = analyze_test_dataset_influential_words(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_texts=test_df['text'].tolist(),\n",
        "    test_labels=test_df['label'].tolist(),\n",
        "    device=device,\n",
        "    top_k=20,\n",
        "    method='attention'\n",
        ")"
      ],
      "metadata": {
        "id": "nHM5Uyekb3e9",
        "outputId": "f4677f6c-42e4-4bec-f1b9-4a957279ef21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nHM5Uyekb3e9",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing BERT explanation analyzer...\n",
            "Analyzing top 20 influential words using attention...\n",
            "Analyzing 606 texts for influential words using attention...\n",
            "Processed 10/606 texts...\n",
            "Processed 20/606 texts...\n",
            "Processed 30/606 texts...\n",
            "Processed 40/606 texts...\n",
            "Processed 50/606 texts...\n",
            "Processed 60/606 texts...\n",
            "Processed 70/606 texts...\n",
            "Processed 80/606 texts...\n",
            "Processed 90/606 texts...\n",
            "Processed 100/606 texts...\n",
            "Processed 110/606 texts...\n",
            "Processed 120/606 texts...\n",
            "Processed 130/606 texts...\n",
            "Processed 140/606 texts...\n",
            "Processed 150/606 texts...\n",
            "Processed 160/606 texts...\n",
            "Processed 170/606 texts...\n",
            "Processed 180/606 texts...\n",
            "Processed 190/606 texts...\n",
            "Processed 200/606 texts...\n",
            "Processed 210/606 texts...\n",
            "Processed 220/606 texts...\n",
            "Processed 230/606 texts...\n",
            "Processed 240/606 texts...\n",
            "Processed 250/606 texts...\n",
            "Processed 260/606 texts...\n",
            "Processed 270/606 texts...\n",
            "Processed 280/606 texts...\n",
            "Processed 290/606 texts...\n",
            "Processed 300/606 texts...\n",
            "Processed 310/606 texts...\n",
            "Processed 320/606 texts...\n",
            "Processed 330/606 texts...\n",
            "Processed 340/606 texts...\n",
            "Processed 350/606 texts...\n",
            "Processed 360/606 texts...\n",
            "Processed 370/606 texts...\n",
            "Processed 380/606 texts...\n",
            "Processed 390/606 texts...\n",
            "Processed 400/606 texts...\n",
            "Processed 410/606 texts...\n",
            "Processed 420/606 texts...\n",
            "Processed 430/606 texts...\n",
            "Processed 440/606 texts...\n",
            "Processed 450/606 texts...\n",
            "Processed 460/606 texts...\n",
            "Processed 470/606 texts...\n",
            "Processed 480/606 texts...\n",
            "Processed 490/606 texts...\n",
            "Processed 500/606 texts...\n",
            "Processed 510/606 texts...\n",
            "Processed 520/606 texts...\n",
            "Processed 530/606 texts...\n",
            "Processed 540/606 texts...\n",
            "Processed 550/606 texts...\n",
            "Processed 560/606 texts...\n",
            "Processed 570/606 texts...\n",
            "Processed 580/606 texts...\n",
            "Processed 590/606 texts...\n",
            "Processed 600/606 texts...\n",
            "Successfully processed 606 texts\n",
            "\n",
            "================================================================================\n",
            "TOP INFLUENTIAL WORDS ANALYSIS\n",
            "================================================================================\n",
            "Method: attention\n",
            "Total texts processed: 606\n",
            "Total unique words found: 2672\n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (OVERALL)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    ing                  28         0.0062       0.0148    \n",
            "2    subject              87         0.0061       0.0072    \n",
            "3    removal              8          0.0044       0.0059    \n",
            "4    allow                8          0.0040       0.0115    \n",
            "5    ed                   5          0.0038       0.0078    \n",
            "6    d                    19         0.0035       0.0150    \n",
            "7    information          8          0.0035       0.0104    \n",
            "8    groups               77         0.0035       0.0037    \n",
            "9    share                2          0.0034       0.0049    \n",
            "10   automated            2          0.0030       0.0044    \n",
            "11   48                   5          0.0030       0.0030    \n",
            "12   panel                2          0.0030       0.0030    \n",
            "13   would                5          0.0030       0.0064    \n",
            "14   under                2          0.0029       0.0037    \n",
            "15   hours                7          0.0028       0.0033    \n",
            "16   thousands            2          0.0028       0.0033    \n",
            "17   abbey                2          0.0028       0.0028    \n",
            "18   idiot                3          0.0027       0.0041    \n",
            "19   quote                5          0.0027       0.0045    \n",
            "20   software             10         0.0027       0.0088    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (SPAM)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    d                    3          0.0083       0.0150    \n",
            "2    ing                  8          0.0069       0.0101    \n",
            "3    allow                5          0.0053       0.0115    \n",
            "4    ed                   2          0.0048       0.0078    \n",
            "5    removal              8          0.0044       0.0059    \n",
            "6    8                    2          0.0038       0.0057    \n",
            "7    s                    40         0.0031       0.0105    \n",
            "8    48                   5          0.0030       0.0030    \n",
            "9    hours                6          0.0029       0.0033    \n",
            "10   quote                5          0.0027       0.0045    \n",
            "11   notices              2          0.0026       0.0028    \n",
            "12   addresses            3          0.0025       0.0033    \n",
            "13   about                10         0.0025       0.0070    \n",
            "14   robot                2          0.0025       0.0026    \n",
            "15   method               2          0.0025       0.0028    \n",
            "16   six                  2          0.0024       0.0025    \n",
            "17   word                 3          0.0024       0.0027    \n",
            "18   email                54         0.0024       0.0150    \n",
            "19   requests             4          0.0024       0.0031    \n",
            "20   mortgage             6          0.0024       0.0035    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (HAM)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    subject              77         0.0066       0.0072    \n",
            "2    ing                  20         0.0059       0.0148    \n",
            "3    information          5          0.0044       0.0104    \n",
            "4    groups               77         0.0035       0.0037    \n",
            "5    share                2          0.0034       0.0049    \n",
            "6    ed                   3          0.0032       0.0057    \n",
            "7    automated            2          0.0030       0.0044    \n",
            "8    panel                2          0.0030       0.0030    \n",
            "9    software             8          0.0029       0.0088    \n",
            "10   service              2          0.0028       0.0036    \n",
            "11   abbey                2          0.0028       0.0028    \n",
            "12   idiot                3          0.0027       0.0041    \n",
            "13   e                    11         0.0027       0.0108    \n",
            "14   wow                  2          0.0027       0.0033    \n",
            "15   joe                  4          0.0027       0.0035    \n",
            "16   warns                2          0.0026       0.0034    \n",
            "17   d                    16         0.0026       0.0140    \n",
            "18   philip               2          0.0026       0.0032    \n",
            "19   byrne                3          0.0026       0.0037    \n",
            "20   peter                2          0.0025       0.0032    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST DISCRIMINATIVE WORDS\n",
            "==================================================\n",
            "Rank Word                 Category        Spam Score   Ham Score   Diff    \n",
            "---------------------------------------------------------------------------\n",
            "1    d                    spam_indicator  0.0083       0.0026      0.0057  \n",
            "2    removal              spam_indicator  0.0044       0.0000      0.0044  \n",
            "3    subject              ham_indicator   0.0023       0.0066      -0.0043 \n",
            "4    groups               ham_indicator   0.0000       0.0035      -0.0035 \n",
            "5    share                ham_indicator   0.0000       0.0034      -0.0034 \n",
            "6    allow                spam_indicator  0.0053       0.0019      0.0034  \n",
            "7    automated            ham_indicator   0.0000       0.0030      -0.0030 \n",
            "8    48                   spam_indicator  0.0030       0.0000      0.0030  \n",
            "9    panel                ham_indicator   0.0000       0.0030      -0.0030 \n",
            "10   hours                spam_indicator  0.0029       0.0000      0.0029  \n",
            "11   abbey                ham_indicator   0.0000       0.0028      -0.0028 \n",
            "12   idiot                ham_indicator   0.0000       0.0027      -0.0027 \n",
            "13   e                    ham_indicator   0.0000       0.0027      -0.0027 \n",
            "14   quote                spam_indicator  0.0027       0.0000      0.0027  \n",
            "15   wow                  ham_indicator   0.0000       0.0027      -0.0027 \n",
            "16   joe                  ham_indicator   0.0000       0.0027      -0.0027 \n",
            "17   warns                ham_indicator   0.0000       0.0026      -0.0026 \n",
            "18   notices              spam_indicator  0.0026       0.0000      0.0026  \n",
            "19   information          ham_indicator   0.0018       0.0044      -0.0026 \n",
            "20   philip               ham_indicator   0.0000       0.0026      -0.0026 \n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from explainability.BertExplanationMetrics import analyze_test_dataset_influential_words\n",
        "\n",
        "# Analyze your test dataset\n",
        "results = analyze_test_dataset_influential_words(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_texts=test_df['text'].tolist(),\n",
        "    test_labels=test_df['label'].tolist(),\n",
        "    device=device,\n",
        "    top_k=20,\n",
        "    method='integrated_gradients'\n",
        ")"
      ],
      "metadata": {
        "id": "XCbaRncycDFI",
        "outputId": "af4b46f4-c5a9-4178-e0f2-b58ef0c03f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XCbaRncycDFI",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing BERT explanation analyzer...\n",
            "Analyzing top 20 influential words using integrated_gradients...\n",
            "Analyzing 606 texts for influential words using integrated_gradients...\n",
            "Processed 10/606 texts...\n",
            "Processed 20/606 texts...\n",
            "Processed 30/606 texts...\n",
            "Processed 40/606 texts...\n",
            "Processed 50/606 texts...\n",
            "Processed 60/606 texts...\n",
            "Processed 70/606 texts...\n",
            "Processed 80/606 texts...\n",
            "Processed 90/606 texts...\n",
            "Processed 100/606 texts...\n",
            "Processed 110/606 texts...\n",
            "Processed 120/606 texts...\n",
            "Processed 130/606 texts...\n",
            "Processed 140/606 texts...\n",
            "Processed 150/606 texts...\n",
            "Processed 160/606 texts...\n",
            "Processed 170/606 texts...\n",
            "Processed 180/606 texts...\n",
            "Processed 190/606 texts...\n",
            "Processed 200/606 texts...\n",
            "Processed 210/606 texts...\n",
            "Processed 220/606 texts...\n",
            "Processed 230/606 texts...\n",
            "Processed 240/606 texts...\n",
            "Processed 250/606 texts...\n",
            "Processed 260/606 texts...\n",
            "Processed 270/606 texts...\n",
            "Processed 280/606 texts...\n",
            "Processed 290/606 texts...\n",
            "Processed 300/606 texts...\n",
            "Processed 310/606 texts...\n",
            "Processed 320/606 texts...\n",
            "Processed 330/606 texts...\n",
            "Processed 340/606 texts...\n",
            "Processed 350/606 texts...\n",
            "Processed 360/606 texts...\n",
            "Processed 370/606 texts...\n",
            "Processed 380/606 texts...\n",
            "Processed 390/606 texts...\n",
            "Processed 400/606 texts...\n",
            "Processed 410/606 texts...\n",
            "Processed 420/606 texts...\n",
            "Processed 430/606 texts...\n",
            "Processed 440/606 texts...\n",
            "Processed 450/606 texts...\n",
            "Processed 460/606 texts...\n",
            "Processed 470/606 texts...\n",
            "Processed 480/606 texts...\n",
            "Processed 490/606 texts...\n",
            "Processed 500/606 texts...\n",
            "Processed 510/606 texts...\n",
            "Processed 520/606 texts...\n",
            "Processed 530/606 texts...\n",
            "Processed 540/606 texts...\n",
            "Processed 550/606 texts...\n",
            "Processed 560/606 texts...\n",
            "Processed 570/606 texts...\n",
            "Processed 580/606 texts...\n",
            "Processed 590/606 texts...\n",
            "Processed 600/606 texts...\n",
            "Successfully processed 606 texts\n",
            "\n",
            "================================================================================\n",
            "TOP INFLUENTIAL WORDS ANALYSIS\n",
            "================================================================================\n",
            "Method: integrated_gradients\n",
            "Total texts processed: 606\n",
            "Total unique words found: 2401\n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (OVERALL)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    addresses            2          0.6400       1.2567    \n",
            "2    viruses              2          0.4413       0.8545    \n",
            "3    sincerely            2          0.4211       0.4211    \n",
            "4    razor                4          0.3762       0.6263    \n",
            "5    robot                2          0.3744       0.4577    \n",
            "6    rpm                  33         0.3607       1.0409    \n",
            "7    britain              3          0.3336       0.5042    \n",
            "8    amsterdam            4          0.3212       0.8201    \n",
            "9    smoking              2          0.2942       0.4546    \n",
            "10   helps                2          0.2895       0.5536    \n",
            "11   welcome              3          0.2885       0.6365    \n",
            "12   yours                5          0.2648       0.4715    \n",
            "13   apparently           2          0.2588       0.4598    \n",
            "14   steven               2          0.2515       0.4479    \n",
            "15   again                3          0.2391       0.6294    \n",
            "16   heaven               3          0.2361       0.3234    \n",
            "17   choose               2          0.2335       0.2689    \n",
            "18   sas                  4          0.2321       0.2955    \n",
            "19   use                  98         0.2114       0.3579    \n",
            "20   note                 3          0.2052       0.4432    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (SPAM)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    addresses            2          0.6400       1.2567    \n",
            "2    sincerely            2          0.4211       0.4211    \n",
            "3    robot                2          0.3744       0.4577    \n",
            "4    english              2          0.3742       0.7245    \n",
            "5    again                2          0.3477       0.6294    \n",
            "6    amsterdam            4          0.3212       0.8201    \n",
            "7    smoking              2          0.2942       0.4546    \n",
            "8    yours                5          0.2648       0.4715    \n",
            "9    try                  2          0.2567       0.2567    \n",
            "10   page                 2          0.2565       0.4918    \n",
            "11   want                 2          0.2429       0.4370    \n",
            "12   choose               2          0.2335       0.2689    \n",
            "13   found                4          0.2335       0.3490    \n",
            "14   purchase             2          0.2087       0.3382    \n",
            "15   warsaw               2          0.2028       0.2028    \n",
            "16   ey                   2          0.1968       0.1968    \n",
            "17   support              2          0.1911       0.3010    \n",
            "18   lose                 3          0.1907       0.2282    \n",
            "19   innocent             2          0.1854       0.2139    \n",
            "20   apologies            2          0.1833       0.2740    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST INFLUENTIAL WORDS (HAM)\n",
            "==================================================\n",
            "Rank Word                 Frequency  Mean Score   Max Score \n",
            "------------------------------------------------------------\n",
            "1    razor                4          0.3762       0.6263    \n",
            "2    rpm                  33         0.3607       1.0409    \n",
            "3    britain              3          0.3336       0.5042    \n",
            "4    heaven               2          0.3204       0.3234    \n",
            "5    apparently           2          0.2588       0.4598    \n",
            "6    steven               2          0.2515       0.4479    \n",
            "7    ryan                 3          0.2500       0.2700    \n",
            "8    please               7          0.2410       0.7541    \n",
            "9    sas                  4          0.2321       0.2955    \n",
            "10   use                  97         0.2131       0.3579    \n",
            "11   note                 3          0.2052       0.4432    \n",
            "12   christmas            2          0.2047       0.3680    \n",
            "13   foot                 2          0.1988       0.3805    \n",
            "14   sin                  4          0.1895       0.3646    \n",
            "15   k                    4          0.1871       0.6556    \n",
            "16   paradise             2          0.1850       0.1857    \n",
            "17   online               3          0.1841       0.3587    \n",
            "18   users                46         0.1820       0.8321    \n",
            "19   everything           2          0.1800       0.3316    \n",
            "20   troy                 2          0.1716       0.1749    \n",
            "\n",
            "==================================================\n",
            "TOP 20 MOST DISCRIMINATIVE WORDS\n",
            "==================================================\n",
            "Rank Word                 Category        Spam Score   Ham Score   Diff    \n",
            "---------------------------------------------------------------------------\n",
            "1    addresses            spam_indicator  0.6400       0.0000      0.6400  \n",
            "2    sincerely            spam_indicator  0.4211       0.0000      0.4211  \n",
            "3    razor                ham_indicator   0.0000       0.3762      -0.3762 \n",
            "4    robot                spam_indicator  0.3744       0.0000      0.3744  \n",
            "5    rpm                  ham_indicator   0.0000       0.3607      -0.3607 \n",
            "6    again                spam_indicator  0.3477       0.0000      0.3477  \n",
            "7    britain              ham_indicator   0.0000       0.3336      -0.3336 \n",
            "8    english              spam_indicator  0.3742       0.0431      0.3312  \n",
            "9    amsterdam            spam_indicator  0.3212       0.0000      0.3212  \n",
            "10   heaven               ham_indicator   0.0000       0.3204      -0.3204 \n",
            "11   smoking              spam_indicator  0.2942       0.0000      0.2942  \n",
            "12   yours                spam_indicator  0.2648       0.0000      0.2648  \n",
            "13   apparently           ham_indicator   0.0000       0.2588      -0.2588 \n",
            "14   steven               ham_indicator   0.0000       0.2515      -0.2515 \n",
            "15   ryan                 ham_indicator   0.0000       0.2500      -0.2500 \n",
            "16   choose               spam_indicator  0.2335       0.0000      0.2335  \n",
            "17   sas                  ham_indicator   0.0000       0.2321      -0.2321 \n",
            "18   try                  spam_indicator  0.2567       0.0429      0.2138  \n",
            "19   use                  ham_indicator   0.0000       0.2131      -0.2131 \n",
            "20   purchase             spam_indicator  0.2087       0.0000      0.2087  \n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}